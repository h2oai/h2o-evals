filename,context,question,choices,answer
EU_AI_Act.pdf,"European Parliament 2019-2024 TEXTS ADOPTED P9_TA(2023)0236 Artificial Intelligence Act Amendments adopted by the European Parliament on 14 June 2023 on the proposal for  a regulation of the European Parliament and of the Council on laying down harmonised  rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union  legislative acts (COM(2021)0206 – C9-0146/2021 – 2021/0106(COD))1 (Ordinary legislative procedure: first reading) 1 The matter was referred back for interinstitutional negotiations to the committee  responsible, pursuant to Rule 59(4), fourth subparagraph (A9-0188/2023). Amendment 1 Proposal for a regulation Citation 4 a (new) Text proposed by the Commission Amendment Having regard to the opinion of the  European Central Bank,  Amendment 2 Proposal for a regulation Citation 4 b (new) Text proposed by the Commission Amendment Having regard to the joint opinion of the  European Data Protection Board and the  European Data Protection Supervisor,  Amendment 3 Proposal for a regulation Recital 1 Text proposed by the Commission Amendment (1) The purpose of this Regulation is to  improve the functioning of the internal  market by laying down a uniform legal  framework in particular for the  development, marketing and use of  artificial intelligence in conformity with  Union values. This Regulation pursues a  number of overriding reasons of public  interest, such as a high level of protection  of health, safety and fundamental rights,  and it ensures the free movement of AI- based goods and services cross-border,  thus preventing Member States from  imposing restrictions on the development,  marketing and use of AI systems, unless  explicitly authorised by this Regulation.(1) The purpose of this Regulation is to  promote the uptake of human centric and  trustworthy artificial intelligence and to  ensure a high level of protection of  health, safety, fundamental rights,  democracy and rule of law and the  environment from harmful effects of  artificial intelligence systems in the Union  while supporting innovation and  improving the functioning of the internal  market. This Regulation lays down a  uniform legal framework in particular for  the development, the placing on the  market, the putting into service and the  use of artificial intelligence in conformity  with Union values and ensures the free  movement of AI-based goods and services cross-border, thus preventing Member  States from imposing restrictions on the  development, marketing and use of  Artificial Intelligence systems (AI  systems), unless explicitly authorised by  this Regulation. Certain AI systems can  also have an impact on democracy and  rule of law and the environment. These  concerns are specifically addressed in the  critical sectors and use cases listed in the  annexes to this Regulation. Amendment 4 Proposal for a regulation Recital 1 a (new) Text proposed by the Commission Amendment (1a) This Regulation should preserve the  values of the Union facilitating the  distribution of artificial intelligence  benefits across society, protecting  individuals, companies, democracy and  rule of law and the environment from  risks while boosting innovation and  employment and making  the Union a  leader in the field. Amendment 5 Proposal for a regulation Recital 2 Text proposed by the Commission Amendment (2)Artificial intelligence systems (AI  systems) can be easily deployed in multiple  sectors of the economy and society,  including cross border, and circulate  throughout the Union. Certain Member  States have already explored the adoption  of national rules to ensure that artificial  intelligence is safe and is developed and  used in compliance with fundamental  rights obligations. Differing national rules  may lead to fragmentation of the internal  market and decrease legal certainty for (2) AI systems can be easily deployed in  multiple sectors of the economy and  society, including cross border, and  circulate throughout the Union. Certain  Member States have already explored the  adoption of national rules to ensure that  artificial intelligence is trustworthy and  safe and is developed and used in  compliance with fundamental rights  obligations. Differing national rules may  lead to fragmentation of the internal market  and decrease legal certainty for operators operators that develop or use AI systems",What are the concerns specifically addressed in the critical sectors and use cases listed in the annexes to the Regulation?,"['Environmental concerns.', 'Health and safety concerns.', 'Democracy and rule of law concerns.', 'Employment concerns.']",2
EU_AI_Act.pdf,"(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  unacceptable artificial intelligence  practices, to lay down requirements for  high-risk AI systems and obligations for  the relevant operators, and to lay down  transparency obligations for certain AI  systems Amendment 37 Proposal for a regulation Recital 15 Text proposed by the Commission Amendment (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  should be prohibited because they  contradict Union values of respect for  human dignity, freedom, equality, (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  abusive and should be prohibited because  they contradict Union values of respect for  human dignity, freedom, equality, democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child.democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child. Amendment 38 Proposal for a regulation Recital 16 Text proposed by the Commission Amendment (16) The placing on the market, putting  into service or use of certain AI systems  intended to distort human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  Such AI systems deploy subliminal  components individuals cannot perceive or  exploit vulnerabilities of children and  people due to their age, physical or mental  incapacities. They do so with the intention  to materially distort the behaviour of a  person and in a manner that causes or is  likely to cause harm to that or another  person. The intention may not be presumed  if the distortion of human behaviour  results from factors external to the AI  system which are outside of the control of  the provider or the user. Research for  legitimate purposes in relation to such AI  systems should not be stifled by the  prohibition, if such research does not  amount to use of the AI system in human- machine relations that exposes natural  persons to harm and such research is  carried out in accordance with recognised  ethical standards for scientific research.(16) The placing on the market, putting  into service or use of certain AI systems  with the objective to or the effect of  materially distorting human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  This limitation should be understood to  include neuro-technologies assisted by AI  systems that are used to monitor, use, or  influence neural data gathered through  brain-computer interfaces insofar as they  are materially distorting the behaviour of  a natural person in a manner that causes  or is likely to cause that person or another  person significant harm. Such AI systems  deploy subliminal components individuals  cannot perceive or exploit vulnerabilities of  individuals and specific groups of persons  due to their known or predicted  personality traits, age, physical or mental  incapacities, social or economic situation.  They do so with the intention to or the  effect of materially distorting the  behaviour of a person and in a manner that  causes or is likely to cause significant  harm to that or another person or groups of  persons, including harms that may be  accumulated over time. The intention to  distort the behaviour may not be presumed  if the distortion results from factors  external to the AI system which are outside  of the control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated by the  provider or the deployer of the AI system",What is the purpose of the proposed regulation regarding AI systems?,"['To encourage the development and use of AI systems without any restrictions.', 'To prohibit the use of AI systems that can cause physical or psychological harm.', 'To regulate the use of AI systems that can distort human behavior.', 'To promote the use of AI systems that can improve human behavior.']",2
EU_AI_Act.pdf,"(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  unacceptable artificial intelligence  practices, to lay down requirements for  high-risk AI systems and obligations for  the relevant operators, and to lay down  transparency obligations for certain AI  systems Amendment 37 Proposal for a regulation Recital 15 Text proposed by the Commission Amendment (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  should be prohibited because they  contradict Union values of respect for  human dignity, freedom, equality, (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  abusive and should be prohibited because  they contradict Union values of respect for  human dignity, freedom, equality, democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child.democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child. Amendment 38 Proposal for a regulation Recital 16 Text proposed by the Commission Amendment (16) The placing on the market, putting  into service or use of certain AI systems  intended to distort human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  Such AI systems deploy subliminal  components individuals cannot perceive or  exploit vulnerabilities of children and  people due to their age, physical or mental  incapacities. They do so with the intention  to materially distort the behaviour of a  person and in a manner that causes or is  likely to cause harm to that or another  person. The intention may not be presumed  if the distortion of human behaviour  results from factors external to the AI  system which are outside of the control of  the provider or the user. Research for  legitimate purposes in relation to such AI  systems should not be stifled by the  prohibition, if such research does not  amount to use of the AI system in human- machine relations that exposes natural  persons to harm and such research is  carried out in accordance with recognised  ethical standards for scientific research.(16) The placing on the market, putting  into service or use of certain AI systems  with the objective to or the effect of  materially distorting human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  This limitation should be understood to  include neuro-technologies assisted by AI  systems that are used to monitor, use, or  influence neural data gathered through  brain-computer interfaces insofar as they  are materially distorting the behaviour of  a natural person in a manner that causes  or is likely to cause that person or another  person significant harm. Such AI systems  deploy subliminal components individuals  cannot perceive or exploit vulnerabilities of  individuals and specific groups of persons  due to their known or predicted  personality traits, age, physical or mental  incapacities, social or economic situation.  They do so with the intention to or the  effect of materially distorting the  behaviour of a person and in a manner that  causes or is likely to cause significant  harm to that or another person or groups of  persons, including harms that may be  accumulated over time. The intention to  distort the behaviour may not be presumed  if the distortion results from factors  external to the AI system which are outside  of the control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated by the  provider or the deployer of the AI system",What is the purpose of Recital 15 of the proposed regulation?,"['To prohibit certain artificial intelligence practices that contradict Union values.', 'To provide novel and powerful tools for manipulative, exploitative, and social control practices.', 'To promote the beneficial uses of artificial intelligence.', 'To establish a risk-based approach for introducing binding rules for AI systems.']",0
EU_AI_Act.pdf,"(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  unacceptable artificial intelligence  practices, to lay down requirements for  high-risk AI systems and obligations for  the relevant operators, and to lay down  transparency obligations for certain AI  systems Amendment 37 Proposal for a regulation Recital 15 Text proposed by the Commission Amendment (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  should be prohibited because they  contradict Union values of respect for  human dignity, freedom, equality, (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  abusive and should be prohibited because  they contradict Union values of respect for  human dignity, freedom, equality, democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child.democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child. Amendment 38 Proposal for a regulation Recital 16 Text proposed by the Commission Amendment (16) The placing on the market, putting  into service or use of certain AI systems  intended to distort human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  Such AI systems deploy subliminal  components individuals cannot perceive or  exploit vulnerabilities of children and  people due to their age, physical or mental  incapacities. They do so with the intention  to materially distort the behaviour of a  person and in a manner that causes or is  likely to cause harm to that or another  person. The intention may not be presumed  if the distortion of human behaviour  results from factors external to the AI  system which are outside of the control of  the provider or the user. Research for  legitimate purposes in relation to such AI  systems should not be stifled by the  prohibition, if such research does not  amount to use of the AI system in human- machine relations that exposes natural  persons to harm and such research is  carried out in accordance with recognised  ethical standards for scientific research.(16) The placing on the market, putting  into service or use of certain AI systems  with the objective to or the effect of  materially distorting human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  This limitation should be understood to  include neuro-technologies assisted by AI  systems that are used to monitor, use, or  influence neural data gathered through  brain-computer interfaces insofar as they  are materially distorting the behaviour of  a natural person in a manner that causes  or is likely to cause that person or another  person significant harm. Such AI systems  deploy subliminal components individuals  cannot perceive or exploit vulnerabilities of  individuals and specific groups of persons  due to their known or predicted  personality traits, age, physical or mental  incapacities, social or economic situation.  They do so with the intention to or the  effect of materially distorting the  behaviour of a person and in a manner that  causes or is likely to cause significant  harm to that or another person or groups of  persons, including harms that may be  accumulated over time. The intention to  distort the behaviour may not be presumed  if the distortion results from factors  external to the AI system which are outside  of the control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated by the  provider or the deployer of the AI system",What is the purpose of Recital 16 of the proposed regulation?,"['To prohibit the use of AI systems that can cause physical or psychological harm.', 'To encourage the development of AI systems that can manipulate human behavior.', 'To establish a risk-based approach for the regulation of AI systems.', 'To protect the rights of children and individuals with mental or physical incapacities.']",0
EU_AI_Act.pdf,"(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  unacceptable artificial intelligence  practices, to lay down requirements for  high-risk AI systems and obligations for  the relevant operators, and to lay down  transparency obligations for certain AI  systems Amendment 37 Proposal for a regulation Recital 15 Text proposed by the Commission Amendment (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  should be prohibited because they  contradict Union values of respect for  human dignity, freedom, equality, (15) Aside from the many beneficial uses  of artificial intelligence, that technology  can also be misused and provide novel and  powerful tools for manipulative,  exploitative and social control practices.  Such practices are particularly harmful and  abusive and should be prohibited because  they contradict Union values of respect for  human dignity, freedom, equality, democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child.democracy and the rule of law and Union  fundamental rights, including the right to  non-discrimination, data protection and  privacy and the rights of the child. Amendment 38 Proposal for a regulation Recital 16 Text proposed by the Commission Amendment (16) The placing on the market, putting  into service or use of certain AI systems  intended to distort human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  Such AI systems deploy subliminal  components individuals cannot perceive or  exploit vulnerabilities of children and  people due to their age, physical or mental  incapacities. They do so with the intention  to materially distort the behaviour of a  person and in a manner that causes or is  likely to cause harm to that or another  person. The intention may not be presumed  if the distortion of human behaviour  results from factors external to the AI  system which are outside of the control of  the provider or the user. Research for  legitimate purposes in relation to such AI  systems should not be stifled by the  prohibition, if such research does not  amount to use of the AI system in human- machine relations that exposes natural  persons to harm and such research is  carried out in accordance with recognised  ethical standards for scientific research.(16) The placing on the market, putting  into service or use of certain AI systems  with the objective to or the effect of  materially distorting human behaviour,  whereby physical or psychological harms  are likely to occur, should be forbidden.  This limitation should be understood to  include neuro-technologies assisted by AI  systems that are used to monitor, use, or  influence neural data gathered through  brain-computer interfaces insofar as they  are materially distorting the behaviour of  a natural person in a manner that causes  or is likely to cause that person or another  person significant harm. Such AI systems  deploy subliminal components individuals  cannot perceive or exploit vulnerabilities of  individuals and specific groups of persons  due to their known or predicted  personality traits, age, physical or mental  incapacities, social or economic situation.  They do so with the intention to or the  effect of materially distorting the  behaviour of a person and in a manner that  causes or is likely to cause significant  harm to that or another person or groups of  persons, including harms that may be  accumulated over time. The intention to  distort the behaviour may not be presumed  if the distortion results from factors  external to the AI system which are outside  of the control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated by the  provider or the deployer of the AI system","What are some of the factors that may not be presumed to distort human behavior, according to Recital 16?","['Subliminal components that individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities.', 'Factors external to the AI system which are outside of the control of the provider or the user, such as factors that may not be reasonably foreseen and mitigated by the provider or the deployer of the AI system.', 'Neural data gathered through brain-computer interfaces insofar as they are materially distorting the behavior of a natural person in a manner that causes or is likely to cause that person or another person significant harm.', 'Intention to distort the behavior of a person and in a manner that causes or is likely to cause significant harm to that or another person or groups of persons.']",1
EU_AI_Act.pdf,"deleted Amendment 159 Proposal for a regulation Article 2 – paragraph 4 Text proposed by the Commission Amendment 4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international agreements for  law enforcement and judicial cooperation  with the Union or with one or more  Member States.4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international cooperation or  agreements for law enforcement and  judicial cooperation with the Union or with  one or more Member States and are  subject of a decision of the Commission  adopted in accordance with Article 36 of  Directive (EU)2016/680 or Article 45 of  Regulation 2016/679 (adequacy decision)  or are part of an international agreement  concluded between the Union and that  third country or international  organisation pursuant to Article 218  TFUE providing adequate safeguards  with respect to the protection of privacy  and fundamental rights and freedoms of  individuals; Amendment 160 Proposal for a regulation Article 2 – paragraph 5 a (new) Text proposed by the Commission Amendment 5a. Union law on the protection of  personal data, privacy and the  confidentiality of communications applies  to personal data processes in connection with the rights and obligations laid down  in this Regulation. This Regulation shall  not affect Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directives  2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in  Article 10(5) and Article 54 of this  Regulation.; Amendment 161 Proposal for a regulation Article 2 – paragraph 5 b (new) Text proposed by the Commission Amendment 5b. This Regulation is without prejudice  to the rules laid down by other Union  legal acts related to consumer protection  and product safety; Amendment 162 Proposal for a regulation Article 2 – paragraph 5 c (new) Text proposed by the Commission Amendment 5c. This regulation shall not preclude  Member States or the Union from  maintaining or introducing laws,  regulations or administrative provisions  which are more favourable to workers in  terms of protecting their rights in respect  of the use of AI systems by employers, or  to encourage or allow the application of  collective agreements which are more  favourable to workers. Amendment 163 Proposal for a regulation Article 2 – paragraph 5 d (new)Text proposed by the Commission Amendment 5d. This Regulation shall not apply to  research, testing and development  activities regarding an AI system prior to  this system being placed on the market or  put into service, provided that these  activities are conducted respecting  fundamental rights and the applicable  Union law. The testing in real world  conditions shall not be covered by this  exemption.The Commission is empowered  to may adopt delegated acts in accordance  with Article 73 that clarify the application  of this paragraph to specify this  exemption to prevent its existing and  potential abuse. The AI Office shall  provide guidance on the governance of  research and development pursuant to  Article 56, also aiming to coordinate its  application by the national supervisory  authorities; Amendment 164 Proposal for a regulation Article 2 – paragraph 5 e (new) Text proposed by the Commission Amendment 5e. This Regulation shall not apply to  AI components provided under free and  open-source licences except to the extent  they are placed on the market or put into  service by a provider as part of a high-risk  AI system or of an AI system that falls  under Title II or IV. This exemption shall  not apply to foundation models as defined  in Art 3",What is the purpose of the proposed Regulation?,"['To regulate the use of AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States.', 'To establish adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals in the use of AI systems.', 'To maintain or introduce laws, regulations, or administrative provisions which are more favourable to workers in terms of protecting their rights in respect of the use of AI systems by employers.', 'To regulate research, testing, and development activities regarding an AI system prior to this system being placed on the market or put into service.']",1
EU_AI_Act.pdf,"deleted Amendment 159 Proposal for a regulation Article 2 – paragraph 4 Text proposed by the Commission Amendment 4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international agreements for  law enforcement and judicial cooperation  with the Union or with one or more  Member States.4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international cooperation or  agreements for law enforcement and  judicial cooperation with the Union or with  one or more Member States and are  subject of a decision of the Commission  adopted in accordance with Article 36 of  Directive (EU)2016/680 or Article 45 of  Regulation 2016/679 (adequacy decision)  or are part of an international agreement  concluded between the Union and that  third country or international  organisation pursuant to Article 218  TFUE providing adequate safeguards  with respect to the protection of privacy  and fundamental rights and freedoms of  individuals; Amendment 160 Proposal for a regulation Article 2 – paragraph 5 a (new) Text proposed by the Commission Amendment 5a. Union law on the protection of  personal data, privacy and the  confidentiality of communications applies  to personal data processes in connection with the rights and obligations laid down  in this Regulation. This Regulation shall  not affect Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directives  2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in  Article 10(5) and Article 54 of this  Regulation.; Amendment 161 Proposal for a regulation Article 2 – paragraph 5 b (new) Text proposed by the Commission Amendment 5b. This Regulation is without prejudice  to the rules laid down by other Union  legal acts related to consumer protection  and product safety; Amendment 162 Proposal for a regulation Article 2 – paragraph 5 c (new) Text proposed by the Commission Amendment 5c. This regulation shall not preclude  Member States or the Union from  maintaining or introducing laws,  regulations or administrative provisions  which are more favourable to workers in  terms of protecting their rights in respect  of the use of AI systems by employers, or  to encourage or allow the application of  collective agreements which are more  favourable to workers. Amendment 163 Proposal for a regulation Article 2 – paragraph 5 d (new)Text proposed by the Commission Amendment 5d. This Regulation shall not apply to  research, testing and development  activities regarding an AI system prior to  this system being placed on the market or  put into service, provided that these  activities are conducted respecting  fundamental rights and the applicable  Union law. The testing in real world  conditions shall not be covered by this  exemption.The Commission is empowered  to may adopt delegated acts in accordance  with Article 73 that clarify the application  of this paragraph to specify this  exemption to prevent its existing and  potential abuse. The AI Office shall  provide guidance on the governance of  research and development pursuant to  Article 56, also aiming to coordinate its  application by the national supervisory  authorities; Amendment 164 Proposal for a regulation Article 2 – paragraph 5 e (new) Text proposed by the Commission Amendment 5e. This Regulation shall not apply to  AI components provided under free and  open-source licences except to the extent  they are placed on the market or put into  service by a provider as part of a high-risk  AI system or of an AI system that falls  under Title II or IV. This exemption shall  not apply to foundation models as defined  in Art 3",What is the scope of the proposed Regulation?,"['It applies to all AI systems used by public authorities in third countries and international organizations.', 'It applies to all AI systems used by public authorities in third countries and international organizations, except those that use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States.', 'It applies to all AI systems used by public authorities in third countries and international organizations, except those subject to a decision of the Commission adopted in accordance with Article 36 of Directive (EU) 2016/680 or Article 45 of Regulation 2016/679 (adequacy decision) or part of an international agreement concluded between the Union and that third country or international organization pursuant to Article 218 TFUE providing adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals.', 'It applies to all AI systems used by public authorities in third countries and international organizations, except those that are part of an international agreement concluded between the Union and that third country or international organization pursuant to Article 218 TFUE providing adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals.']",2
EU_AI_Act.pdf,"deleted Amendment 159 Proposal for a regulation Article 2 – paragraph 4 Text proposed by the Commission Amendment 4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international agreements for  law enforcement and judicial cooperation  with the Union or with one or more  Member States.4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international cooperation or  agreements for law enforcement and  judicial cooperation with the Union or with  one or more Member States and are  subject of a decision of the Commission  adopted in accordance with Article 36 of  Directive (EU)2016/680 or Article 45 of  Regulation 2016/679 (adequacy decision)  or are part of an international agreement  concluded between the Union and that  third country or international  organisation pursuant to Article 218  TFUE providing adequate safeguards  with respect to the protection of privacy  and fundamental rights and freedoms of  individuals; Amendment 160 Proposal for a regulation Article 2 – paragraph 5 a (new) Text proposed by the Commission Amendment 5a. Union law on the protection of  personal data, privacy and the  confidentiality of communications applies  to personal data processes in connection with the rights and obligations laid down  in this Regulation. This Regulation shall  not affect Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directives  2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in  Article 10(5) and Article 54 of this  Regulation.; Amendment 161 Proposal for a regulation Article 2 – paragraph 5 b (new) Text proposed by the Commission Amendment 5b. This Regulation is without prejudice  to the rules laid down by other Union  legal acts related to consumer protection  and product safety; Amendment 162 Proposal for a regulation Article 2 – paragraph 5 c (new) Text proposed by the Commission Amendment 5c. This regulation shall not preclude  Member States or the Union from  maintaining or introducing laws,  regulations or administrative provisions  which are more favourable to workers in  terms of protecting their rights in respect  of the use of AI systems by employers, or  to encourage or allow the application of  collective agreements which are more  favourable to workers. Amendment 163 Proposal for a regulation Article 2 – paragraph 5 d (new)Text proposed by the Commission Amendment 5d. This Regulation shall not apply to  research, testing and development  activities regarding an AI system prior to  this system being placed on the market or  put into service, provided that these  activities are conducted respecting  fundamental rights and the applicable  Union law. The testing in real world  conditions shall not be covered by this  exemption.The Commission is empowered  to may adopt delegated acts in accordance  with Article 73 that clarify the application  of this paragraph to specify this  exemption to prevent its existing and  potential abuse. The AI Office shall  provide guidance on the governance of  research and development pursuant to  Article 56, also aiming to coordinate its  application by the national supervisory  authorities; Amendment 164 Proposal for a regulation Article 2 – paragraph 5 e (new) Text proposed by the Commission Amendment 5e. This Regulation shall not apply to  AI components provided under free and  open-source licences except to the extent  they are placed on the market or put into  service by a provider as part of a high-risk  AI system or of an AI system that falls  under Title II or IV. This exemption shall  not apply to foundation models as defined  in Art 3",Are there any exceptions to the scope of the proposed Regulation?,"['Yes, there are exceptions to the scope of the proposed Regulation.', 'No, there are no exceptions to the scope of the proposed Regulation.', 'The proposed Regulation does not provide any exceptions to its scope.', 'The Regulation applies to all AI systems, including those used by public authorities and international organizations.']",0
EU_AI_Act.pdf,"deleted Amendment 159 Proposal for a regulation Article 2 – paragraph 4 Text proposed by the Commission Amendment 4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international agreements for  law enforcement and judicial cooperation  with the Union or with one or more  Member States.4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international cooperation or  agreements for law enforcement and  judicial cooperation with the Union or with  one or more Member States and are  subject of a decision of the Commission  adopted in accordance with Article 36 of  Directive (EU)2016/680 or Article 45 of  Regulation 2016/679 (adequacy decision)  or are part of an international agreement  concluded between the Union and that  third country or international  organisation pursuant to Article 218  TFUE providing adequate safeguards  with respect to the protection of privacy  and fundamental rights and freedoms of  individuals; Amendment 160 Proposal for a regulation Article 2 – paragraph 5 a (new) Text proposed by the Commission Amendment 5a. Union law on the protection of  personal data, privacy and the  confidentiality of communications applies  to personal data processes in connection with the rights and obligations laid down  in this Regulation. This Regulation shall  not affect Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directives  2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in  Article 10(5) and Article 54 of this  Regulation.; Amendment 161 Proposal for a regulation Article 2 – paragraph 5 b (new) Text proposed by the Commission Amendment 5b. This Regulation is without prejudice  to the rules laid down by other Union  legal acts related to consumer protection  and product safety; Amendment 162 Proposal for a regulation Article 2 – paragraph 5 c (new) Text proposed by the Commission Amendment 5c. This regulation shall not preclude  Member States or the Union from  maintaining or introducing laws,  regulations or administrative provisions  which are more favourable to workers in  terms of protecting their rights in respect  of the use of AI systems by employers, or  to encourage or allow the application of  collective agreements which are more  favourable to workers. Amendment 163 Proposal for a regulation Article 2 – paragraph 5 d (new)Text proposed by the Commission Amendment 5d. This Regulation shall not apply to  research, testing and development  activities regarding an AI system prior to  this system being placed on the market or  put into service, provided that these  activities are conducted respecting  fundamental rights and the applicable  Union law. The testing in real world  conditions shall not be covered by this  exemption.The Commission is empowered  to may adopt delegated acts in accordance  with Article 73 that clarify the application  of this paragraph to specify this  exemption to prevent its existing and  potential abuse. The AI Office shall  provide guidance on the governance of  research and development pursuant to  Article 56, also aiming to coordinate its  application by the national supervisory  authorities; Amendment 164 Proposal for a regulation Article 2 – paragraph 5 e (new) Text proposed by the Commission Amendment 5e. This Regulation shall not apply to  AI components provided under free and  open-source licences except to the extent  they are placed on the market or put into  service by a provider as part of a high-risk  AI system or of an AI system that falls  under Title II or IV. This exemption shall  not apply to foundation models as defined  in Art 3",What is the role of the Commission in the proposed Regulation?,"['The Commission is empowered to adopt delegated acts in accordance with Article 73 to clarify the application of paragraph 5d of Article 2 to specify this exemption to prevent its existing and potential abuse.', 'The Commission has the authority to maintain or introduce laws, regulations, or administrative provisions that are more favourable to workers in terms of protecting their rights in respect of the use of AI systems by employers.', 'The Commission is responsible for ensuring that international organisations falling within the scope of this Regulation pursuant to paragraph 1 use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States.', 'The Commission shall provide guidance on the governance of research and development pursuant to Article 56, also aiming to coordinate its application by the national supervisory authorities.']",0
EU_AI_Act.pdf,"deleted Amendment 159 Proposal for a regulation Article 2 – paragraph 4 Text proposed by the Commission Amendment 4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international agreements for  law enforcement and judicial cooperation  with the Union or with one or more  Member States.4. This Regulation shall not apply to  public authorities in a third country nor to  international organisations falling within  the scope of this Regulation pursuant to  paragraph 1, where those authorities or  organisations use AI systems in the  framework of international cooperation or  agreements for law enforcement and  judicial cooperation with the Union or with  one or more Member States and are  subject of a decision of the Commission  adopted in accordance with Article 36 of  Directive (EU)2016/680 or Article 45 of  Regulation 2016/679 (adequacy decision)  or are part of an international agreement  concluded between the Union and that  third country or international  organisation pursuant to Article 218  TFUE providing adequate safeguards  with respect to the protection of privacy  and fundamental rights and freedoms of  individuals; Amendment 160 Proposal for a regulation Article 2 – paragraph 5 a (new) Text proposed by the Commission Amendment 5a. Union law on the protection of  personal data, privacy and the  confidentiality of communications applies  to personal data processes in connection with the rights and obligations laid down  in this Regulation. This Regulation shall  not affect Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directives  2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in  Article 10(5) and Article 54 of this  Regulation.; Amendment 161 Proposal for a regulation Article 2 – paragraph 5 b (new) Text proposed by the Commission Amendment 5b. This Regulation is without prejudice  to the rules laid down by other Union  legal acts related to consumer protection  and product safety; Amendment 162 Proposal for a regulation Article 2 – paragraph 5 c (new) Text proposed by the Commission Amendment 5c. This regulation shall not preclude  Member States or the Union from  maintaining or introducing laws,  regulations or administrative provisions  which are more favourable to workers in  terms of protecting their rights in respect  of the use of AI systems by employers, or  to encourage or allow the application of  collective agreements which are more  favourable to workers. Amendment 163 Proposal for a regulation Article 2 – paragraph 5 d (new)Text proposed by the Commission Amendment 5d. This Regulation shall not apply to  research, testing and development  activities regarding an AI system prior to  this system being placed on the market or  put into service, provided that these  activities are conducted respecting  fundamental rights and the applicable  Union law. The testing in real world  conditions shall not be covered by this  exemption.The Commission is empowered  to may adopt delegated acts in accordance  with Article 73 that clarify the application  of this paragraph to specify this  exemption to prevent its existing and  potential abuse. The AI Office shall  provide guidance on the governance of  research and development pursuant to  Article 56, also aiming to coordinate its  application by the national supervisory  authorities; Amendment 164 Proposal for a regulation Article 2 – paragraph 5 e (new) Text proposed by the Commission Amendment 5e. This Regulation shall not apply to  AI components provided under free and  open-source licences except to the extent  they are placed on the market or put into  service by a provider as part of a high-risk  AI system or of an AI system that falls  under Title II or IV. This exemption shall  not apply to foundation models as defined  in Art 3",How does the proposed Regulation relate to other Union legal acts related to consumer protection and product safety?,"['This Regulation is without prejudice to the rules laid down by other Union legal acts related to consumer protection and product safety.', 'This Regulation shall not apply to research, testing, and development activities regarding an AI system prior to being placed on the market or put into service, provided that these activities are conducted respecting fundamental rights and applicable Union law.', 'This Regulation shall not affect Regulations (EU) 2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation.', 'This Regulation shall not apply to AI components provided under free and open-source licenses except to the extent they are placed on the market or put into service by a provider as part of a high-risk AI system or of an AI system that falls under Title II or IV.']",0
EU_AI_Act.pdf,"varying levels of autonomy, meaning that  they have at least some degree of  independence of actions from human  controls and of capabilities to operate  without human intervention. The term  “machine-based” refers to the fact that AI  systems run on machines. The reference  to explicit or implicit objectives  underscores that AI systems can operate  according to explicit human-defined  objectives or to implicit objectives. The  objectives of the AI system may be  different from the intended purpose of the  AI system in a specific context. The  reference to predictions includes content,  which is considered in this Regulation a  form of prediction as one of the possible  outputs produced by an AI system. For  the purposes of this Regulation,  environments should be understood as the  contexts in which the AI systems operate,  whereas outputs generated by the AI  system, meaning predictions,  recommendations or decisions, respond to  the objectives of the system, on the basis  of inputs from said environment. Such  output further influences said  environment, even by merely introducing  new information to it.  Amendment 19 Proposal for a regulation Recital 6 a (new) Text proposed by the Commission Amendment (6a) AI systems often have machine  learning capacities that allow them to  adapt and perform new tasks  autonomously. Machine learning refers to  the computational process of optimizing  the parameters of a model from data,  which is a mathematical construct  generating an output based on input data.  Machine learning approaches include, for  instance, supervised, unsupervised and  reinforcement learning, using a variety of  methods including deep learning with neural networks. This Regulation is  aimed at addressing new potential risks  that may arise by delegating control to AI  systems, in particular to those AI systems  that can evolve after deployment. The  function and outputs of many of these AI  systems are based on abstract  mathematical relationships that are  difficult for humans to understand,  monitor and trace back to specific inputs.  These complex and opaque characteristics   (black box element) impact accountability  and explainability. Comparably simpler  techniques such as knowledge-based  approaches, Bayesian estimation or  decision-trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they are  used in combination with machine  learning approaches in hybrid systems. Amendment 20 Proposal for a regulation Recital 6 b (new) Text proposed by the Commission Amendment (6b) AI systems can be used as stand- alone software system, integrated into a  physical product (embedded), used to  serve the functionality of a physical  product without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If this  larger system would not function without  the AI component in question, then the  entire larger system should be considered  as one single AI system under this  Regulation. Amendment 21 Proposal for a regulation Recital 7Text proposed by the Commission Amendment (7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35 ,  Article 3(18) of Regulation (EU)  2018/1725 of the European Parliament  and of the Council36 and Article 3(13) of  Directive (EU) 2016/680 of the European  Parliament and of the Council37 .(7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35.  Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person",What is the main purpose of the proposed Regulation?,"['To regulate the use of AI systems with varying levels of autonomy.', 'To define the notion of biometric data used in this Regulation.', 'To address new potential risks that may arise by delegating control to AI systems.', 'To provide a framework for the development and deployment of AI systems.']",2
EU_AI_Act.pdf,"varying levels of autonomy, meaning that  they have at least some degree of  independence of actions from human  controls and of capabilities to operate  without human intervention. The term  “machine-based” refers to the fact that AI  systems run on machines. The reference  to explicit or implicit objectives  underscores that AI systems can operate  according to explicit human-defined  objectives or to implicit objectives. The  objectives of the AI system may be  different from the intended purpose of the  AI system in a specific context. The  reference to predictions includes content,  which is considered in this Regulation a  form of prediction as one of the possible  outputs produced by an AI system. For  the purposes of this Regulation,  environments should be understood as the  contexts in which the AI systems operate,  whereas outputs generated by the AI  system, meaning predictions,  recommendations or decisions, respond to  the objectives of the system, on the basis  of inputs from said environment. Such  output further influences said  environment, even by merely introducing  new information to it.  Amendment 19 Proposal for a regulation Recital 6 a (new) Text proposed by the Commission Amendment (6a) AI systems often have machine  learning capacities that allow them to  adapt and perform new tasks  autonomously. Machine learning refers to  the computational process of optimizing  the parameters of a model from data,  which is a mathematical construct  generating an output based on input data.  Machine learning approaches include, for  instance, supervised, unsupervised and  reinforcement learning, using a variety of  methods including deep learning with neural networks. This Regulation is  aimed at addressing new potential risks  that may arise by delegating control to AI  systems, in particular to those AI systems  that can evolve after deployment. The  function and outputs of many of these AI  systems are based on abstract  mathematical relationships that are  difficult for humans to understand,  monitor and trace back to specific inputs.  These complex and opaque characteristics   (black box element) impact accountability  and explainability. Comparably simpler  techniques such as knowledge-based  approaches, Bayesian estimation or  decision-trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they are  used in combination with machine  learning approaches in hybrid systems. Amendment 20 Proposal for a regulation Recital 6 b (new) Text proposed by the Commission Amendment (6b) AI systems can be used as stand- alone software system, integrated into a  physical product (embedded), used to  serve the functionality of a physical  product without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If this  larger system would not function without  the AI component in question, then the  entire larger system should be considered  as one single AI system under this  Regulation. Amendment 21 Proposal for a regulation Recital 7Text proposed by the Commission Amendment (7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35 ,  Article 3(18) of Regulation (EU)  2018/1725 of the European Parliament  and of the Council36 and Article 3(13) of  Directive (EU) 2016/680 of the European  Parliament and of the Council37 .(7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35.  Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person","What is the meaning of ""black box element"" in the context of AI systems?","['A component of an AI system that is not accessible or understandable by humans.', 'A part of an AI system that is transparent and easily understandable by humans.', ""AI system's ability to adapt and perform new tasks autonomously."", ""AI system's reliance on explicit human-defined objectives.""]",0
EU_AI_Act.pdf,"varying levels of autonomy, meaning that  they have at least some degree of  independence of actions from human  controls and of capabilities to operate  without human intervention. The term  “machine-based” refers to the fact that AI  systems run on machines. The reference  to explicit or implicit objectives  underscores that AI systems can operate  according to explicit human-defined  objectives or to implicit objectives. The  objectives of the AI system may be  different from the intended purpose of the  AI system in a specific context. The  reference to predictions includes content,  which is considered in this Regulation a  form of prediction as one of the possible  outputs produced by an AI system. For  the purposes of this Regulation,  environments should be understood as the  contexts in which the AI systems operate,  whereas outputs generated by the AI  system, meaning predictions,  recommendations or decisions, respond to  the objectives of the system, on the basis  of inputs from said environment. Such  output further influences said  environment, even by merely introducing  new information to it.  Amendment 19 Proposal for a regulation Recital 6 a (new) Text proposed by the Commission Amendment (6a) AI systems often have machine  learning capacities that allow them to  adapt and perform new tasks  autonomously. Machine learning refers to  the computational process of optimizing  the parameters of a model from data,  which is a mathematical construct  generating an output based on input data.  Machine learning approaches include, for  instance, supervised, unsupervised and  reinforcement learning, using a variety of  methods including deep learning with neural networks. This Regulation is  aimed at addressing new potential risks  that may arise by delegating control to AI  systems, in particular to those AI systems  that can evolve after deployment. The  function and outputs of many of these AI  systems are based on abstract  mathematical relationships that are  difficult for humans to understand,  monitor and trace back to specific inputs.  These complex and opaque characteristics   (black box element) impact accountability  and explainability. Comparably simpler  techniques such as knowledge-based  approaches, Bayesian estimation or  decision-trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they are  used in combination with machine  learning approaches in hybrid systems. Amendment 20 Proposal for a regulation Recital 6 b (new) Text proposed by the Commission Amendment (6b) AI systems can be used as stand- alone software system, integrated into a  physical product (embedded), used to  serve the functionality of a physical  product without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If this  larger system would not function without  the AI component in question, then the  entire larger system should be considered  as one single AI system under this  Regulation. Amendment 21 Proposal for a regulation Recital 7Text proposed by the Commission Amendment (7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35 ,  Article 3(18) of Regulation (EU)  2018/1725 of the European Parliament  and of the Council36 and Article 3(13) of  Directive (EU) 2016/680 of the European  Parliament and of the Council37 .(7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35.  Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person",What is the purpose of Recital 6a of the proposed Regulation?,"['To define the term ""machine-based"" as it relates to AI systems.', 'To explain the concept of biometric data as it relates to AI systems.', 'To describe the different types of AI systems, including stand-alone software, embedded, non-embedded, and hybrid systems.', 'To address new potential risks that may arise by delegating control to AI systems, in particular to those AI systems that can evolve after deployment.']",3
EU_AI_Act.pdf,"varying levels of autonomy, meaning that  they have at least some degree of  independence of actions from human  controls and of capabilities to operate  without human intervention. The term  “machine-based” refers to the fact that AI  systems run on machines. The reference  to explicit or implicit objectives  underscores that AI systems can operate  according to explicit human-defined  objectives or to implicit objectives. The  objectives of the AI system may be  different from the intended purpose of the  AI system in a specific context. The  reference to predictions includes content,  which is considered in this Regulation a  form of prediction as one of the possible  outputs produced by an AI system. For  the purposes of this Regulation,  environments should be understood as the  contexts in which the AI systems operate,  whereas outputs generated by the AI  system, meaning predictions,  recommendations or decisions, respond to  the objectives of the system, on the basis  of inputs from said environment. Such  output further influences said  environment, even by merely introducing  new information to it.  Amendment 19 Proposal for a regulation Recital 6 a (new) Text proposed by the Commission Amendment (6a) AI systems often have machine  learning capacities that allow them to  adapt and perform new tasks  autonomously. Machine learning refers to  the computational process of optimizing  the parameters of a model from data,  which is a mathematical construct  generating an output based on input data.  Machine learning approaches include, for  instance, supervised, unsupervised and  reinforcement learning, using a variety of  methods including deep learning with neural networks. This Regulation is  aimed at addressing new potential risks  that may arise by delegating control to AI  systems, in particular to those AI systems  that can evolve after deployment. The  function and outputs of many of these AI  systems are based on abstract  mathematical relationships that are  difficult for humans to understand,  monitor and trace back to specific inputs.  These complex and opaque characteristics   (black box element) impact accountability  and explainability. Comparably simpler  techniques such as knowledge-based  approaches, Bayesian estimation or  decision-trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they are  used in combination with machine  learning approaches in hybrid systems. Amendment 20 Proposal for a regulation Recital 6 b (new) Text proposed by the Commission Amendment (6b) AI systems can be used as stand- alone software system, integrated into a  physical product (embedded), used to  serve the functionality of a physical  product without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If this  larger system would not function without  the AI component in question, then the  entire larger system should be considered  as one single AI system under this  Regulation. Amendment 21 Proposal for a regulation Recital 7Text proposed by the Commission Amendment (7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35 ,  Article 3(18) of Regulation (EU)  2018/1725 of the European Parliament  and of the Council36 and Article 3(13) of  Directive (EU) 2016/680 of the European  Parliament and of the Council37 .(7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35.  Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person",What is the relationship between the proposed Regulation and the General Data Protection Regulation (GDPR)?,"['The proposed Regulation is a supplement to the GDPR, providing additional guidelines for AI systems that process personal data.', 'The proposed Regulation is a replacement for the GDPR, superseding its provisions for AI systems.', 'The proposed Regulation and the GDPR are separate regulations that apply to different aspects of AI systems.', 'The proposed Regulation is a clarification of the GDPR, providing further guidance on the application of data protection principles to AI systems.']",2
EU_AI_Act.pdf,"varying levels of autonomy, meaning that  they have at least some degree of  independence of actions from human  controls and of capabilities to operate  without human intervention. The term  “machine-based” refers to the fact that AI  systems run on machines. The reference  to explicit or implicit objectives  underscores that AI systems can operate  according to explicit human-defined  objectives or to implicit objectives. The  objectives of the AI system may be  different from the intended purpose of the  AI system in a specific context. The  reference to predictions includes content,  which is considered in this Regulation a  form of prediction as one of the possible  outputs produced by an AI system. For  the purposes of this Regulation,  environments should be understood as the  contexts in which the AI systems operate,  whereas outputs generated by the AI  system, meaning predictions,  recommendations or decisions, respond to  the objectives of the system, on the basis  of inputs from said environment. Such  output further influences said  environment, even by merely introducing  new information to it.  Amendment 19 Proposal for a regulation Recital 6 a (new) Text proposed by the Commission Amendment (6a) AI systems often have machine  learning capacities that allow them to  adapt and perform new tasks  autonomously. Machine learning refers to  the computational process of optimizing  the parameters of a model from data,  which is a mathematical construct  generating an output based on input data.  Machine learning approaches include, for  instance, supervised, unsupervised and  reinforcement learning, using a variety of  methods including deep learning with neural networks. This Regulation is  aimed at addressing new potential risks  that may arise by delegating control to AI  systems, in particular to those AI systems  that can evolve after deployment. The  function and outputs of many of these AI  systems are based on abstract  mathematical relationships that are  difficult for humans to understand,  monitor and trace back to specific inputs.  These complex and opaque characteristics   (black box element) impact accountability  and explainability. Comparably simpler  techniques such as knowledge-based  approaches, Bayesian estimation or  decision-trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they are  used in combination with machine  learning approaches in hybrid systems. Amendment 20 Proposal for a regulation Recital 6 b (new) Text proposed by the Commission Amendment (6b) AI systems can be used as stand- alone software system, integrated into a  physical product (embedded), used to  serve the functionality of a physical  product without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If this  larger system would not function without  the AI component in question, then the  entire larger system should be considered  as one single AI system under this  Regulation. Amendment 21 Proposal for a regulation Recital 7Text proposed by the Commission Amendment (7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35 ,  Article 3(18) of Regulation (EU)  2018/1725 of the European Parliament  and of the Council36 and Article 3(13) of  Directive (EU) 2016/680 of the European  Parliament and of the Council37 .(7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35.  Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person",What is the purpose of Recital 7 of the proposed Regulation?,"['To define the notion of biometric data used in the Regulation.', 'To explain the concept of machine learning and its relevance to AI systems.', 'To describe the different types of AI systems and their capabilities.', 'To outline the potential risks associated with the use of AI systems and the need for regulation.']",0
EU_AI_Act.pdf,"varying levels of autonomy, meaning that  they have at least some degree of  independence of actions from human  controls and of capabilities to operate  without human intervention. The term  “machine-based” refers to the fact that AI  systems run on machines. The reference  to explicit or implicit objectives  underscores that AI systems can operate  according to explicit human-defined  objectives or to implicit objectives. The  objectives of the AI system may be  different from the intended purpose of the  AI system in a specific context. The  reference to predictions includes content,  which is considered in this Regulation a  form of prediction as one of the possible  outputs produced by an AI system. For  the purposes of this Regulation,  environments should be understood as the  contexts in which the AI systems operate,  whereas outputs generated by the AI  system, meaning predictions,  recommendations or decisions, respond to  the objectives of the system, on the basis  of inputs from said environment. Such  output further influences said  environment, even by merely introducing  new information to it.  Amendment 19 Proposal for a regulation Recital 6 a (new) Text proposed by the Commission Amendment (6a) AI systems often have machine  learning capacities that allow them to  adapt and perform new tasks  autonomously. Machine learning refers to  the computational process of optimizing  the parameters of a model from data,  which is a mathematical construct  generating an output based on input data.  Machine learning approaches include, for  instance, supervised, unsupervised and  reinforcement learning, using a variety of  methods including deep learning with neural networks. This Regulation is  aimed at addressing new potential risks  that may arise by delegating control to AI  systems, in particular to those AI systems  that can evolve after deployment. The  function and outputs of many of these AI  systems are based on abstract  mathematical relationships that are  difficult for humans to understand,  monitor and trace back to specific inputs.  These complex and opaque characteristics   (black box element) impact accountability  and explainability. Comparably simpler  techniques such as knowledge-based  approaches, Bayesian estimation or  decision-trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they are  used in combination with machine  learning approaches in hybrid systems. Amendment 20 Proposal for a regulation Recital 6 b (new) Text proposed by the Commission Amendment (6b) AI systems can be used as stand- alone software system, integrated into a  physical product (embedded), used to  serve the functionality of a physical  product without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If this  larger system would not function without  the AI component in question, then the  entire larger system should be considered  as one single AI system under this  Regulation. Amendment 21 Proposal for a regulation Recital 7Text proposed by the Commission Amendment (7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35 ,  Article 3(18) of Regulation (EU)  2018/1725 of the European Parliament  and of the Council36 and Article 3(13) of  Directive (EU) 2016/680 of the European  Parliament and of the Council37 .(7) The notion of biometric data used in  this Regulation is in line with and should  be interpreted consistently with the notion  of biometric data as defined in Article  4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council35.  Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person",What is the significance of Amendment 21 of the proposed Regulation?,"['It defines the notion of biometric data used in the Regulation and ensures consistency with other EU regulations.', 'It introduces the concept of machine learning and its applications in AI systems.', 'It outlines the requirements for AI systems to have varying levels of autonomy.', 'It explains the black box element in AI systems and its impact on accountability and explainability.']",0
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is biometric categorization?,"['Assigning natural persons to specific categories or inferring their characteristics and attributes such as gender, sex, age, hair color, eye color, tattoos, ethnic or social origin, health, mental or physical ability, behavioral or personality traits, language, religion, or membership of a national minority or sexual or political orientation on the basis of their biometric or biometric-based data, or which can be inferred from such data.', ""The automated recognition of physical, physiological, behavioral, and psychological human features such as the face, eye movement, facial expressions, body shape, voice, speech, gait, posture, heart rate, blood pressure, odor, keystrokes, psychological reactions (anger, distress, grief, etc.) for the purpose of establishing an individual's identity by comparing biometric data of that individual to stored biometric data of individuals in a database (one-to-many identification), irrespective of whether the individual has given its consent or not."", ""A system intended for the identification of natural persons at a distance through the comparison of a person's biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespective of the particular technology, processes or types of biometric data used."", ""The comparison of a person's biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespective of the particular technology, processes or types of biometric data used.""]",1
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is the purpose of the General Data Protection Regulation (GDPR)?,"['To regulate the processing of personal data and ensure the free movement of such data.', 'To establish a framework for the protection of natural persons with regard to the processing of personal data.', 'To provide individuals with control over their personal data and to ensure that organizations handle personal data responsibly.', 'To repeal Directive 95/46/EC (General Data Protection Regulation).']",2
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is the purpose of the proposal for a regulation Recital 7a?,"['To define the notion of biometric identification as used in the Regulation.', 'To establish the criteria for the processing of personal data for the purposes of the prevention, investigation, detection or prosecution of criminal offenses.', ""To distinguish between 'real-time' and 'post' remote biometric identification systems."", 'To assign natural persons to specific categories or infer their characteristics and attributes.']",0
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is the purpose of the proposal for a regulation Recital 7b?,"['To define the notion of biometric identification as used in the Regulation.', 'To assign natural persons to specific categories or infer their characteristics and attributes.', ""To establish an individual's identity by comparing biometric data to stored biometric data in a database."", 'To repeal Directive 95/46/EC (General Data Protection Regulation).']",1
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is the purpose of the amendment 22 proposal for a regulation?,"['To define the notion of biometric identification as used in the Regulation.', 'To establish the criteria for the processing of personal data for the purposes of the prevention, investigation, detection or prosecution of criminal offenses.', 'To provide a legal framework for the use of remote biometric identification systems.', 'To regulate the use of biometric data for the purpose of categorizing natural persons.']",0
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is the purpose of the amendment 23 proposal for a regulation?,"['To define the notion of biometric identification as used in the Regulation.', 'To assign natural persons to specific categories or infer their characteristics and attributes.', ""To establish an individual's identity by comparing biometric data to stored biometric data in a database."", ""To make a distinction between 'real-time' and 'post' remote biometric identification systems.""]",1
EU_AI_Act.pdf,"Biometrics-based data are additional data  resulting from specific technical  processing relating to physical,  physiological or behavioural signals of a  natural person, such as facial  expressions, movements, pulse frequency,  voice, key strikes or gait, which may or  may not allow or confirm the unique  identification of a natural person. __________________ __________________ 35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).35 Regulation (EU) 2016/679 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive  95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1). 36 Regulation (EU) 2018/1725 of the  European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the  processing of personal data by the Union  institutions, bodies, offices and agencies  and on the free movement of such data,  and repealing Regulation (EC) No  45/2001 and Decision No 1247/2002/EC  (OJ L 295, 21.11.2018, p. 39) 37 Directive (EU) 2016/680 of the  European Parliament and of the Council  of 27 April 2016 on the protection of  natural persons with regard to the  processing of personal data by competent  authorities for the purposes of the  prevention, investigation, detection or  prosecution of criminal offences or the  execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89). Amendment 22 Proposal for a regulation Recital 7 a (new) Text proposed by the Commission Amendment (7a)  The notion of biometric  identification as used in this Regulation  should be defined as the automated  recognition of physical, physiological,  behavioural, and psychological human  features such as the face, eye movement,  facial expressions, body shape, voice,  speech, gait, posture, heart rate, blood  pressure, odour, keystrokes, psychological  reactions (anger, distress, grief, etc.) for  the purpose of establishing an  individual’s identity by comparing  biometric data of that individual to stored  biometric data of individuals in a  database (one-to-many identification),  irrespective of whether the individual has  given its consent or not. Amendment 23 Proposal for a regulation Recital 7 b (new) Text proposed by the Commission Amendment (7b) The notion of biometric  categorisation as used in this Regulation  should be defined as assigning natural  persons to specific categories or inferring  their characteristics and attributes such as  gender, sex, age, hair colour, eye colour,  tattoos, ethnic or social origin, health,  mental or physical ability, behavioural or  personality, traits language, religion, or  membership of a national minority or  sexual or political orientation on the basis  of their biometric or biometric-based data,  or which can be inferred from such data.Amendment 24 Proposal for a regulation Recital 8 Text proposed by the Commission Amendment (8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used. Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay",What is the purpose of the amendment 24 proposal for a regulation?,"['To define the notion of biometric identification as used in the Regulation.', 'To establish the criteria for the use of remote biometric identification systems.', ""To distinguish between 'real-time' and 'post' remote biometric identification systems."", 'To assign natural persons to specific categories or infer their characteristics and attributes.']",2
EU_AI_Act.pdf,"Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay. In this regard,  there should be no scope for circumventing  the rules of this Regulation on the ‘real- time’ use of the AI systems in question by  providing for minor delays. ‘Real-time’  systems involve the use of ‘live’ or ‘near- ‘live’ material, such as video footage,  generated by a camera or other device with  similar functionality. In the case of ‘post’  systems, in contrast, the biometric data  have already been captured and the  comparison and identification occur only  after a significant delay. This involves  material, such as pictures or video footage  generated by closed circuit television  cameras or private devices, which has been  generated before the use of the system in  respect of the natural persons concerned.(8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used, exlcuding verification systems  which merely compare the biometric data  of an individual to their previously  provided biometric data (one-to-one).  Considering their different characteristics  and manners in which they are used, as  well as the different risks involved, a  distinction should be made between ‘real- time’ and ‘post’ remote biometric  identification systems. In the case of ‘real- time’ systems, the capturing of the  biometric data, the comparison and the  identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay. In this regard,  there should be no scope for circumventing  the rules of this Regulation on the ‘real- time’ use of the AI systems in question by  providing for minor delays. ‘Real-time’  systems involve the use of ‘live’ or ‘near- ‘live’ material, such as video footage,  generated by a camera or other device with  similar functionality. In the case of ‘post’  systems, in contrast, the biometric data  have already been captured and the  comparison and identification occur only  after a significant delay. This involves  material, such as pictures or video footage  generated by closed circuit television  cameras or private devices, which has been generated before the use of the system in  respect of the natural persons concerned.  Given that the notion of biometric  identification is independent from the  individual’s consent, this definition  applies even when warning notices are  placed in the location that is under  surveillance of the remote biometric  identification system, and is not de facto  annulled by pre-enrolment. Amendment 25 Proposal for a regulation Recital 8 a (new) Text proposed by the Commission Amendment (8a) The identification of natural  persons at a distance is understood to  distinguish remote biometric  identification systems from close  proximity individual verification systems  using biometric identification means,  whose sole purpose is to confirm whether  or not a specific natural person  presenting themselves for identification is  permitted, such as in order to gain access  to a service, a device, or premises. Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned",What is the main purpose of the Regulation mentioned in the text?,"['To regulate the use of remote biometric identification systems in real-time.', 'To distinguish between real-time and post remote biometric identification systems.', 'To regulate the use of biometric identification means for individual verification systems.', 'To define the notion of publicly accessible space for the purposes of the Regulation.']",1
EU_AI_Act.pdf,"Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay. In this regard,  there should be no scope for circumventing  the rules of this Regulation on the ‘real- time’ use of the AI systems in question by  providing for minor delays. ‘Real-time’  systems involve the use of ‘live’ or ‘near- ‘live’ material, such as video footage,  generated by a camera or other device with  similar functionality. In the case of ‘post’  systems, in contrast, the biometric data  have already been captured and the  comparison and identification occur only  after a significant delay. This involves  material, such as pictures or video footage  generated by closed circuit television  cameras or private devices, which has been  generated before the use of the system in  respect of the natural persons concerned.(8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used, exlcuding verification systems  which merely compare the biometric data  of an individual to their previously  provided biometric data (one-to-one).  Considering their different characteristics  and manners in which they are used, as  well as the different risks involved, a  distinction should be made between ‘real- time’ and ‘post’ remote biometric  identification systems. In the case of ‘real- time’ systems, the capturing of the  biometric data, the comparison and the  identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay. In this regard,  there should be no scope for circumventing  the rules of this Regulation on the ‘real- time’ use of the AI systems in question by  providing for minor delays. ‘Real-time’  systems involve the use of ‘live’ or ‘near- ‘live’ material, such as video footage,  generated by a camera or other device with  similar functionality. In the case of ‘post’  systems, in contrast, the biometric data  have already been captured and the  comparison and identification occur only  after a significant delay. This involves  material, such as pictures or video footage  generated by closed circuit television  cameras or private devices, which has been generated before the use of the system in  respect of the natural persons concerned.  Given that the notion of biometric  identification is independent from the  individual’s consent, this definition  applies even when warning notices are  placed in the location that is under  surveillance of the remote biometric  identification system, and is not de facto  annulled by pre-enrolment. Amendment 25 Proposal for a regulation Recital 8 a (new) Text proposed by the Commission Amendment (8a) The identification of natural  persons at a distance is understood to  distinguish remote biometric  identification systems from close  proximity individual verification systems  using biometric identification means,  whose sole purpose is to confirm whether  or not a specific natural person  presenting themselves for identification is  permitted, such as in order to gain access  to a service, a device, or premises. Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned",What is the purpose of Amendment 26 Proposal for a regulation Recital 9?,"['To define the term ""remote biometric identification system""', ""To distinguish between 'real-time' and 'post' remote biometric identification systems."", 'To establish the notion of publicly accessible space', 'To confirm whether a specific natural person is permitted to access a service, a device, or premises.']",2
EU_AI_Act.pdf,"Considering their different  characteristics and manners in which they  are used, as well as the different risks  involved, a distinction should be made  between ‘real-time’ and ‘post’ remote  biometric identification systems. In the  case of ‘real-time’ systems, the capturing  of the biometric data, the comparison and  the identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay. In this regard,  there should be no scope for circumventing  the rules of this Regulation on the ‘real- time’ use of the AI systems in question by  providing for minor delays. ‘Real-time’  systems involve the use of ‘live’ or ‘near- ‘live’ material, such as video footage,  generated by a camera or other device with  similar functionality. In the case of ‘post’  systems, in contrast, the biometric data  have already been captured and the  comparison and identification occur only  after a significant delay. This involves  material, such as pictures or video footage  generated by closed circuit television  cameras or private devices, which has been  generated before the use of the system in  respect of the natural persons concerned.(8) The notion of remote biometric  identification system as used in this  Regulation should be defined functionally,  as an AI system intended for the  identification of natural persons at a  distance through the comparison of a  person’s biometric data with the biometric  data contained in a reference database, and  without prior knowledge whether the  targeted person will be present and can be  identified, irrespectively of the particular  technology, processes or types of biometric  data used, exlcuding verification systems  which merely compare the biometric data  of an individual to their previously  provided biometric data (one-to-one).  Considering their different characteristics  and manners in which they are used, as  well as the different risks involved, a  distinction should be made between ‘real- time’ and ‘post’ remote biometric  identification systems. In the case of ‘real- time’ systems, the capturing of the  biometric data, the comparison and the  identification occur all instantaneously,  near-instantaneously or in any event  without a significant delay. In this regard,  there should be no scope for circumventing  the rules of this Regulation on the ‘real- time’ use of the AI systems in question by  providing for minor delays. ‘Real-time’  systems involve the use of ‘live’ or ‘near- ‘live’ material, such as video footage,  generated by a camera or other device with  similar functionality. In the case of ‘post’  systems, in contrast, the biometric data  have already been captured and the  comparison and identification occur only  after a significant delay. This involves  material, such as pictures or video footage  generated by closed circuit television  cameras or private devices, which has been generated before the use of the system in  respect of the natural persons concerned.  Given that the notion of biometric  identification is independent from the  individual’s consent, this definition  applies even when warning notices are  placed in the location that is under  surveillance of the remote biometric  identification system, and is not de facto  annulled by pre-enrolment. Amendment 25 Proposal for a regulation Recital 8 a (new) Text proposed by the Commission Amendment (8a) The identification of natural  persons at a distance is understood to  distinguish remote biometric  identification systems from close  proximity individual verification systems  using biometric identification means,  whose sole purpose is to confirm whether  or not a specific natural person  presenting themselves for identification is  permitted, such as in order to gain access  to a service, a device, or premises. Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned",What is the significance of the distinction between 'real-time' and 'post' remote biometric identification systems?,"['The distinction allows for different levels of accuracy in biometric identification.', 'The distinction determines whether the system can be used for both real-time and post-identification.', 'The distinction ensures that the system complies with privacy regulations.', 'The distinction allows for different types of biometric data to be used.']",2
EU_AI_Act.pdf,"Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned.  Therefore, the notion does not cover places  that are private in nature and normally not  freely accessible for third parties, including  law enforcement authorities, unless those  parties have been specifically invited or (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned and  regardless of the potential capacity  restrictions. Therefore, the notion does not  cover places that are private in nature and  normally not freely accessible for third  parties, including law enforcement authorised, such as homes, private clubs,  offices, warehouses and factories. Online  spaces are not covered either, as they are  not physical spaces. However, the mere  fact that certain conditions for accessing a  particular space may apply, such as  admission tickets or age restrictions, does  not mean that the space is not publicly  accessible within the meaning of this  Regulation. Consequently, in addition to  public spaces such as streets, relevant parts  of government buildings and most  transport infrastructure, spaces such as  cinemas, theatres, shops and shopping  centres are normally also publicly  accessible. Whether a given space is  accessible to the public should however be  determined on a case-by-case basis, having  regard to the specificities of the individual  situation at hand.authorities, unless those parties have been  specifically invited or authorised, such as  homes, private clubs, offices, warehouses  and factories. Online spaces are not  covered either, as they are not physical  spaces. However, the mere fact that certain  conditions for accessing a particular space  may apply, such as admission tickets or  age restrictions, does not mean that the  space is not publicly accessible within the  meaning of this Regulation. Consequently,  in addition to public spaces such as streets,  relevant parts of government buildings and  most transport infrastructure, spaces such  as cinemas, theatres, sports grounds,  schools, universities, relevant parts of  hospitals and banks, amusement parks,  festivals, shops and shopping centres are  normally also publicly accessible. Whether  a given space is accessible to the public  should however be determined on a case- by-case basis, having regard to the  specificities of the individual situation at  hand.  Amendment 27 Proposal for a regulation Recital 9 a (new) Text proposed by the Commission Amendment (9a) It is important to note that AI  systems should make best efforts to  respect general principles establishing a  high-level framework that promotes a  coherent human-centric approach to  ethical and trustworthy AI in line with the  Charter of Fundamental Rights of the  European Union and the values on which  the Union is founded, including the  protection of fundamental rights, human  agency and oversight, technical  robustness and safety, privacy and data  governance, transparency, non- discrimination and fairness and societal  and environmental wellbeing.Amendment 28 Proposal for a regulation Recital 9 b (new) Text proposed by the Commission Amendment (9b) ‘AI literacy’ refers to skills,  knowledge and understanding that allows  providers, users and affected persons,  taking into account their respective rights  and obligations in the context of this  Regulation, to make an informed  deployment of AI systems, as well as to  gain awareness about the opportunities  and risks of AI and possible harm it can  cause and thereby promote its democratic  control. AI literacy should not be limited  to learning about tools and technologies,  but should also aim to equip providers  and users with the notions and skills  required to ensure compliance with and  enforcement of this Regulation",What is the significance of Recital 9 in the proposed Regulation?,"['It defines the scope of publicly accessible spaces for the purpose of the Regulation.', 'It outlines the importance of AI literacy for providers, users, and affected persons.', 'It establishes general principles for ethical and trustworthy AI in line with the Charter of Fundamental Rights of the European Union.', 'It provides a framework for determining whether a given space is publicly accessible.']",2
EU_AI_Act.pdf,"Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned.  Therefore, the notion does not cover places  that are private in nature and normally not  freely accessible for third parties, including  law enforcement authorities, unless those  parties have been specifically invited or (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned and  regardless of the potential capacity  restrictions. Therefore, the notion does not  cover places that are private in nature and  normally not freely accessible for third  parties, including law enforcement authorised, such as homes, private clubs,  offices, warehouses and factories. Online  spaces are not covered either, as they are  not physical spaces. However, the mere  fact that certain conditions for accessing a  particular space may apply, such as  admission tickets or age restrictions, does  not mean that the space is not publicly  accessible within the meaning of this  Regulation. Consequently, in addition to  public spaces such as streets, relevant parts  of government buildings and most  transport infrastructure, spaces such as  cinemas, theatres, shops and shopping  centres are normally also publicly  accessible. Whether a given space is  accessible to the public should however be  determined on a case-by-case basis, having  regard to the specificities of the individual  situation at hand.authorities, unless those parties have been  specifically invited or authorised, such as  homes, private clubs, offices, warehouses  and factories. Online spaces are not  covered either, as they are not physical  spaces. However, the mere fact that certain  conditions for accessing a particular space  may apply, such as admission tickets or  age restrictions, does not mean that the  space is not publicly accessible within the  meaning of this Regulation. Consequently,  in addition to public spaces such as streets,  relevant parts of government buildings and  most transport infrastructure, spaces such  as cinemas, theatres, sports grounds,  schools, universities, relevant parts of  hospitals and banks, amusement parks,  festivals, shops and shopping centres are  normally also publicly accessible. Whether  a given space is accessible to the public  should however be determined on a case- by-case basis, having regard to the  specificities of the individual situation at  hand.  Amendment 27 Proposal for a regulation Recital 9 a (new) Text proposed by the Commission Amendment (9a) It is important to note that AI  systems should make best efforts to  respect general principles establishing a  high-level framework that promotes a  coherent human-centric approach to  ethical and trustworthy AI in line with the  Charter of Fundamental Rights of the  European Union and the values on which  the Union is founded, including the  protection of fundamental rights, human  agency and oversight, technical  robustness and safety, privacy and data  governance, transparency, non- discrimination and fairness and societal  and environmental wellbeing.Amendment 28 Proposal for a regulation Recital 9 b (new) Text proposed by the Commission Amendment (9b) ‘AI literacy’ refers to skills,  knowledge and understanding that allows  providers, users and affected persons,  taking into account their respective rights  and obligations in the context of this  Regulation, to make an informed  deployment of AI systems, as well as to  gain awareness about the opportunities  and risks of AI and possible harm it can  cause and thereby promote its democratic  control. AI literacy should not be limited  to learning about tools and technologies,  but should also aim to equip providers  and users with the notions and skills  required to ensure compliance with and  enforcement of this Regulation","What is AI literacy, according to Amendment 28 Proposal for a regulation?","['The ability to use AI systems to promote a coherent human-centric approach to ethical and trustworthy AI.', 'The skills, knowledge, and understanding needed to make informed decisions about the deployment of AI systems.', 'The ability to design and develop AI systems that are technically robust and safe.', 'The knowledge of how to protect fundamental rights, human agency, and oversight when using AI systems.']",1
EU_AI_Act.pdf,"Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned.  Therefore, the notion does not cover places  that are private in nature and normally not  freely accessible for third parties, including  law enforcement authorities, unless those  parties have been specifically invited or (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned and  regardless of the potential capacity  restrictions. Therefore, the notion does not  cover places that are private in nature and  normally not freely accessible for third  parties, including law enforcement authorised, such as homes, private clubs,  offices, warehouses and factories. Online  spaces are not covered either, as they are  not physical spaces. However, the mere  fact that certain conditions for accessing a  particular space may apply, such as  admission tickets or age restrictions, does  not mean that the space is not publicly  accessible within the meaning of this  Regulation. Consequently, in addition to  public spaces such as streets, relevant parts  of government buildings and most  transport infrastructure, spaces such as  cinemas, theatres, shops and shopping  centres are normally also publicly  accessible. Whether a given space is  accessible to the public should however be  determined on a case-by-case basis, having  regard to the specificities of the individual  situation at hand.authorities, unless those parties have been  specifically invited or authorised, such as  homes, private clubs, offices, warehouses  and factories. Online spaces are not  covered either, as they are not physical  spaces. However, the mere fact that certain  conditions for accessing a particular space  may apply, such as admission tickets or  age restrictions, does not mean that the  space is not publicly accessible within the  meaning of this Regulation. Consequently,  in addition to public spaces such as streets,  relevant parts of government buildings and  most transport infrastructure, spaces such  as cinemas, theatres, sports grounds,  schools, universities, relevant parts of  hospitals and banks, amusement parks,  festivals, shops and shopping centres are  normally also publicly accessible. Whether  a given space is accessible to the public  should however be determined on a case- by-case basis, having regard to the  specificities of the individual situation at  hand.  Amendment 27 Proposal for a regulation Recital 9 a (new) Text proposed by the Commission Amendment (9a) It is important to note that AI  systems should make best efforts to  respect general principles establishing a  high-level framework that promotes a  coherent human-centric approach to  ethical and trustworthy AI in line with the  Charter of Fundamental Rights of the  European Union and the values on which  the Union is founded, including the  protection of fundamental rights, human  agency and oversight, technical  robustness and safety, privacy and data  governance, transparency, non- discrimination and fairness and societal  and environmental wellbeing.Amendment 28 Proposal for a regulation Recital 9 b (new) Text proposed by the Commission Amendment (9b) ‘AI literacy’ refers to skills,  knowledge and understanding that allows  providers, users and affected persons,  taking into account their respective rights  and obligations in the context of this  Regulation, to make an informed  deployment of AI systems, as well as to  gain awareness about the opportunities  and risks of AI and possible harm it can  cause and thereby promote its democratic  control. AI literacy should not be limited  to learning about tools and technologies,  but should also aim to equip providers  and users with the notions and skills  required to ensure compliance with and  enforcement of this Regulation",What is the purpose of Amendment 27 Proposal for a regulation?,"['To establish a high-level framework that promotes a coherent human-centric approach to ethical and trustworthy AI.', 'To provide skills, knowledge, and understanding to providers, users, and affected persons to make an informed deployment of AI systems.', 'To regulate the use of AI systems in publicly accessible spaces.', 'To protect fundamental rights, human agency and oversight, technical robustness and safety, privacy and data governance, transparency, non-discrimination, and fairness, and societal and environmental well-being.']",0
EU_AI_Act.pdf,"Amendment 26 Proposal for a regulation Recital 9 Text proposed by the Commission Amendment (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned.  Therefore, the notion does not cover places  that are private in nature and normally not  freely accessible for third parties, including  law enforcement authorities, unless those  parties have been specifically invited or (9) For the purposes of this Regulation  the notion of publicly accessible space  should be understood as referring to any  physical place that is accessible to the  public, irrespective of whether the place in  question is privately or publicly owned and  regardless of the potential capacity  restrictions. Therefore, the notion does not  cover places that are private in nature and  normally not freely accessible for third  parties, including law enforcement authorised, such as homes, private clubs,  offices, warehouses and factories. Online  spaces are not covered either, as they are  not physical spaces. However, the mere  fact that certain conditions for accessing a  particular space may apply, such as  admission tickets or age restrictions, does  not mean that the space is not publicly  accessible within the meaning of this  Regulation. Consequently, in addition to  public spaces such as streets, relevant parts  of government buildings and most  transport infrastructure, spaces such as  cinemas, theatres, shops and shopping  centres are normally also publicly  accessible. Whether a given space is  accessible to the public should however be  determined on a case-by-case basis, having  regard to the specificities of the individual  situation at hand.authorities, unless those parties have been  specifically invited or authorised, such as  homes, private clubs, offices, warehouses  and factories. Online spaces are not  covered either, as they are not physical  spaces. However, the mere fact that certain  conditions for accessing a particular space  may apply, such as admission tickets or  age restrictions, does not mean that the  space is not publicly accessible within the  meaning of this Regulation. Consequently,  in addition to public spaces such as streets,  relevant parts of government buildings and  most transport infrastructure, spaces such  as cinemas, theatres, sports grounds,  schools, universities, relevant parts of  hospitals and banks, amusement parks,  festivals, shops and shopping centres are  normally also publicly accessible. Whether  a given space is accessible to the public  should however be determined on a case- by-case basis, having regard to the  specificities of the individual situation at  hand.  Amendment 27 Proposal for a regulation Recital 9 a (new) Text proposed by the Commission Amendment (9a) It is important to note that AI  systems should make best efforts to  respect general principles establishing a  high-level framework that promotes a  coherent human-centric approach to  ethical and trustworthy AI in line with the  Charter of Fundamental Rights of the  European Union and the values on which  the Union is founded, including the  protection of fundamental rights, human  agency and oversight, technical  robustness and safety, privacy and data  governance, transparency, non- discrimination and fairness and societal  and environmental wellbeing.Amendment 28 Proposal for a regulation Recital 9 b (new) Text proposed by the Commission Amendment (9b) ‘AI literacy’ refers to skills,  knowledge and understanding that allows  providers, users and affected persons,  taking into account their respective rights  and obligations in the context of this  Regulation, to make an informed  deployment of AI systems, as well as to  gain awareness about the opportunities  and risks of AI and possible harm it can  cause and thereby promote its democratic  control. AI literacy should not be limited  to learning about tools and technologies,  but should also aim to equip providers  and users with the notions and skills  required to ensure compliance with and  enforcement of this Regulation","What is the relationship between AI literacy and the deployment of AI systems, according to Amendment 28 Proposal for a regulation?","['AI literacy is not related to the deployment of AI systems.', 'AI literacy is essential for the deployment of AI systems.', 'AI literacy is only relevant for the development of AI systems.', 'AI literacy is necessary for ensuring compliance with and enforcement of the Regulation.']",3
EU_AI_Act.pdf,"This Regulation should not be understood  as providing for the legal ground for  processing of personal data, including  special categories of personal data, where  relevant.accordance with the applicable  requirements resulting from the Charter  and from the applicable acts of secondary  Union law and national law. Amendment 75 Proposal for a regulation Recital 41 a (new) Text proposed by the Commission Amendment (41a) A number of legally binding rules at  European, national and international  level already apply or are relevant to AI  systems today, including but not limited to  EU primary law (the Treaties of the  European Union and its Charter of  Fundamental Rights), EU secondary law  (such as the General Data Protection  Regulation, the Product Liability  Directive, the Regulation on the Free  Flow of Non-Personal Data, anti- discrimination Directives, consumer law  and Safety and Health at Work  Directives), the UN Human Rights  treaties and the Council of Europe  conventions (such as the European  Convention on Human Rights), and   national law. Besides horizontally  applicable rules, various domain-specific  rules exist that apply to particular AI  applications (such as for instance the  Medical Device Regulation in the  healthcare sector). Amendment 76 Proposal for a regulation Recital 42Text proposed by the Commission Amendment (42) To mitigate the risks from high-risk  AI systems placed or otherwise put into  service on the Union market for users and  affected persons, certain mandatory  requirements should apply, taking into  account the intended purpose of the use of  the system and according to the risk  management system to be established by  the provider.(42) To mitigate the risks from high-risk  AI systems placed or otherwise put into  service on the Union market for deployers  and affected persons, certain mandatory  requirements should apply, taking into  account the intended purpose, the  reasonably foreseeable misuse of the  system and according to the risk  management system to be established by  the provider. These requirements should  be objective-driven, fit for purpose,  reasonable and effective, without adding  undue regulatory burdens or costs on  operators.  Amendment 77 Proposal for a regulation Recital 43 Text proposed by the Commission Amendment (43) Requirements should apply to high- risk AI systems as regards the quality of  data sets used, technical documentation  and record-keeping, transparency and the  provision of information to users, human  oversight, and robustness, accuracy and  cybersecurity. Those requirements are  necessary to effectively mitigate the risks  for health, safety and fundamental rights,  as applicable in the light of the intended  purpose of the system, and no other less  trade restrictive measures are reasonably  available, thus avoiding unjustified  restrictions to trade.(43) Requirements should apply to high- risk AI systems as regards the quality and  relevance of data sets used, technical  documentation and record-keeping,  transparency and the provision of  information to deployers, human oversight,  and robustness, accuracy and  cybersecurity. Those requirements are  necessary to effectively mitigate the risks  for health, safety and fundamental rights,  as well as the environment, democracy  and rule of law, as applicable in the light  of the intended purpose or reasonably  foreseeable misuse of the system, and no  other less trade restrictive measures are  reasonably available, thus avoiding  unjustified restrictions to trade. Amendment 78 Proposal for a regulation Recital 44Text proposed by the Commission Amendment (44)High data quality is essential for the  performance of many AI systems,  especially when techniques involving the  training of models are used, with a view to  ensure that the high-risk AI system  performs as intended and safely and it does  not become the source of discrimination  prohibited by Union law. High quality  training, validation and testing data sets  require the implementation of appropriate  data governance and management  practices. Training, validation and testing  data sets should be sufficiently relevant,  representative and free of errors and  complete in view of the intended purpose  of the system. They should also have the  appropriate statistical properties, including  as regards the persons or groups of persons  on which the high-risk AI system is  intended to be used","What is the purpose of the requirements for high-risk AI systems, according to Recital 42?","['To mitigate the risks from high-risk AI systems for users and affected persons.', 'To ensure that high-risk AI systems perform as intended and safely.', 'To prevent discrimination prohibited by Union law.', 'To establish a risk management system for deployers.']",0
EU_AI_Act.pdf,"This Regulation should not be understood  as providing for the legal ground for  processing of personal data, including  special categories of personal data, where  relevant.accordance with the applicable  requirements resulting from the Charter  and from the applicable acts of secondary  Union law and national law. Amendment 75 Proposal for a regulation Recital 41 a (new) Text proposed by the Commission Amendment (41a) A number of legally binding rules at  European, national and international  level already apply or are relevant to AI  systems today, including but not limited to  EU primary law (the Treaties of the  European Union and its Charter of  Fundamental Rights), EU secondary law  (such as the General Data Protection  Regulation, the Product Liability  Directive, the Regulation on the Free  Flow of Non-Personal Data, anti- discrimination Directives, consumer law  and Safety and Health at Work  Directives), the UN Human Rights  treaties and the Council of Europe  conventions (such as the European  Convention on Human Rights), and   national law. Besides horizontally  applicable rules, various domain-specific  rules exist that apply to particular AI  applications (such as for instance the  Medical Device Regulation in the  healthcare sector). Amendment 76 Proposal for a regulation Recital 42Text proposed by the Commission Amendment (42) To mitigate the risks from high-risk  AI systems placed or otherwise put into  service on the Union market for users and  affected persons, certain mandatory  requirements should apply, taking into  account the intended purpose of the use of  the system and according to the risk  management system to be established by  the provider.(42) To mitigate the risks from high-risk  AI systems placed or otherwise put into  service on the Union market for deployers  and affected persons, certain mandatory  requirements should apply, taking into  account the intended purpose, the  reasonably foreseeable misuse of the  system and according to the risk  management system to be established by  the provider. These requirements should  be objective-driven, fit for purpose,  reasonable and effective, without adding  undue regulatory burdens or costs on  operators.  Amendment 77 Proposal for a regulation Recital 43 Text proposed by the Commission Amendment (43) Requirements should apply to high- risk AI systems as regards the quality of  data sets used, technical documentation  and record-keeping, transparency and the  provision of information to users, human  oversight, and robustness, accuracy and  cybersecurity. Those requirements are  necessary to effectively mitigate the risks  for health, safety and fundamental rights,  as applicable in the light of the intended  purpose of the system, and no other less  trade restrictive measures are reasonably  available, thus avoiding unjustified  restrictions to trade.(43) Requirements should apply to high- risk AI systems as regards the quality and  relevance of data sets used, technical  documentation and record-keeping,  transparency and the provision of  information to deployers, human oversight,  and robustness, accuracy and  cybersecurity. Those requirements are  necessary to effectively mitigate the risks  for health, safety and fundamental rights,  as well as the environment, democracy  and rule of law, as applicable in the light  of the intended purpose or reasonably  foreseeable misuse of the system, and no  other less trade restrictive measures are  reasonably available, thus avoiding  unjustified restrictions to trade. Amendment 78 Proposal for a regulation Recital 44Text proposed by the Commission Amendment (44)High data quality is essential for the  performance of many AI systems,  especially when techniques involving the  training of models are used, with a view to  ensure that the high-risk AI system  performs as intended and safely and it does  not become the source of discrimination  prohibited by Union law. High quality  training, validation and testing data sets  require the implementation of appropriate  data governance and management  practices. Training, validation and testing  data sets should be sufficiently relevant,  representative and free of errors and  complete in view of the intended purpose  of the system. They should also have the  appropriate statistical properties, including  as regards the persons or groups of persons  on which the high-risk AI system is  intended to be used","What is the purpose of the risk management system, according to Recital 42?","['To mitigate the risks from high-risk AI systems for users and affected persons.', 'To mitigate the risks from high-risk AI systems for deployers and affected persons.', 'To ensure that high-risk AI systems perform as intended and safely.', 'To avoid unjustified restrictions to trade.']",1
EU_AI_Act.pdf,"This Regulation should not be understood  as providing for the legal ground for  processing of personal data, including  special categories of personal data, where  relevant.accordance with the applicable  requirements resulting from the Charter  and from the applicable acts of secondary  Union law and national law. Amendment 75 Proposal for a regulation Recital 41 a (new) Text proposed by the Commission Amendment (41a) A number of legally binding rules at  European, national and international  level already apply or are relevant to AI  systems today, including but not limited to  EU primary law (the Treaties of the  European Union and its Charter of  Fundamental Rights), EU secondary law  (such as the General Data Protection  Regulation, the Product Liability  Directive, the Regulation on the Free  Flow of Non-Personal Data, anti- discrimination Directives, consumer law  and Safety and Health at Work  Directives), the UN Human Rights  treaties and the Council of Europe  conventions (such as the European  Convention on Human Rights), and   national law. Besides horizontally  applicable rules, various domain-specific  rules exist that apply to particular AI  applications (such as for instance the  Medical Device Regulation in the  healthcare sector). Amendment 76 Proposal for a regulation Recital 42Text proposed by the Commission Amendment (42) To mitigate the risks from high-risk  AI systems placed or otherwise put into  service on the Union market for users and  affected persons, certain mandatory  requirements should apply, taking into  account the intended purpose of the use of  the system and according to the risk  management system to be established by  the provider.(42) To mitigate the risks from high-risk  AI systems placed or otherwise put into  service on the Union market for deployers  and affected persons, certain mandatory  requirements should apply, taking into  account the intended purpose, the  reasonably foreseeable misuse of the  system and according to the risk  management system to be established by  the provider. These requirements should  be objective-driven, fit for purpose,  reasonable and effective, without adding  undue regulatory burdens or costs on  operators.  Amendment 77 Proposal for a regulation Recital 43 Text proposed by the Commission Amendment (43) Requirements should apply to high- risk AI systems as regards the quality of  data sets used, technical documentation  and record-keeping, transparency and the  provision of information to users, human  oversight, and robustness, accuracy and  cybersecurity. Those requirements are  necessary to effectively mitigate the risks  for health, safety and fundamental rights,  as applicable in the light of the intended  purpose of the system, and no other less  trade restrictive measures are reasonably  available, thus avoiding unjustified  restrictions to trade.(43) Requirements should apply to high- risk AI systems as regards the quality and  relevance of data sets used, technical  documentation and record-keeping,  transparency and the provision of  information to deployers, human oversight,  and robustness, accuracy and  cybersecurity. Those requirements are  necessary to effectively mitigate the risks  for health, safety and fundamental rights,  as well as the environment, democracy  and rule of law, as applicable in the light  of the intended purpose or reasonably  foreseeable misuse of the system, and no  other less trade restrictive measures are  reasonably available, thus avoiding  unjustified restrictions to trade. Amendment 78 Proposal for a regulation Recital 44Text proposed by the Commission Amendment (44)High data quality is essential for the  performance of many AI systems,  especially when techniques involving the  training of models are used, with a view to  ensure that the high-risk AI system  performs as intended and safely and it does  not become the source of discrimination  prohibited by Union law. High quality  training, validation and testing data sets  require the implementation of appropriate  data governance and management  practices. Training, validation and testing  data sets should be sufficiently relevant,  representative and free of errors and  complete in view of the intended purpose  of the system. They should also have the  appropriate statistical properties, including  as regards the persons or groups of persons  on which the high-risk AI system is  intended to be used","Who is responsible for establishing the risk management system, according to Recital 42?","['The provider of the high-risk AI system', 'The deployer of the high-risk AI system', 'The European Commission', 'The national authorities']",0
EU_AI_Act.pdf,"To  foster the development and deployment of  AI, especially by SMEs, start-ups,  academic research but also by individuals,  this Regulation should not apply to such  free and open-source AI components  except to the extent that they are placed  on the market or put into service by a  provider as part of a high-risk AI system  or of an AI system that falls under Title II  or IV of this Regulation. Amendment 33 Proposal for a regulation Recital 12 b (new) Text proposed by the Commission Amendment (12b) Neither the collaborative  development of free and open-source AI  components nor making them available  on open repositories should constitute a  placing on the market or putting into  service. A commercial activity, within the  understanding of making available on the  market, might however be characterised  by charging a price, with the exception of transactions between micro enterprises,  for a free and open-source AI component  but also by charging a price for technical  support services, by providing a software  platform through which the provider  monetises other services, or by the use of  personal data for reasons other than  exclusively for improving the security,  compatibility or interoperability of the  software. Amendment 34 Proposal for a regulation Recital 12 c (new) Text proposed by the Commission Amendment (12c) The developers of free and open- source AI components should not be  mandated under this Regulation to  comply with requirements targeting the AI  value chain and, in particular, not  towards the provider that has used that  free and open-source AI component.  Developers of free and open-source AI  components should however be  encouraged to implement widely adopted  documentation practices, such as model  and data cards, as a way to accelerate  information sharing along the AI value  chain, allowing the promotion of  trustworthy AI systems in the Union. Amendment 35 Proposal for a regulation Recital 13 Text proposed by the Commission Amendment (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights, common normative standards for all  high-risk AI systems should be established.  Those standards should be consistent with  the Charter of fundamental rights of the (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights as well as democracy and rule of  law and the environment, common  normative standards for all high-risk AI  systems should be established. Those European Union (the Charter) and should  be non-discriminatory and in line with the  Union’s international trade commitments.standards should be consistent with the  Charter, the European Green Deal, the  Joint Declaration on Digital Rights of the  Union and the Ethics Guidelines for  Trustworthy Artificial Intelligence (AI) of  the High-Level Expert Group on Artificial  Intelligence, and should be non- discriminatory and in line with the Union’s  international trade commitments. Amendment 36 Proposal for a regulation Recital 14 Text proposed by the Commission Amendment (14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  artificial intelligence practices, to lay down  requirements for high-risk AI systems and  obligations for the relevant operators, and  to lay down transparency obligations for  certain AI systems.(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate",What is the purpose of the Regulation according to Recital 12b?,"['To establish a risk-based approach for AI systems.', 'To encourage the development and deployment of AI.', 'To mandate compliance with requirements targeting the AI value chain.', 'To prohibit certain AI practices and lay down transparency obligations.']",1
EU_AI_Act.pdf,"To  foster the development and deployment of  AI, especially by SMEs, start-ups,  academic research but also by individuals,  this Regulation should not apply to such  free and open-source AI components  except to the extent that they are placed  on the market or put into service by a  provider as part of a high-risk AI system  or of an AI system that falls under Title II  or IV of this Regulation. Amendment 33 Proposal for a regulation Recital 12 b (new) Text proposed by the Commission Amendment (12b) Neither the collaborative  development of free and open-source AI  components nor making them available  on open repositories should constitute a  placing on the market or putting into  service. A commercial activity, within the  understanding of making available on the  market, might however be characterised  by charging a price, with the exception of transactions between micro enterprises,  for a free and open-source AI component  but also by charging a price for technical  support services, by providing a software  platform through which the provider  monetises other services, or by the use of  personal data for reasons other than  exclusively for improving the security,  compatibility or interoperability of the  software. Amendment 34 Proposal for a regulation Recital 12 c (new) Text proposed by the Commission Amendment (12c) The developers of free and open- source AI components should not be  mandated under this Regulation to  comply with requirements targeting the AI  value chain and, in particular, not  towards the provider that has used that  free and open-source AI component.  Developers of free and open-source AI  components should however be  encouraged to implement widely adopted  documentation practices, such as model  and data cards, as a way to accelerate  information sharing along the AI value  chain, allowing the promotion of  trustworthy AI systems in the Union. Amendment 35 Proposal for a regulation Recital 13 Text proposed by the Commission Amendment (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights, common normative standards for all  high-risk AI systems should be established.  Those standards should be consistent with  the Charter of fundamental rights of the (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights as well as democracy and rule of  law and the environment, common  normative standards for all high-risk AI  systems should be established. Those European Union (the Charter) and should  be non-discriminatory and in line with the  Union’s international trade commitments.standards should be consistent with the  Charter, the European Green Deal, the  Joint Declaration on Digital Rights of the  Union and the Ethics Guidelines for  Trustworthy Artificial Intelligence (AI) of  the High-Level Expert Group on Artificial  Intelligence, and should be non- discriminatory and in line with the Union’s  international trade commitments. Amendment 36 Proposal for a regulation Recital 14 Text proposed by the Commission Amendment (14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  artificial intelligence practices, to lay down  requirements for high-risk AI systems and  obligations for the relevant operators, and  to lay down transparency obligations for  certain AI systems.(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate","What are the exceptions to the non-application of the Regulation to free and open-source AI components, according to Recital 12b?","['Charging a price for technical support services or using personal data for reasons other than improving the security, compatibility, or interoperability of the software.', 'Providing a software platform through which the provider monetizes other services.', 'Transactions between micro-enterprises for a free and open-source AI component.', 'Making available on open repositories or collaborative development of free and open-source AI components.']",1
EU_AI_Act.pdf,"To  foster the development and deployment of  AI, especially by SMEs, start-ups,  academic research but also by individuals,  this Regulation should not apply to such  free and open-source AI components  except to the extent that they are placed  on the market or put into service by a  provider as part of a high-risk AI system  or of an AI system that falls under Title II  or IV of this Regulation. Amendment 33 Proposal for a regulation Recital 12 b (new) Text proposed by the Commission Amendment (12b) Neither the collaborative  development of free and open-source AI  components nor making them available  on open repositories should constitute a  placing on the market or putting into  service. A commercial activity, within the  understanding of making available on the  market, might however be characterised  by charging a price, with the exception of transactions between micro enterprises,  for a free and open-source AI component  but also by charging a price for technical  support services, by providing a software  platform through which the provider  monetises other services, or by the use of  personal data for reasons other than  exclusively for improving the security,  compatibility or interoperability of the  software. Amendment 34 Proposal for a regulation Recital 12 c (new) Text proposed by the Commission Amendment (12c) The developers of free and open- source AI components should not be  mandated under this Regulation to  comply with requirements targeting the AI  value chain and, in particular, not  towards the provider that has used that  free and open-source AI component.  Developers of free and open-source AI  components should however be  encouraged to implement widely adopted  documentation practices, such as model  and data cards, as a way to accelerate  information sharing along the AI value  chain, allowing the promotion of  trustworthy AI systems in the Union. Amendment 35 Proposal for a regulation Recital 13 Text proposed by the Commission Amendment (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights, common normative standards for all  high-risk AI systems should be established.  Those standards should be consistent with  the Charter of fundamental rights of the (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights as well as democracy and rule of  law and the environment, common  normative standards for all high-risk AI  systems should be established. Those European Union (the Charter) and should  be non-discriminatory and in line with the  Union’s international trade commitments.standards should be consistent with the  Charter, the European Green Deal, the  Joint Declaration on Digital Rights of the  Union and the Ethics Guidelines for  Trustworthy Artificial Intelligence (AI) of  the High-Level Expert Group on Artificial  Intelligence, and should be non- discriminatory and in line with the Union’s  international trade commitments. Amendment 36 Proposal for a regulation Recital 14 Text proposed by the Commission Amendment (14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  artificial intelligence practices, to lay down  requirements for high-risk AI systems and  obligations for the relevant operators, and  to lay down transparency obligations for  certain AI systems.(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate",What is the purpose of Recital 12c?,"['To encourage developers of free and open-source AI components to implement widely adopted documentation practices.', 'To mandate developers of free and open-source AI components to comply with requirements targeting the AI value chain.', 'To establish common normative standards for all high-risk AI systems.', 'To prohibit certain artificial intelligence practices.']",0
EU_AI_Act.pdf,"To  foster the development and deployment of  AI, especially by SMEs, start-ups,  academic research but also by individuals,  this Regulation should not apply to such  free and open-source AI components  except to the extent that they are placed  on the market or put into service by a  provider as part of a high-risk AI system  or of an AI system that falls under Title II  or IV of this Regulation. Amendment 33 Proposal for a regulation Recital 12 b (new) Text proposed by the Commission Amendment (12b) Neither the collaborative  development of free and open-source AI  components nor making them available  on open repositories should constitute a  placing on the market or putting into  service. A commercial activity, within the  understanding of making available on the  market, might however be characterised  by charging a price, with the exception of transactions between micro enterprises,  for a free and open-source AI component  but also by charging a price for technical  support services, by providing a software  platform through which the provider  monetises other services, or by the use of  personal data for reasons other than  exclusively for improving the security,  compatibility or interoperability of the  software. Amendment 34 Proposal for a regulation Recital 12 c (new) Text proposed by the Commission Amendment (12c) The developers of free and open- source AI components should not be  mandated under this Regulation to  comply with requirements targeting the AI  value chain and, in particular, not  towards the provider that has used that  free and open-source AI component.  Developers of free and open-source AI  components should however be  encouraged to implement widely adopted  documentation practices, such as model  and data cards, as a way to accelerate  information sharing along the AI value  chain, allowing the promotion of  trustworthy AI systems in the Union. Amendment 35 Proposal for a regulation Recital 13 Text proposed by the Commission Amendment (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights, common normative standards for all  high-risk AI systems should be established.  Those standards should be consistent with  the Charter of fundamental rights of the (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights as well as democracy and rule of  law and the environment, common  normative standards for all high-risk AI  systems should be established. Those European Union (the Charter) and should  be non-discriminatory and in line with the  Union’s international trade commitments.standards should be consistent with the  Charter, the European Green Deal, the  Joint Declaration on Digital Rights of the  Union and the Ethics Guidelines for  Trustworthy Artificial Intelligence (AI) of  the High-Level Expert Group on Artificial  Intelligence, and should be non- discriminatory and in line with the Union’s  international trade commitments. Amendment 36 Proposal for a regulation Recital 14 Text proposed by the Commission Amendment (14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  artificial intelligence practices, to lay down  requirements for high-risk AI systems and  obligations for the relevant operators, and  to lay down transparency obligations for  certain AI systems.(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate",What is the purpose of Recital 13?,"['To establish common normative standards for all high-risk AI systems.', 'To prohibit certain AI practices and lay down requirements for high-risk AI systems.', 'To encourage the development and deployment of AI, especially by SMEs, start-ups, and academic research.', 'To introduce a proportionate and effective set of binding rules for AI systems.']",0
EU_AI_Act.pdf,"To  foster the development and deployment of  AI, especially by SMEs, start-ups,  academic research but also by individuals,  this Regulation should not apply to such  free and open-source AI components  except to the extent that they are placed  on the market or put into service by a  provider as part of a high-risk AI system  or of an AI system that falls under Title II  or IV of this Regulation. Amendment 33 Proposal for a regulation Recital 12 b (new) Text proposed by the Commission Amendment (12b) Neither the collaborative  development of free and open-source AI  components nor making them available  on open repositories should constitute a  placing on the market or putting into  service. A commercial activity, within the  understanding of making available on the  market, might however be characterised  by charging a price, with the exception of transactions between micro enterprises,  for a free and open-source AI component  but also by charging a price for technical  support services, by providing a software  platform through which the provider  monetises other services, or by the use of  personal data for reasons other than  exclusively for improving the security,  compatibility or interoperability of the  software. Amendment 34 Proposal for a regulation Recital 12 c (new) Text proposed by the Commission Amendment (12c) The developers of free and open- source AI components should not be  mandated under this Regulation to  comply with requirements targeting the AI  value chain and, in particular, not  towards the provider that has used that  free and open-source AI component.  Developers of free and open-source AI  components should however be  encouraged to implement widely adopted  documentation practices, such as model  and data cards, as a way to accelerate  information sharing along the AI value  chain, allowing the promotion of  trustworthy AI systems in the Union. Amendment 35 Proposal for a regulation Recital 13 Text proposed by the Commission Amendment (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights, common normative standards for all  high-risk AI systems should be established.  Those standards should be consistent with  the Charter of fundamental rights of the (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights as well as democracy and rule of  law and the environment, common  normative standards for all high-risk AI  systems should be established. Those European Union (the Charter) and should  be non-discriminatory and in line with the  Union’s international trade commitments.standards should be consistent with the  Charter, the European Green Deal, the  Joint Declaration on Digital Rights of the  Union and the Ethics Guidelines for  Trustworthy Artificial Intelligence (AI) of  the High-Level Expert Group on Artificial  Intelligence, and should be non- discriminatory and in line with the Union’s  international trade commitments. Amendment 36 Proposal for a regulation Recital 14 Text proposed by the Commission Amendment (14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  artificial intelligence practices, to lay down  requirements for high-risk AI systems and  obligations for the relevant operators, and  to lay down transparency obligations for  certain AI systems.(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate",What are the standards established by Recital 13?,"['Standards for high-risk AI systems that fall under Title II or IV of the Regulation.', 'Standards for all high-risk AI systems, consistent with the Charter of fundamental rights of the European Union, the European Green Deal, the Joint Declaration on Digital Rights of the Union, and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High-Level Expert Group on Artificial Intelligence.', 'Standards for AI systems that are placed on the market or put into service by a provider.', 'Standards for the collaborative development of free and open-source AI components.']",1
EU_AI_Act.pdf,"To  foster the development and deployment of  AI, especially by SMEs, start-ups,  academic research but also by individuals,  this Regulation should not apply to such  free and open-source AI components  except to the extent that they are placed  on the market or put into service by a  provider as part of a high-risk AI system  or of an AI system that falls under Title II  or IV of this Regulation. Amendment 33 Proposal for a regulation Recital 12 b (new) Text proposed by the Commission Amendment (12b) Neither the collaborative  development of free and open-source AI  components nor making them available  on open repositories should constitute a  placing on the market or putting into  service. A commercial activity, within the  understanding of making available on the  market, might however be characterised  by charging a price, with the exception of transactions between micro enterprises,  for a free and open-source AI component  but also by charging a price for technical  support services, by providing a software  platform through which the provider  monetises other services, or by the use of  personal data for reasons other than  exclusively for improving the security,  compatibility or interoperability of the  software. Amendment 34 Proposal for a regulation Recital 12 c (new) Text proposed by the Commission Amendment (12c) The developers of free and open- source AI components should not be  mandated under this Regulation to  comply with requirements targeting the AI  value chain and, in particular, not  towards the provider that has used that  free and open-source AI component.  Developers of free and open-source AI  components should however be  encouraged to implement widely adopted  documentation practices, such as model  and data cards, as a way to accelerate  information sharing along the AI value  chain, allowing the promotion of  trustworthy AI systems in the Union. Amendment 35 Proposal for a regulation Recital 13 Text proposed by the Commission Amendment (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights, common normative standards for all  high-risk AI systems should be established.  Those standards should be consistent with  the Charter of fundamental rights of the (13) In order to ensure a consistent and  high level of protection of public interests  as regards health, safety and fundamental  rights as well as democracy and rule of  law and the environment, common  normative standards for all high-risk AI  systems should be established. Those European Union (the Charter) and should  be non-discriminatory and in line with the  Union’s international trade commitments.standards should be consistent with the  Charter, the European Green Deal, the  Joint Declaration on Digital Rights of the  Union and the Ethics Guidelines for  Trustworthy Artificial Intelligence (AI) of  the High-Level Expert Group on Artificial  Intelligence, and should be non- discriminatory and in line with the Union’s  international trade commitments. Amendment 36 Proposal for a regulation Recital 14 Text proposed by the Commission Amendment (14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate. It is  therefore necessary to prohibit certain  artificial intelligence practices, to lay down  requirements for high-risk AI systems and  obligations for the relevant operators, and  to lay down transparency obligations for  certain AI systems.(14) In order to introduce a proportionate  and effective set of binding rules for AI  systems, a clearly defined risk-based  approach should be followed. That  approach should tailor the type and content  of such rules to the intensity and scope of  the risks that AI systems can generate",What is the approach followed by the Regulation according to Recital 14?,"['Risk-based approach', 'Non-discriminatory approach', 'Fundamental rights approach', 'International trade commitment approach']",0
EU_AI_Act.pdf,"The intention to  distort the behaviour may not be presumed  if the distortion results from factors  external to the AI system which are outside  of the control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated by the  provider or the deployer of the AI system.  In any case, it is not necessary for the  provider or the deployer to have the intention to cause the significant harm, as  long as such harm results from the  manipulative or exploitative AI-enabled  practices. The prohibitions for such AI  practices is complementary to the  provisions contained in Directive  2005/29/EC, according to which unfair  commercial practices are prohibited,  irrespective of whether they carried out  having recourse to AI systems or  otherwise. In such setting, lawful  commercial practices, for example in the  field of advertising, that are in compliance  with Union law should not in themselves  be regarded as violating prohibition.  Research for legitimate purposes in relation  to such AI systems should not be stifled by  the prohibition, if such research does not  amount to use of the AI system in human- machine relations that exposes natural  persons to harm and such research is  carried out in accordance with recognised  ethical standards for scientific research and  on the basis of specific informed consent  of the individuals that are exposed to them  or, where applicable, of their legal  guardian. Amendment 39 Proposal for a regulation Recital 16 a (new) Text proposed by the Commission Amendment (16a) AI systems that categorise natural  persons by assigning them to specific  categories, according to known or  inferred sensitive or protected  characteristics are particularly intrusive,  violate human dignity and hold great risk  of discrimination. Such characteristics  include gender, gender identity, race,  ethnic origin, migration or citizenship  status, political orientation, sexual  orientation, religion, disability or any  other grounds on which discrimination is  prohibited under Article 21 of the Charter  of Fundamental Rights of the European Union, as well as under Article 9 of  Regulation (EU)2016/769. Such systems  should therefore be prohibited. Amendment 40 Proposal for a regulation Recital 17 Text proposed by the Commission Amendment (17) AI systems providing social scoring  of natural persons for general purpose by  public authorities or on their behalf may  lead to discriminatory outcomes and the  exclusion of certain groups. They may  violate the right to dignity and non- discrimination and the values of equality  and justice. Such AI systems evaluate or  classify the trustworthiness of natural  persons based on their social behaviour in  multiple contexts or known or predicted  personal or personality characteristics. The  social score obtained from such AI systems  may lead to the detrimental or  unfavourable treatment of natural persons  or whole groups thereof in social contexts,  which are unrelated to the context in which  the data was originally generated or  collected or to a detrimental treatment that  is disproportionate or unjustified to the  gravity of their social behaviour. Such AI  systems should be therefore prohibited.(17) AI systems providing social scoring  of natural persons for general purpose may  lead to discriminatory outcomes and the  exclusion of certain groups. They violate  the right to dignity and non-discrimination  and the values of equality and justice. Such  AI systems evaluate or classify natural  persons or groups based on multiple data  points and time occurrences related to  their social behaviour in multiple contexts  or known, inferred or predicted personal or  personality characteristics. The social score  obtained from such AI systems may lead to  the detrimental or unfavourable treatment  of natural persons or whole groups thereof  in social contexts, which are unrelated to  the context in which the data was originally  generated or collected or to a detrimental  treatment that is disproportionate or  unjustified to the gravity of their social  behaviour. Such AI systems should be  therefore prohibited",What is the purpose of the prohibition on AI systems that categorize natural persons by assigning them to specific categories based on sensitive or protected characteristics?,"['To ensure that AI systems do not violate human dignity and do not discriminate against certain groups.', 'To allow AI systems to categorize natural persons based on their social behavior and personal characteristics for general purposes.', 'To promote the use of AI systems for legitimate research purposes in relation to human-machine relations.', 'To ensure that AI systems providing social scoring of natural persons for general purposes by public authorities or on their behalf do not lead to discriminatory outcomes and the exclusion of certain groups.']",0
EU_AI_Act.pdf,"The intention to  distort the behaviour may not be presumed  if the distortion results from factors  external to the AI system which are outside  of the control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated by the  provider or the deployer of the AI system.  In any case, it is not necessary for the  provider or the deployer to have the intention to cause the significant harm, as  long as such harm results from the  manipulative or exploitative AI-enabled  practices. The prohibitions for such AI  practices is complementary to the  provisions contained in Directive  2005/29/EC, according to which unfair  commercial practices are prohibited,  irrespective of whether they carried out  having recourse to AI systems or  otherwise. In such setting, lawful  commercial practices, for example in the  field of advertising, that are in compliance  with Union law should not in themselves  be regarded as violating prohibition.  Research for legitimate purposes in relation  to such AI systems should not be stifled by  the prohibition, if such research does not  amount to use of the AI system in human- machine relations that exposes natural  persons to harm and such research is  carried out in accordance with recognised  ethical standards for scientific research and  on the basis of specific informed consent  of the individuals that are exposed to them  or, where applicable, of their legal  guardian. Amendment 39 Proposal for a regulation Recital 16 a (new) Text proposed by the Commission Amendment (16a) AI systems that categorise natural  persons by assigning them to specific  categories, according to known or  inferred sensitive or protected  characteristics are particularly intrusive,  violate human dignity and hold great risk  of discrimination. Such characteristics  include gender, gender identity, race,  ethnic origin, migration or citizenship  status, political orientation, sexual  orientation, religion, disability or any  other grounds on which discrimination is  prohibited under Article 21 of the Charter  of Fundamental Rights of the European Union, as well as under Article 9 of  Regulation (EU)2016/769. Such systems  should therefore be prohibited. Amendment 40 Proposal for a regulation Recital 17 Text proposed by the Commission Amendment (17) AI systems providing social scoring  of natural persons for general purpose by  public authorities or on their behalf may  lead to discriminatory outcomes and the  exclusion of certain groups. They may  violate the right to dignity and non- discrimination and the values of equality  and justice. Such AI systems evaluate or  classify the trustworthiness of natural  persons based on their social behaviour in  multiple contexts or known or predicted  personal or personality characteristics. The  social score obtained from such AI systems  may lead to the detrimental or  unfavourable treatment of natural persons  or whole groups thereof in social contexts,  which are unrelated to the context in which  the data was originally generated or  collected or to a detrimental treatment that  is disproportionate or unjustified to the  gravity of their social behaviour. Such AI  systems should be therefore prohibited.(17) AI systems providing social scoring  of natural persons for general purpose may  lead to discriminatory outcomes and the  exclusion of certain groups. They violate  the right to dignity and non-discrimination  and the values of equality and justice. Such  AI systems evaluate or classify natural  persons or groups based on multiple data  points and time occurrences related to  their social behaviour in multiple contexts  or known, inferred or predicted personal or  personality characteristics. The social score  obtained from such AI systems may lead to  the detrimental or unfavourable treatment  of natural persons or whole groups thereof  in social contexts, which are unrelated to  the context in which the data was originally  generated or collected or to a detrimental  treatment that is disproportionate or  unjustified to the gravity of their social  behaviour. Such AI systems should be  therefore prohibited",What is the issue with AI systems providing social scoring for general purpose by public authorities or on their behalf?,"['They violate the right to dignity and non-discrimination and the values of equality and justice.', 'They may lead to the exclusion of certain groups and discriminatory outcomes.', 'They evaluate or classify natural persons or groups based on multiple data points and time occurrences related to their social behavior in multiple contexts or known, inferred, or predicted personal or personality characteristics.', 'They provide an unfair advantage to certain groups.']",1
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",What type of AI systems should be classified as high-risk?,"['AI systems used to evaluate and classify emergency calls and dispatch emergency first response services.', 'AI systems used to determine whether public assistance benefits and services should be denied, reduced, revoked, or reclaimed by authorities.', 'AI systems used to evaluate the credit score or creditworthiness of natural persons.', 'AI systems used by law enforcement authorities for the prevention, investigation, detection, or prosecution of criminal offenses.']",1
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",Why should AI systems used for credit evaluation be classified as high-risk?,"['Because they may perpetuate historical patterns of discrimination.', 'Because they determine access to essential services such as housing and telecommunication.', 'Because they are used for detecting fraud in the offering of financial services.', 'Because they are used to dispatch or establish priority in the dispatching of emergency first response services.']",1
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",Are AI systems used for detecting fraud in offering financial services considered high-risk?,"['Yes, because they may perpetuate historical patterns of discrimination.', 'No, because they are not used to determine access to essential services.', 'Yes, because they may create new forms of discriminatory impacts.', 'No, because they are not intended to make decisions on the eligibility of natural persons for health and life insurance.']",1
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",Why should AI systems used in public administration be classified as high-risk?,"['Because they may perpetuate historical patterns of discrimination and create new forms of discriminatory impacts.', 'Because they are used for detecting fraud in the offering of financial services.', 'Because they are used to dispatch or establish priority in the dispatching of emergency first response services.', 'Because they are used to evaluate and classify emergency calls by natural persons.']",0
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",Why should AI systems used in health and life insurance be classified as high-risk?,"['Because they may perpetuate discrimination based on personal characteristics.', 'Because they may limit access to healthcare.', 'Because they may not entail a high risk to legal and natural persons.', 'Because they may infringe the right to social protection, non-discrimination, human dignity, or an effective remedy.']",3
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",Why should AI systems used in law enforcement be classified as high-risk?,"['Because they have the potential to significantly affect the lives or fundamental rights of individuals.', 'Because they are used to dispatch or establish priority in the dispatching of emergency first response services.', ""Because they determine those persons' access to financial resources or essential services such as housing, electricity, and telecommunication services."", 'Because they are used to evaluate and classify emergency calls by natural persons or to dispatch or establish priority in the dispatching of emergency first response services.']",0
EU_AI_Act.pdf,"In particular, AI systems used to  evaluate the credit score or  creditworthiness of natural persons should  be classified as high-risk AI systems, since  they determine those persons’ access to  financial resources or essential services  such as housing, electricity, and  telecommunication services. AI systems  used for this purpose may lead to  discrimination of persons or groups and  perpetuate historical patterns of  discrimination, for example based on racial  or ethnic origins, gender, disabilities, age,  sexual orientation, or create new forms of  discriminatory impacts. However, AI  systems provided for by Union law  for the  purpose of detecting fraud in the offering  of financial services should not be  considered as high-risk under this  Regulation. Natural persons applying for  or receiving public assistance benefits and  services from public authorities, including  healthcare services and essential services,  including but not limited to housing,  electricity, heating/cooling and internet,  are typically dependent on those benefits  and services and in a vulnerable position in impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Those systems should  therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to dispatch or establish priority in the  dispatching of emergency first response  services should also be classified as high- risk since they make decisions in very  critical situations for the life and health of  persons and their property.relation to the responsible authorities. If AI  systems are used for determining whether  such benefits and services should be  denied, reduced, revoked or reclaimed by  authorities, they may have a significant  impact on persons’ livelihood and may  infringe their fundamental rights, such as  the right to social protection, non- discrimination, human dignity or an  effective remedy. Similarly, AI systems  intended to be used to make decisions or  materially influence decisions on the  eligibility of natural persons for health  and life insurance may also have a  significant impact on persons’ livelihood  and may infringe their fundamental rights  such as by limiting access to healthcare or  by perpetuating discrimination based on  personal characteristics. Those systems  should therefore be classified as high-risk.  Nonetheless, this Regulation should not  hamper the development and use of  innovative approaches in the public  administration, which would stand to  benefit from a wider use of compliant and  safe AI systems, provided that those  systems do not entail a high risk to legal  and natural persons. Finally, AI systems  used to evaluate and classify emergency  calls by natural persons or to dispatch or  establish priority in the dispatching of  emergency first response services should  also be classified as high-risk since they  make decisions in very critical situations  for the life and health of persons and their  property.  Amendment 68 Proposal for a regulation Recital 37 a (new) Text proposed by the Commission Amendment (37a) Given the role and responsibility of  police and judicial authorities, and the  impact of decisions they take for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences or the execution of criminal  penalties, some specific use-cases of AI  applications in law enforcement has to be  classified as high-risk, in particular in  instances where there is the potential to  significantly affect the lives or the  fundamental rights of individuals. Amendment 69 Proposal for a regulation Recital 38 Text proposed by the Commission Amendment (38) Actions by law enforcement  authorities involving certain uses of AI  systems are characterised by a significant  degree of power imbalance and may lead to  surveillance, arrest or deprivation of a  natural person’s liberty as well as other  adverse impacts on fundamental rights  guaranteed in the Charter",What is the purpose of the proposed Regulation regarding AI systems?,"['To promote the development and use of innovative AI systems in public administration.', 'To classify AI systems used in law enforcement as high-risk.', 'To ensure that AI systems do not entail a high risk to legal and natural persons.', 'To prevent the use of AI systems that perpetuate discrimination based on personal characteristics.']",2