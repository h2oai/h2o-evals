filename,context,Question,Choices,Answer
AI-Act-FullText.pdf,"2021/0106 (COD)   Proposal for a   REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL   LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE  (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION  LEGISLATIVE ACTS   THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,   Having regard to the Treaty on the Functioning of the European Union, and in particular Articles 16  and 114 thereof,   Having regard to the proposal from the European Commission,   After transmission of the draft legislative act to the national parliaments,   Having regard to the opinion of the European Economic and Social Committee1,  Having regard to the opinion of the European Central Bank2,  Having regard to the joint opinion of the European Data Protection Board and the European Data  Protection Supervisor,   Having regard to the opinion of the Committee of the Regions3,  Acting in accordance with the ordinary legislative procedure,   Whereas:   (1) The purpose of this Regulation is to improve the functioning of the internal market by  laying down a uniform legal framework in particular for the development, placing on the  market, putting into service and the use of artificial intelligence systems in the Union in    1 OJ C […], […], p. […].   2 Reference to ECB opinion   3 OJ C […], […], p. […].  conformity with Union values,  to promote the uptake of human centric and  trustworthy  artificial intelligence while ensuring a high level of protection of health, safety,  fundamental rights enshrined in the Charter, including democracy  and rule of law and  environmental protection, against harmful effects of artificial intelligence  systems in the  Union and to support innovation. This regulation ensures the free movement of AI -based  goods and services cross -border, thus preventing Member States from imposing  restrictions on the development, marketing and use of Artificial Intelligence systems (AI  systems), unless explicitly authorised by this Regulation.   (1a) This Regulation should be applied in conformity with the values of the Union enshrined in  the Charter facilitating the protection of individuals, companies, democracy and rule of law  and the environment  while boosting innovation and employment and making the Union a  leader in the  uptake of trustworthy AI.   (2) AI systems can be easily deployed in multiple sectors of the economy and society,  including cross border, and circulate throughout the Union. Certain Member States have  already explored the adoption of national rules to ensure that artificial intelligence is  trustworthy and safe and is developed and used in compliance with fundamental rights  obligations. Differing national rules may lead to fragmentation of the internal market and  decrease legal certainty for operators that develop, import or use AI systems. A consistent  and high level of protection throughout the Union should therefore be ensured in order to  achieve trustworthy AI, while divergences hampering the free circulation, innovation,  deployment and uptake of AI systems and related products and services within the internal  market should be prevented, by laying down uniform obligations for operators and  guaranteeing the uniform protection of overriding reasons of public interest and of rights of  persons throughout the internal market based on Article 114 of the Treaty on the  Functioning of the European Union (TFEU). To the extent that this Regulation contains  specific rules on the protection of individuals with regard to the processing of personal data  concerning restrictions of the use of AI systems for  remote biometric identification for the  purpose of law enforcement, for the use of AI systems for risk assessments of natural  persons for the purpose of law enforcement and for the use of AI systems of biometric  categorization for the purpose of law enforcement, it is appropriate to base this Regulation,  in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities",What are the values of the Union that should be respected when applying this Regulation?,"['Respect, dignity, freedom, equality, rule of law, and democracy.', 'Efficiency, productivity, innovation, and competitiveness.', 'Sustainability, environmental protection, and social responsibility.', 'Security, stability, and economic growth.']",0
AI-Act-FullText.pdf,"2021/0106 (COD)   Proposal for a   REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL   LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE  (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION  LEGISLATIVE ACTS   THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,   Having regard to the Treaty on the Functioning of the European Union, and in particular Articles 16  and 114 thereof,   Having regard to the proposal from the European Commission,   After transmission of the draft legislative act to the national parliaments,   Having regard to the opinion of the European Economic and Social Committee1,  Having regard to the opinion of the European Central Bank2,  Having regard to the joint opinion of the European Data Protection Board and the European Data  Protection Supervisor,   Having regard to the opinion of the Committee of the Regions3,  Acting in accordance with the ordinary legislative procedure,   Whereas:   (1) The purpose of this Regulation is to improve the functioning of the internal market by  laying down a uniform legal framework in particular for the development, placing on the  market, putting into service and the use of artificial intelligence systems in the Union in    1 OJ C […], […], p. […].   2 Reference to ECB opinion   3 OJ C […], […], p. […].  conformity with Union values,  to promote the uptake of human centric and  trustworthy  artificial intelligence while ensuring a high level of protection of health, safety,  fundamental rights enshrined in the Charter, including democracy  and rule of law and  environmental protection, against harmful effects of artificial intelligence  systems in the  Union and to support innovation. This regulation ensures the free movement of AI -based  goods and services cross -border, thus preventing Member States from imposing  restrictions on the development, marketing and use of Artificial Intelligence systems (AI  systems), unless explicitly authorised by this Regulation.   (1a) This Regulation should be applied in conformity with the values of the Union enshrined in  the Charter facilitating the protection of individuals, companies, democracy and rule of law  and the environment  while boosting innovation and employment and making the Union a  leader in the  uptake of trustworthy AI.   (2) AI systems can be easily deployed in multiple sectors of the economy and society,  including cross border, and circulate throughout the Union. Certain Member States have  already explored the adoption of national rules to ensure that artificial intelligence is  trustworthy and safe and is developed and used in compliance with fundamental rights  obligations. Differing national rules may lead to fragmentation of the internal market and  decrease legal certainty for operators that develop, import or use AI systems. A consistent  and high level of protection throughout the Union should therefore be ensured in order to  achieve trustworthy AI, while divergences hampering the free circulation, innovation,  deployment and uptake of AI systems and related products and services within the internal  market should be prevented, by laying down uniform obligations for operators and  guaranteeing the uniform protection of overriding reasons of public interest and of rights of  persons throughout the internal market based on Article 114 of the Treaty on the  Functioning of the European Union (TFEU). To the extent that this Regulation contains  specific rules on the protection of individuals with regard to the processing of personal data  concerning restrictions of the use of AI systems for  remote biometric identification for the  purpose of law enforcement, for the use of AI systems for risk assessments of natural  persons for the purpose of law enforcement and for the use of AI systems of biometric  categorization for the purpose of law enforcement, it is appropriate to base this Regulation,  in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities",Why is a uniform legal framework for AI necessary?,"['To ensure that AI systems are developed and used in compliance with fundamental rights and obligations.', 'To prevent divergences in national rules from hampering the free circulation, innovation, deployment, and uptake of AI systems.', 'To ensure that AI systems are safe and trustworthy and developed and used in compliance with environmental protection.', 'To promote the uptake of human-centric and trustworthy AI while ensuring a high level of protection of health, safety, and fundamental rights enshrined in the Charter, including democracy and rule of law, and environmental protection against harmful effects of AI systems in the Union.']",3
AI-Act-FullText.pdf,"2021/0106 (COD)   Proposal for a   REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL   LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE  (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION  LEGISLATIVE ACTS   THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,   Having regard to the Treaty on the Functioning of the European Union, and in particular Articles 16  and 114 thereof,   Having regard to the proposal from the European Commission,   After transmission of the draft legislative act to the national parliaments,   Having regard to the opinion of the European Economic and Social Committee1,  Having regard to the opinion of the European Central Bank2,  Having regard to the joint opinion of the European Data Protection Board and the European Data  Protection Supervisor,   Having regard to the opinion of the Committee of the Regions3,  Acting in accordance with the ordinary legislative procedure,   Whereas:   (1) The purpose of this Regulation is to improve the functioning of the internal market by  laying down a uniform legal framework in particular for the development, placing on the  market, putting into service and the use of artificial intelligence systems in the Union in    1 OJ C […], […], p. […].   2 Reference to ECB opinion   3 OJ C […], […], p. […].  conformity with Union values,  to promote the uptake of human centric and  trustworthy  artificial intelligence while ensuring a high level of protection of health, safety,  fundamental rights enshrined in the Charter, including democracy  and rule of law and  environmental protection, against harmful effects of artificial intelligence  systems in the  Union and to support innovation. This regulation ensures the free movement of AI -based  goods and services cross -border, thus preventing Member States from imposing  restrictions on the development, marketing and use of Artificial Intelligence systems (AI  systems), unless explicitly authorised by this Regulation.   (1a) This Regulation should be applied in conformity with the values of the Union enshrined in  the Charter facilitating the protection of individuals, companies, democracy and rule of law  and the environment  while boosting innovation and employment and making the Union a  leader in the  uptake of trustworthy AI.   (2) AI systems can be easily deployed in multiple sectors of the economy and society,  including cross border, and circulate throughout the Union. Certain Member States have  already explored the adoption of national rules to ensure that artificial intelligence is  trustworthy and safe and is developed and used in compliance with fundamental rights  obligations. Differing national rules may lead to fragmentation of the internal market and  decrease legal certainty for operators that develop, import or use AI systems. A consistent  and high level of protection throughout the Union should therefore be ensured in order to  achieve trustworthy AI, while divergences hampering the free circulation, innovation,  deployment and uptake of AI systems and related products and services within the internal  market should be prevented, by laying down uniform obligations for operators and  guaranteeing the uniform protection of overriding reasons of public interest and of rights of  persons throughout the internal market based on Article 114 of the Treaty on the  Functioning of the European Union (TFEU). To the extent that this Regulation contains  specific rules on the protection of individuals with regard to the processing of personal data  concerning restrictions of the use of AI systems for  remote biometric identification for the  purpose of law enforcement, for the use of AI systems for risk assessments of natural  persons for the purpose of law enforcement and for the use of AI systems of biometric  categorization for the purpose of law enforcement, it is appropriate to base this Regulation,  in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities",Who is responsible for ensuring compliance with the Regulation?,"['The European Parliament and the Council of the European Union', 'The European Commission', 'The national parliaments of the Member States', 'The operators that develop, import, or use AI systems']",1
AI-Act-FullText.pdf,"2021/0106 (COD)   Proposal for a   REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL   LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE  (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION  LEGISLATIVE ACTS   THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,   Having regard to the Treaty on the Functioning of the European Union, and in particular Articles 16  and 114 thereof,   Having regard to the proposal from the European Commission,   After transmission of the draft legislative act to the national parliaments,   Having regard to the opinion of the European Economic and Social Committee1,  Having regard to the opinion of the European Central Bank2,  Having regard to the joint opinion of the European Data Protection Board and the European Data  Protection Supervisor,   Having regard to the opinion of the Committee of the Regions3,  Acting in accordance with the ordinary legislative procedure,   Whereas:   (1) The purpose of this Regulation is to improve the functioning of the internal market by  laying down a uniform legal framework in particular for the development, placing on the  market, putting into service and the use of artificial intelligence systems in the Union in    1 OJ C […], […], p. […].   2 Reference to ECB opinion   3 OJ C […], […], p. […].  conformity with Union values,  to promote the uptake of human centric and  trustworthy  artificial intelligence while ensuring a high level of protection of health, safety,  fundamental rights enshrined in the Charter, including democracy  and rule of law and  environmental protection, against harmful effects of artificial intelligence  systems in the  Union and to support innovation. This regulation ensures the free movement of AI -based  goods and services cross -border, thus preventing Member States from imposing  restrictions on the development, marketing and use of Artificial Intelligence systems (AI  systems), unless explicitly authorised by this Regulation.   (1a) This Regulation should be applied in conformity with the values of the Union enshrined in  the Charter facilitating the protection of individuals, companies, democracy and rule of law  and the environment  while boosting innovation and employment and making the Union a  leader in the  uptake of trustworthy AI.   (2) AI systems can be easily deployed in multiple sectors of the economy and society,  including cross border, and circulate throughout the Union. Certain Member States have  already explored the adoption of national rules to ensure that artificial intelligence is  trustworthy and safe and is developed and used in compliance with fundamental rights  obligations. Differing national rules may lead to fragmentation of the internal market and  decrease legal certainty for operators that develop, import or use AI systems. A consistent  and high level of protection throughout the Union should therefore be ensured in order to  achieve trustworthy AI, while divergences hampering the free circulation, innovation,  deployment and uptake of AI systems and related products and services within the internal  market should be prevented, by laying down uniform obligations for operators and  guaranteeing the uniform protection of overriding reasons of public interest and of rights of  persons throughout the internal market based on Article 114 of the Treaty on the  Functioning of the European Union (TFEU). To the extent that this Regulation contains  specific rules on the protection of individuals with regard to the processing of personal data  concerning restrictions of the use of AI systems for  remote biometric identification for the  purpose of law enforcement, for the use of AI systems for risk assessments of natural  persons for the purpose of law enforcement and for the use of AI systems of biometric  categorization for the purpose of law enforcement, it is appropriate to base this Regulation,  in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities",What is the role of the European Data Protection Board in relation to the Regulation?,"['The European Data Protection Board is consulted on specific rules regarding the protection of individuals with regard to the processing of personal data.', 'The European Data Protection Board is responsible for ensuring a high level of protection of health, safety, fundamental rights, and environmental protection.', 'The European Data Protection Board is responsible for promoting the uptake of human-centric and trustworthy artificial intelligence.', 'The European Data Protection Board is responsible for laying down uniform obligations for operators and guaranteeing uniform protection of overriding reasons of public interest and rights of persons throughout the internal market.']",0
AI-Act-FullText.pdf,"The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems.  In cooperation with the relevant stakeholders, the Commission and the Member States  should facilitate the drawing up of voluntary codes of conduct to advance AI literacy  among persons dealing with the development, operation and use of AI .  (10) In order to ensure a level playing field and an effective protection of rights and freedoms of  individuals across the Union, the rules established by this Regulation should apply to  providers of AI systems in a non -discriminatory manner, irrespective of whether they are  established within the Union or in a third country, and to deployers of AI systems  established within the Union.   (11) In light of their digital nature, certain AI systems should fall within the scope of this  Regulation even when they are neither placed on the market, nor put into service, nor used  in the Union. This is the case for example of an operator established in the Union that  contracts certain services to an operator established outside the Union in relation to an  activity to be performed by an AI system that would qualify as high -risk. In those  circumstances, the AI system used by the operator outside the Uni on could process data  lawfully collected in and transferred from the Union, and provide to the contracting  operator in the Union the output of that AI system resulting from that processing, without  that AI system being placed on the market, put into service or used in the Union. To  prevent the circumvention of this Regulation and to ensure an effective protection of  natural persons located in the Union, this Regulation should also apply to providers and  deployers of AI systems that are established in a thir d country, to the extent the output  produced by those systems is intended to be used in the Union. Nonetheless, to take into  account existing arrangements and special needs for future cooperation with foreign  partners with whom information and evidence is exchanged, this Regulation should not  apply to public authorities of a third country and international organisations when acting in  the framework of cooperation or international agreements concluded at national or  European level for law enforcement and jud icial cooperation with the Union or with its  Member States, under the condition that this third country or international organisations  provide adequate safeguards with respect to the protection of fundamental rights and  freedoms of individuals. Where relevant, this may also cover activities of entities entrusted  by the third countries to carry out specific tasks in support of such law enforcement and  judicial cooperation. Such framework for cooperation or agreements have been  established  bilaterally betwee n Member States and third countries or between the European Union,  Europol and other EU agencies and third countries and international organisations. The  authorities competent for supervision of the law enforcement and judicial authorities under  the AI Act should assess whether these frameworks for cooperation or international  agreements include adequate safeguards with respect to the protection of fundamental  rights and freedoms of individuals.  Recipient Member States authorities and Union institutions, offices and bodies making use of such outputs in the Union remain  accountable to ensure their use complies with Union law. When those international  agreements are revised or new ones are concluded in the future, the contracting parties  should undertake the utmost effort to align those agreements with the requirements of this  Regulation.   (12) This Regulation should also apply to Union institutions, offices, bodies and agencies when  acting as a provider or deployer of an AI system.   (12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity",Who should facilitate the drawing up of voluntary codes of conduct for AI literacy?,"['The European Artificial Intelligence Board', 'The Commission and the Member States', 'Relevant stakeholders', 'Providers of AI systems']",1
AI-Act-FullText.pdf,"The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems.  In cooperation with the relevant stakeholders, the Commission and the Member States  should facilitate the drawing up of voluntary codes of conduct to advance AI literacy  among persons dealing with the development, operation and use of AI .  (10) In order to ensure a level playing field and an effective protection of rights and freedoms of  individuals across the Union, the rules established by this Regulation should apply to  providers of AI systems in a non -discriminatory manner, irrespective of whether they are  established within the Union or in a third country, and to deployers of AI systems  established within the Union.   (11) In light of their digital nature, certain AI systems should fall within the scope of this  Regulation even when they are neither placed on the market, nor put into service, nor used  in the Union. This is the case for example of an operator established in the Union that  contracts certain services to an operator established outside the Union in relation to an  activity to be performed by an AI system that would qualify as high -risk. In those  circumstances, the AI system used by the operator outside the Uni on could process data  lawfully collected in and transferred from the Union, and provide to the contracting  operator in the Union the output of that AI system resulting from that processing, without  that AI system being placed on the market, put into service or used in the Union. To  prevent the circumvention of this Regulation and to ensure an effective protection of  natural persons located in the Union, this Regulation should also apply to providers and  deployers of AI systems that are established in a thir d country, to the extent the output  produced by those systems is intended to be used in the Union. Nonetheless, to take into  account existing arrangements and special needs for future cooperation with foreign  partners with whom information and evidence is exchanged, this Regulation should not  apply to public authorities of a third country and international organisations when acting in  the framework of cooperation or international agreements concluded at national or  European level for law enforcement and jud icial cooperation with the Union or with its  Member States, under the condition that this third country or international organisations  provide adequate safeguards with respect to the protection of fundamental rights and  freedoms of individuals. Where relevant, this may also cover activities of entities entrusted  by the third countries to carry out specific tasks in support of such law enforcement and  judicial cooperation. Such framework for cooperation or agreements have been  established  bilaterally betwee n Member States and third countries or between the European Union,  Europol and other EU agencies and third countries and international organisations. The  authorities competent for supervision of the law enforcement and judicial authorities under  the AI Act should assess whether these frameworks for cooperation or international  agreements include adequate safeguards with respect to the protection of fundamental  rights and freedoms of individuals.  Recipient Member States authorities and Union institutions, offices and bodies making use of such outputs in the Union remain  accountable to ensure their use complies with Union law. When those international  agreements are revised or new ones are concluded in the future, the contracting parties  should undertake the utmost effort to align those agreements with the requirements of this  Regulation.   (12) This Regulation should also apply to Union institutions, offices, bodies and agencies when  acting as a provider or deployer of an AI system.   (12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity",How should the rules established by this Regulation apply to providers of AI systems?,"['The rules should apply to providers of AI systems established within the Union only.', 'The rules should apply to providers of AI systems established within the Union and in third countries.', 'The rules should apply to providers of AI systems established in third countries only.', 'The rules should not apply to providers of AI systems established in third countries with which the Union has concluded international agreements for law enforcement and judicial cooperation.']",1
AI-Act-FullText.pdf,"The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems.  In cooperation with the relevant stakeholders, the Commission and the Member States  should facilitate the drawing up of voluntary codes of conduct to advance AI literacy  among persons dealing with the development, operation and use of AI .  (10) In order to ensure a level playing field and an effective protection of rights and freedoms of  individuals across the Union, the rules established by this Regulation should apply to  providers of AI systems in a non -discriminatory manner, irrespective of whether they are  established within the Union or in a third country, and to deployers of AI systems  established within the Union.   (11) In light of their digital nature, certain AI systems should fall within the scope of this  Regulation even when they are neither placed on the market, nor put into service, nor used  in the Union. This is the case for example of an operator established in the Union that  contracts certain services to an operator established outside the Union in relation to an  activity to be performed by an AI system that would qualify as high -risk. In those  circumstances, the AI system used by the operator outside the Uni on could process data  lawfully collected in and transferred from the Union, and provide to the contracting  operator in the Union the output of that AI system resulting from that processing, without  that AI system being placed on the market, put into service or used in the Union. To  prevent the circumvention of this Regulation and to ensure an effective protection of  natural persons located in the Union, this Regulation should also apply to providers and  deployers of AI systems that are established in a thir d country, to the extent the output  produced by those systems is intended to be used in the Union. Nonetheless, to take into  account existing arrangements and special needs for future cooperation with foreign  partners with whom information and evidence is exchanged, this Regulation should not  apply to public authorities of a third country and international organisations when acting in  the framework of cooperation or international agreements concluded at national or  European level for law enforcement and jud icial cooperation with the Union or with its  Member States, under the condition that this third country or international organisations  provide adequate safeguards with respect to the protection of fundamental rights and  freedoms of individuals. Where relevant, this may also cover activities of entities entrusted  by the third countries to carry out specific tasks in support of such law enforcement and  judicial cooperation. Such framework for cooperation or agreements have been  established  bilaterally betwee n Member States and third countries or between the European Union,  Europol and other EU agencies and third countries and international organisations. The  authorities competent for supervision of the law enforcement and judicial authorities under  the AI Act should assess whether these frameworks for cooperation or international  agreements include adequate safeguards with respect to the protection of fundamental  rights and freedoms of individuals.  Recipient Member States authorities and Union institutions, offices and bodies making use of such outputs in the Union remain  accountable to ensure their use complies with Union law. When those international  agreements are revised or new ones are concluded in the future, the contracting parties  should undertake the utmost effort to align those agreements with the requirements of this  Regulation.   (12) This Regulation should also apply to Union institutions, offices, bodies and agencies when  acting as a provider or deployer of an AI system.   (12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity",When should an AI system used by an operator outside the Union be subject to this Regulation?,"['When the AI system is placed on the market or put into service in the Union.', 'When the output produced by the AI system is intended to be used in the Union.', 'When the AI system is developed or deployed by a provider established in the Union.', 'When the AI system is used for military, defense, or national security purposes.']",1
AI-Act-FullText.pdf,"The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems.  In cooperation with the relevant stakeholders, the Commission and the Member States  should facilitate the drawing up of voluntary codes of conduct to advance AI literacy  among persons dealing with the development, operation and use of AI .  (10) In order to ensure a level playing field and an effective protection of rights and freedoms of  individuals across the Union, the rules established by this Regulation should apply to  providers of AI systems in a non -discriminatory manner, irrespective of whether they are  established within the Union or in a third country, and to deployers of AI systems  established within the Union.   (11) In light of their digital nature, certain AI systems should fall within the scope of this  Regulation even when they are neither placed on the market, nor put into service, nor used  in the Union. This is the case for example of an operator established in the Union that  contracts certain services to an operator established outside the Union in relation to an  activity to be performed by an AI system that would qualify as high -risk. In those  circumstances, the AI system used by the operator outside the Uni on could process data  lawfully collected in and transferred from the Union, and provide to the contracting  operator in the Union the output of that AI system resulting from that processing, without  that AI system being placed on the market, put into service or used in the Union. To  prevent the circumvention of this Regulation and to ensure an effective protection of  natural persons located in the Union, this Regulation should also apply to providers and  deployers of AI systems that are established in a thir d country, to the extent the output  produced by those systems is intended to be used in the Union. Nonetheless, to take into  account existing arrangements and special needs for future cooperation with foreign  partners with whom information and evidence is exchanged, this Regulation should not  apply to public authorities of a third country and international organisations when acting in  the framework of cooperation or international agreements concluded at national or  European level for law enforcement and jud icial cooperation with the Union or with its  Member States, under the condition that this third country or international organisations  provide adequate safeguards with respect to the protection of fundamental rights and  freedoms of individuals. Where relevant, this may also cover activities of entities entrusted  by the third countries to carry out specific tasks in support of such law enforcement and  judicial cooperation. Such framework for cooperation or agreements have been  established  bilaterally betwee n Member States and third countries or between the European Union,  Europol and other EU agencies and third countries and international organisations. The  authorities competent for supervision of the law enforcement and judicial authorities under  the AI Act should assess whether these frameworks for cooperation or international  agreements include adequate safeguards with respect to the protection of fundamental  rights and freedoms of individuals.  Recipient Member States authorities and Union institutions, offices and bodies making use of such outputs in the Union remain  accountable to ensure their use complies with Union law. When those international  agreements are revised or new ones are concluded in the future, the contracting parties  should undertake the utmost effort to align those agreements with the requirements of this  Regulation.   (12) This Regulation should also apply to Union institutions, offices, bodies and agencies when  acting as a provider or deployer of an AI system.   (12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity",Should public authorities of a third country and international organizations be subject to this Regulation?,"['Yes, they should be subject to this Regulation, irrespective of any international agreements or arrangements.', 'No, they should not be subject to this Regulation, as they are not established in the Union.', 'Yes, they should be subject to this Regulation, but only when they are acting in the framework of cooperation or international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or its Member States.', 'No, they should not be subject to this Regulation, as they are not bound by Union law.']",2
AI-Act-FullText.pdf,"The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems.  In cooperation with the relevant stakeholders, the Commission and the Member States  should facilitate the drawing up of voluntary codes of conduct to advance AI literacy  among persons dealing with the development, operation and use of AI .  (10) In order to ensure a level playing field and an effective protection of rights and freedoms of  individuals across the Union, the rules established by this Regulation should apply to  providers of AI systems in a non -discriminatory manner, irrespective of whether they are  established within the Union or in a third country, and to deployers of AI systems  established within the Union.   (11) In light of their digital nature, certain AI systems should fall within the scope of this  Regulation even when they are neither placed on the market, nor put into service, nor used  in the Union. This is the case for example of an operator established in the Union that  contracts certain services to an operator established outside the Union in relation to an  activity to be performed by an AI system that would qualify as high -risk. In those  circumstances, the AI system used by the operator outside the Uni on could process data  lawfully collected in and transferred from the Union, and provide to the contracting  operator in the Union the output of that AI system resulting from that processing, without  that AI system being placed on the market, put into service or used in the Union. To  prevent the circumvention of this Regulation and to ensure an effective protection of  natural persons located in the Union, this Regulation should also apply to providers and  deployers of AI systems that are established in a thir d country, to the extent the output  produced by those systems is intended to be used in the Union. Nonetheless, to take into  account existing arrangements and special needs for future cooperation with foreign  partners with whom information and evidence is exchanged, this Regulation should not  apply to public authorities of a third country and international organisations when acting in  the framework of cooperation or international agreements concluded at national or  European level for law enforcement and jud icial cooperation with the Union or with its  Member States, under the condition that this third country or international organisations  provide adequate safeguards with respect to the protection of fundamental rights and  freedoms of individuals. Where relevant, this may also cover activities of entities entrusted  by the third countries to carry out specific tasks in support of such law enforcement and  judicial cooperation. Such framework for cooperation or agreements have been  established  bilaterally betwee n Member States and third countries or between the European Union,  Europol and other EU agencies and third countries and international organisations. The  authorities competent for supervision of the law enforcement and judicial authorities under  the AI Act should assess whether these frameworks for cooperation or international  agreements include adequate safeguards with respect to the protection of fundamental  rights and freedoms of individuals.  Recipient Member States authorities and Union institutions, offices and bodies making use of such outputs in the Union remain  accountable to ensure their use complies with Union law. When those international  agreements are revised or new ones are concluded in the future, the contracting parties  should undertake the utmost effort to align those agreements with the requirements of this  Regulation.   (12) This Regulation should also apply to Union institutions, offices, bodies and agencies when  acting as a provider or deployer of an AI system.   (12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity",Who should assess whether frameworks for cooperation or international agreements include adequate safeguards?,"['The European Artificial Intelligence Board', 'The authorities competent for supervision of the law enforcement and judicial authorities under the AI Act', 'The contracting parties to the international agreements', 'The provider or deployer of an AI system']",1
AI-Act-FullText.pdf,"The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems.  In cooperation with the relevant stakeholders, the Commission and the Member States  should facilitate the drawing up of voluntary codes of conduct to advance AI literacy  among persons dealing with the development, operation and use of AI .  (10) In order to ensure a level playing field and an effective protection of rights and freedoms of  individuals across the Union, the rules established by this Regulation should apply to  providers of AI systems in a non -discriminatory manner, irrespective of whether they are  established within the Union or in a third country, and to deployers of AI systems  established within the Union.   (11) In light of their digital nature, certain AI systems should fall within the scope of this  Regulation even when they are neither placed on the market, nor put into service, nor used  in the Union. This is the case for example of an operator established in the Union that  contracts certain services to an operator established outside the Union in relation to an  activity to be performed by an AI system that would qualify as high -risk. In those  circumstances, the AI system used by the operator outside the Uni on could process data  lawfully collected in and transferred from the Union, and provide to the contracting  operator in the Union the output of that AI system resulting from that processing, without  that AI system being placed on the market, put into service or used in the Union. To  prevent the circumvention of this Regulation and to ensure an effective protection of  natural persons located in the Union, this Regulation should also apply to providers and  deployers of AI systems that are established in a thir d country, to the extent the output  produced by those systems is intended to be used in the Union. Nonetheless, to take into  account existing arrangements and special needs for future cooperation with foreign  partners with whom information and evidence is exchanged, this Regulation should not  apply to public authorities of a third country and international organisations when acting in  the framework of cooperation or international agreements concluded at national or  European level for law enforcement and jud icial cooperation with the Union or with its  Member States, under the condition that this third country or international organisations  provide adequate safeguards with respect to the protection of fundamental rights and  freedoms of individuals. Where relevant, this may also cover activities of entities entrusted  by the third countries to carry out specific tasks in support of such law enforcement and  judicial cooperation. Such framework for cooperation or agreements have been  established  bilaterally betwee n Member States and third countries or between the European Union,  Europol and other EU agencies and third countries and international organisations. The  authorities competent for supervision of the law enforcement and judicial authorities under  the AI Act should assess whether these frameworks for cooperation or international  agreements include adequate safeguards with respect to the protection of fundamental  rights and freedoms of individuals.  Recipient Member States authorities and Union institutions, offices and bodies making use of such outputs in the Union remain  accountable to ensure their use complies with Union law. When those international  agreements are revised or new ones are concluded in the future, the contracting parties  should undertake the utmost effort to align those agreements with the requirements of this  Regulation.   (12) This Regulation should also apply to Union institutions, offices, bodies and agencies when  acting as a provider or deployer of an AI system.   (12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity","Are Union institutions, offices, bodies, and agencies subject to this Regulation?","['Yes, they are subject to this Regulation when acting as a provider or deployer of an AI system.', 'No, they are not subject to this Regulation when acting as a provider or deployer of an AI system.', 'Yes, they are subject to this Regulation only when using AI systems for military, defense, or national security purposes.', 'No, they are not subject to this Regulation when using AI systems for military, defense, or national security purposes.']",0
AI-Act-FullText.pdf,"In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities. By improving prediction, optimising operations and  resource allocation, and personalising digital solutions available for individuals and  organisations, the use of artificial intelligence can provide key competitive advantages to  companies and support socially and environmentally beneficial outcomes, for example in  healthcare, farming, food safety, education and training, media, sports, culture,  infrastructure management, energy, transport and logistics, public services, security,  justice, resource and energy efficiency, environmental monitoring, the conservation and  restoration of biodiversity and ecosystems and climate change mitigation and adaptation .   (4) At the same time, depending on the circumstances regarding its specific application, use,  and level of technological development, artificial intelligence may generate risks and cause  harm to public interests and fundamental rights that are protected by Union law. Such harm  might be material or immaterial, including physical, psychological, societal or economic  harm.   (4a) Given the major impact that artificial intelligence can have on society and the need to build  trust, it is vital for artificial intelligence and its regulatory framework to be developed  according to Union values enshrined in Article 2 TEU, the fundamental rights and  freedoms enshrined in the Treaties, the Charter. As a pre -requisite, artificial intelligence  should be a human -centric technology. It should serve as a tool for people, with the  ultimate aim of increasing human well -being.   (4aa) In order to ensure a consistent and high level of protection of public interests as  regards health, safety and fundamental rights, common rules for all high -risk AI systems  should be established. Those rules should be consistent with the Charter of fundamental  rights of the European Union (the Charter) and should be non -discriminatory and in line  with the Union’s international trade commitments. They should also take into account the  European Declaration on Digital Rights and Principles for the Digital Decade (2023/C  23/01) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High - Level Expert Group on Artificial Intelligence.   (5) A Union legal framework laying down harmonised rules on artificial intelligence is  therefore needed to foster the development, use and uptake of artificial intelligence in the  internal market that at the same time meets a high level of protection of public interests,  such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by Union law. To  achieve that objective, rules regulating the placing on the market, putting into service and  use of certain AI systems should be laid down, thus ensuring the smooth functioning of the  internal market and allowing those systems to benefit from the principle of free movement  of goods and services. These rules should be clear and robust in protecting fundamental  rights, supportive of new innovative solutions,  enabling to a E uropean ecosystem of public  and private actors creating AI systems in line with Union values and unlocking the  potential of the digital transformation across all regions of the Union. By laying down  those rules as well as measures in support of innovation with a particular focus on SMEs  including startups, this Regulation supports the objective of promoting the European  human -centric approach to AI and being a global leader in the development of secure,  trustworthy and ethical artificial intelligence as sta ted by the European Council4, and it  ensures the protection of ethical principles, as specifically requested by the the European  Parliament5",What is the purpose of the European Data Protection Board's consultation on artificial intelligence?,"['To establish a set of common rules for all high-risk AI systems across the European Union.', 'To ensure that the development and use of AI meets a high level of protection of public interests, such as health and safety, and the protection of fundamental rights.', 'To promote the European human-centric approach to AI and ensure the protection of ethical principles.', 'To provide support for innovation, particularly for SMEs and startups, in the development of secure, trustworthy, and ethical AI systems.']",1
AI-Act-FullText.pdf,"In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities. By improving prediction, optimising operations and  resource allocation, and personalising digital solutions available for individuals and  organisations, the use of artificial intelligence can provide key competitive advantages to  companies and support socially and environmentally beneficial outcomes, for example in  healthcare, farming, food safety, education and training, media, sports, culture,  infrastructure management, energy, transport and logistics, public services, security,  justice, resource and energy efficiency, environmental monitoring, the conservation and  restoration of biodiversity and ecosystems and climate change mitigation and adaptation .   (4) At the same time, depending on the circumstances regarding its specific application, use,  and level of technological development, artificial intelligence may generate risks and cause  harm to public interests and fundamental rights that are protected by Union law. Such harm  might be material or immaterial, including physical, psychological, societal or economic  harm.   (4a) Given the major impact that artificial intelligence can have on society and the need to build  trust, it is vital for artificial intelligence and its regulatory framework to be developed  according to Union values enshrined in Article 2 TEU, the fundamental rights and  freedoms enshrined in the Treaties, the Charter. As a pre -requisite, artificial intelligence  should be a human -centric technology. It should serve as a tool for people, with the  ultimate aim of increasing human well -being.   (4aa) In order to ensure a consistent and high level of protection of public interests as  regards health, safety and fundamental rights, common rules for all high -risk AI systems  should be established. Those rules should be consistent with the Charter of fundamental  rights of the European Union (the Charter) and should be non -discriminatory and in line  with the Union’s international trade commitments. They should also take into account the  European Declaration on Digital Rights and Principles for the Digital Decade (2023/C  23/01) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High - Level Expert Group on Artificial Intelligence.   (5) A Union legal framework laying down harmonised rules on artificial intelligence is  therefore needed to foster the development, use and uptake of artificial intelligence in the  internal market that at the same time meets a high level of protection of public interests,  such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by Union law. To  achieve that objective, rules regulating the placing on the market, putting into service and  use of certain AI systems should be laid down, thus ensuring the smooth functioning of the  internal market and allowing those systems to benefit from the principle of free movement  of goods and services. These rules should be clear and robust in protecting fundamental  rights, supportive of new innovative solutions,  enabling to a E uropean ecosystem of public  and private actors creating AI systems in line with Union values and unlocking the  potential of the digital transformation across all regions of the Union. By laying down  those rules as well as measures in support of innovation with a particular focus on SMEs  including startups, this Regulation supports the objective of promoting the European  human -centric approach to AI and being a global leader in the development of secure,  trustworthy and ethical artificial intelligence as sta ted by the European Council4, and it  ensures the protection of ethical principles, as specifically requested by the the European  Parliament5",What are the benefits of artificial intelligence across different industries and social activities?,"['Artificial intelligence provides key competitive advantages to companies and supports socially and environmentally beneficial outcomes in various sectors such as healthcare, farming, food safety, education and training, media, sports, culture, infrastructure management, energy, transport and logistics, public services, security, justice, resource and energy efficiency, environmental monitoring, the conservation and restoration of biodiversity and ecosystems and climate change mitigation and adaptation.']",0
AI-Act-FullText.pdf,"In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities. By improving prediction, optimising operations and  resource allocation, and personalising digital solutions available for individuals and  organisations, the use of artificial intelligence can provide key competitive advantages to  companies and support socially and environmentally beneficial outcomes, for example in  healthcare, farming, food safety, education and training, media, sports, culture,  infrastructure management, energy, transport and logistics, public services, security,  justice, resource and energy efficiency, environmental monitoring, the conservation and  restoration of biodiversity and ecosystems and climate change mitigation and adaptation .   (4) At the same time, depending on the circumstances regarding its specific application, use,  and level of technological development, artificial intelligence may generate risks and cause  harm to public interests and fundamental rights that are protected by Union law. Such harm  might be material or immaterial, including physical, psychological, societal or economic  harm.   (4a) Given the major impact that artificial intelligence can have on society and the need to build  trust, it is vital for artificial intelligence and its regulatory framework to be developed  according to Union values enshrined in Article 2 TEU, the fundamental rights and  freedoms enshrined in the Treaties, the Charter. As a pre -requisite, artificial intelligence  should be a human -centric technology. It should serve as a tool for people, with the  ultimate aim of increasing human well -being.   (4aa) In order to ensure a consistent and high level of protection of public interests as  regards health, safety and fundamental rights, common rules for all high -risk AI systems  should be established. Those rules should be consistent with the Charter of fundamental  rights of the European Union (the Charter) and should be non -discriminatory and in line  with the Union’s international trade commitments. They should also take into account the  European Declaration on Digital Rights and Principles for the Digital Decade (2023/C  23/01) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High - Level Expert Group on Artificial Intelligence.   (5) A Union legal framework laying down harmonised rules on artificial intelligence is  therefore needed to foster the development, use and uptake of artificial intelligence in the  internal market that at the same time meets a high level of protection of public interests,  such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by Union law. To  achieve that objective, rules regulating the placing on the market, putting into service and  use of certain AI systems should be laid down, thus ensuring the smooth functioning of the  internal market and allowing those systems to benefit from the principle of free movement  of goods and services. These rules should be clear and robust in protecting fundamental  rights, supportive of new innovative solutions,  enabling to a E uropean ecosystem of public  and private actors creating AI systems in line with Union values and unlocking the  potential of the digital transformation across all regions of the Union. By laying down  those rules as well as measures in support of innovation with a particular focus on SMEs  including startups, this Regulation supports the objective of promoting the European  human -centric approach to AI and being a global leader in the development of secure,  trustworthy and ethical artificial intelligence as sta ted by the European Council4, and it  ensures the protection of ethical principles, as specifically requested by the the European  Parliament5",What are the potential risks and harms associated with the use of artificial intelligence?,"['Physical, psychological, societal, and economic harm.', 'Immaterial, societal, and environmental harm.', 'Physical, psychological, and economic harm.', 'Environmental and societal harm.']",0
AI-Act-FullText.pdf,"In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities. By improving prediction, optimising operations and  resource allocation, and personalising digital solutions available for individuals and  organisations, the use of artificial intelligence can provide key competitive advantages to  companies and support socially and environmentally beneficial outcomes, for example in  healthcare, farming, food safety, education and training, media, sports, culture,  infrastructure management, energy, transport and logistics, public services, security,  justice, resource and energy efficiency, environmental monitoring, the conservation and  restoration of biodiversity and ecosystems and climate change mitigation and adaptation .   (4) At the same time, depending on the circumstances regarding its specific application, use,  and level of technological development, artificial intelligence may generate risks and cause  harm to public interests and fundamental rights that are protected by Union law. Such harm  might be material or immaterial, including physical, psychological, societal or economic  harm.   (4a) Given the major impact that artificial intelligence can have on society and the need to build  trust, it is vital for artificial intelligence and its regulatory framework to be developed  according to Union values enshrined in Article 2 TEU, the fundamental rights and  freedoms enshrined in the Treaties, the Charter. As a pre -requisite, artificial intelligence  should be a human -centric technology. It should serve as a tool for people, with the  ultimate aim of increasing human well -being.   (4aa) In order to ensure a consistent and high level of protection of public interests as  regards health, safety and fundamental rights, common rules for all high -risk AI systems  should be established. Those rules should be consistent with the Charter of fundamental  rights of the European Union (the Charter) and should be non -discriminatory and in line  with the Union’s international trade commitments. They should also take into account the  European Declaration on Digital Rights and Principles for the Digital Decade (2023/C  23/01) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High - Level Expert Group on Artificial Intelligence.   (5) A Union legal framework laying down harmonised rules on artificial intelligence is  therefore needed to foster the development, use and uptake of artificial intelligence in the  internal market that at the same time meets a high level of protection of public interests,  such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by Union law. To  achieve that objective, rules regulating the placing on the market, putting into service and  use of certain AI systems should be laid down, thus ensuring the smooth functioning of the  internal market and allowing those systems to benefit from the principle of free movement  of goods and services. These rules should be clear and robust in protecting fundamental  rights, supportive of new innovative solutions,  enabling to a E uropean ecosystem of public  and private actors creating AI systems in line with Union values and unlocking the  potential of the digital transformation across all regions of the Union. By laying down  those rules as well as measures in support of innovation with a particular focus on SMEs  including startups, this Regulation supports the objective of promoting the European  human -centric approach to AI and being a global leader in the development of secure,  trustworthy and ethical artificial intelligence as sta ted by the European Council4, and it  ensures the protection of ethical principles, as specifically requested by the the European  Parliament5",What is the importance of building trust in artificial intelligence?,"['To ensure that AI systems are developed according to Union values and fundamental rights enshrined in the Treaties and the Charter.', 'To promote the European human-centric approach to AI and being a global leader in the development of secure, trustworthy, and ethical artificial intelligence.', 'To allow the free movement of AI systems in the internal market, supporting new innovative solutions and unlocking the potential of the digital transformation across all regions of the Union.', 'To generate risks and cause harm to public interests and fundamental rights that are protected by Union law.']",1
AI-Act-FullText.pdf,"In light of those  specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the  European Data Protection Board.  (3) Artificial intelligence is a fast evolving family of technologies that contributes to a wide  array of economic, environmental and societal benefits across the entire spectrum of  industries and social activities. By improving prediction, optimising operations and  resource allocation, and personalising digital solutions available for individuals and  organisations, the use of artificial intelligence can provide key competitive advantages to  companies and support socially and environmentally beneficial outcomes, for example in  healthcare, farming, food safety, education and training, media, sports, culture,  infrastructure management, energy, transport and logistics, public services, security,  justice, resource and energy efficiency, environmental monitoring, the conservation and  restoration of biodiversity and ecosystems and climate change mitigation and adaptation .   (4) At the same time, depending on the circumstances regarding its specific application, use,  and level of technological development, artificial intelligence may generate risks and cause  harm to public interests and fundamental rights that are protected by Union law. Such harm  might be material or immaterial, including physical, psychological, societal or economic  harm.   (4a) Given the major impact that artificial intelligence can have on society and the need to build  trust, it is vital for artificial intelligence and its regulatory framework to be developed  according to Union values enshrined in Article 2 TEU, the fundamental rights and  freedoms enshrined in the Treaties, the Charter. As a pre -requisite, artificial intelligence  should be a human -centric technology. It should serve as a tool for people, with the  ultimate aim of increasing human well -being.   (4aa) In order to ensure a consistent and high level of protection of public interests as  regards health, safety and fundamental rights, common rules for all high -risk AI systems  should be established. Those rules should be consistent with the Charter of fundamental  rights of the European Union (the Charter) and should be non -discriminatory and in line  with the Union’s international trade commitments. They should also take into account the  European Declaration on Digital Rights and Principles for the Digital Decade (2023/C  23/01) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High - Level Expert Group on Artificial Intelligence.   (5) A Union legal framework laying down harmonised rules on artificial intelligence is  therefore needed to foster the development, use and uptake of artificial intelligence in the  internal market that at the same time meets a high level of protection of public interests,  such as health and safety and the protection of fundamental rights, including democracy, rule of law and environmental protection as recognised and protected by Union law. To  achieve that objective, rules regulating the placing on the market, putting into service and  use of certain AI systems should be laid down, thus ensuring the smooth functioning of the  internal market and allowing those systems to benefit from the principle of free movement  of goods and services. These rules should be clear and robust in protecting fundamental  rights, supportive of new innovative solutions,  enabling to a E uropean ecosystem of public  and private actors creating AI systems in line with Union values and unlocking the  potential of the digital transformation across all regions of the Union. By laying down  those rules as well as measures in support of innovation with a particular focus on SMEs  including startups, this Regulation supports the objective of promoting the European  human -centric approach to AI and being a global leader in the development of secure,  trustworthy and ethical artificial intelligence as sta ted by the European Council4, and it  ensures the protection of ethical principles, as specifically requested by the the European  Parliament5",What is the purpose of establishing common rules for high-risk AI systems?,"['To ensure a consistent and high level of protection of public interests, such as health, safety, and fundamental rights.', 'To promote the development of artificial intelligence in the internal market and support innovation, particularly for SMEs and startups.', 'To establish a European approach to AI that is centred on human values and ensures the protection of ethical principles.', 'To create a single market for AI systems across the Union and promote the free movement of goods and services.']",0
AI-Act-FullText.pdf,"This Regulation shall not apply to AI systems which are not placed on the market or put  into service in the Union, where the output is used in the Union exclusively for military,  defence or national security purposes, regardless of the type of entity carrying out those  activities.  4. This Regulation shall not apply to public authorities in a third country nor to international  organisations falling within the scope of this Regulation pursuant to paragraph 1, where  those authorities or organisations use AI systems in the framework of international  cooperation or agreements for law enforcement and judicial cooperation with the Union or  with one or more Member States, under the condition that  this third country or  international organisations provide adequate safeguards with respect to the protection of  fundamental rights and freedoms of individuals;   5. This Regulation shall not affect the application of the provisions on the liability of  intermediary service providers set out in Chapter II, Section 4 of Directive 2000/31/EC of  the European Parliament and of the Council29 [as to be replaced by  the corresponding  provisions of the Digital Services Act ].   5a. This Regulation shall not apply to AI systems and models, including their output,  specifically developed and put into service for the sole purpose of scientific research and  development.   5a. Union law on the protection of personal data, privacy and the confidentiality of  communications applies to personal data processed in connection with the rights and  obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU)  2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation;   5b. This Regulation shall not apply to any research, testing and development activity regarding  AI systems or models prior to  being placed on the market or put into service; those  activities shall be conducted respecting applicable Union law. The testing in real world  conditions shall not be covered by this exemption .  5b. This Regulation is without prejudice to the rules laid down by other Union legal acts  related to consumer protection and product safety.   5c. This Regulation shall not apply to obligations of deployers who are natural persons using  AI systems in the course of a purely personal non -professional activity.     29 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on  certain legal aspects of information society services, in particular electronic commerce, in  the Internal Market ('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).  5e. This Regulation shall not preclude Member States or the Union from maintaining or  introducing laws, regulations or administrative provisions which are more favourable to  workers in terms of protecting their rights in respect of the use of  AI systems by  employers, or to encourage or allow the application of collective agreements which are  more favourable to workers.   5g. The obligations laid down in this Regulation shall not apply to AI systems released under  free and open source licences unless they are placed on the market or put into service as  high-risk AI systems or an AI system that falls under Title II and IV.         (1) An AI system is a machine -based system designed to operate with varying levels of  autonomy and that may exhibit adaptiveness after deployment and that, for explicit  or implicit objectives, infers, from the input it receives, how to generate outputs such  as predictions, content, recommendations, or decisions that can influence physical or  virtual environments.",What types of AI systems are exempt from the Regulation?,"['AI systems used for military, defense, or national security purposes.', 'AI systems developed and used for scientific research and development.', 'AI systems used by public authorities in a third country or international organizations for law enforcement and judicial cooperation.', 'AI systems used by natural persons in the course of a purely personal non-professional activity.']",1
AI-Act-FullText.pdf,"This Regulation shall not apply to AI systems which are not placed on the market or put  into service in the Union, where the output is used in the Union exclusively for military,  defence or national security purposes, regardless of the type of entity carrying out those  activities.  4. This Regulation shall not apply to public authorities in a third country nor to international  organisations falling within the scope of this Regulation pursuant to paragraph 1, where  those authorities or organisations use AI systems in the framework of international  cooperation or agreements for law enforcement and judicial cooperation with the Union or  with one or more Member States, under the condition that  this third country or  international organisations provide adequate safeguards with respect to the protection of  fundamental rights and freedoms of individuals;   5. This Regulation shall not affect the application of the provisions on the liability of  intermediary service providers set out in Chapter II, Section 4 of Directive 2000/31/EC of  the European Parliament and of the Council29 [as to be replaced by  the corresponding  provisions of the Digital Services Act ].   5a. This Regulation shall not apply to AI systems and models, including their output,  specifically developed and put into service for the sole purpose of scientific research and  development.   5a. Union law on the protection of personal data, privacy and the confidentiality of  communications applies to personal data processed in connection with the rights and  obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU)  2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation;   5b. This Regulation shall not apply to any research, testing and development activity regarding  AI systems or models prior to  being placed on the market or put into service; those  activities shall be conducted respecting applicable Union law. The testing in real world  conditions shall not be covered by this exemption .  5b. This Regulation is without prejudice to the rules laid down by other Union legal acts  related to consumer protection and product safety.   5c. This Regulation shall not apply to obligations of deployers who are natural persons using  AI systems in the course of a purely personal non -professional activity.     29 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on  certain legal aspects of information society services, in particular electronic commerce, in  the Internal Market ('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).  5e. This Regulation shall not preclude Member States or the Union from maintaining or  introducing laws, regulations or administrative provisions which are more favourable to  workers in terms of protecting their rights in respect of the use of  AI systems by  employers, or to encourage or allow the application of collective agreements which are  more favourable to workers.   5g. The obligations laid down in this Regulation shall not apply to AI systems released under  free and open source licences unless they are placed on the market or put into service as  high-risk AI systems or an AI system that falls under Title II and IV.         (1) An AI system is a machine -based system designed to operate with varying levels of  autonomy and that may exhibit adaptiveness after deployment and that, for explicit  or implicit objectives, infers, from the input it receives, how to generate outputs such  as predictions, content, recommendations, or decisions that can influence physical or  virtual environments.","Does the Regulation apply to AI systems used by natural persons for personal, non-professional activities?","['Yes, the Regulation applies to all AI systems, regardless of their use.', 'No, the Regulation does not apply to AI systems used for personal, non-professional activities.', 'Yes, the Regulation applies to AI systems that are not open-source.', 'No, the Regulation does not apply to AI systems that are not high-risk.']",1
AI-Act-FullText.pdf,"This Regulation shall not apply to AI systems which are not placed on the market or put  into service in the Union, where the output is used in the Union exclusively for military,  defence or national security purposes, regardless of the type of entity carrying out those  activities.  4. This Regulation shall not apply to public authorities in a third country nor to international  organisations falling within the scope of this Regulation pursuant to paragraph 1, where  those authorities or organisations use AI systems in the framework of international  cooperation or agreements for law enforcement and judicial cooperation with the Union or  with one or more Member States, under the condition that  this third country or  international organisations provide adequate safeguards with respect to the protection of  fundamental rights and freedoms of individuals;   5. This Regulation shall not affect the application of the provisions on the liability of  intermediary service providers set out in Chapter II, Section 4 of Directive 2000/31/EC of  the European Parliament and of the Council29 [as to be replaced by  the corresponding  provisions of the Digital Services Act ].   5a. This Regulation shall not apply to AI systems and models, including their output,  specifically developed and put into service for the sole purpose of scientific research and  development.   5a. Union law on the protection of personal data, privacy and the confidentiality of  communications applies to personal data processed in connection with the rights and  obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU)  2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation;   5b. This Regulation shall not apply to any research, testing and development activity regarding  AI systems or models prior to  being placed on the market or put into service; those  activities shall be conducted respecting applicable Union law. The testing in real world  conditions shall not be covered by this exemption .  5b. This Regulation is without prejudice to the rules laid down by other Union legal acts  related to consumer protection and product safety.   5c. This Regulation shall not apply to obligations of deployers who are natural persons using  AI systems in the course of a purely personal non -professional activity.     29 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on  certain legal aspects of information society services, in particular electronic commerce, in  the Internal Market ('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).  5e. This Regulation shall not preclude Member States or the Union from maintaining or  introducing laws, regulations or administrative provisions which are more favourable to  workers in terms of protecting their rights in respect of the use of  AI systems by  employers, or to encourage or allow the application of collective agreements which are  more favourable to workers.   5g. The obligations laid down in this Regulation shall not apply to AI systems released under  free and open source licences unless they are placed on the market or put into service as  high-risk AI systems or an AI system that falls under Title II and IV.         (1) An AI system is a machine -based system designed to operate with varying levels of  autonomy and that may exhibit adaptiveness after deployment and that, for explicit  or implicit objectives, infers, from the input it receives, how to generate outputs such  as predictions, content, recommendations, or decisions that can influence physical or  virtual environments.",Can Member States or the Union introduce laws that are more favorable to workers in terms of protecting their rights in respect of the use of AI systems by employers?,"['Yes, Member States or the Union can introduce laws that are more favorable to workers.', 'No, this regulation prevents Member States or the Union from introducing laws that are more favorable to workers.', 'Only Member States can introduce laws that are more favorable to workers, but the Union cannot.', 'The regulation does not address whether Member States or the Union can introduce laws that are more favorable to workers.']",0
AI-Act-FullText.pdf,"This Regulation shall not apply to AI systems which are not placed on the market or put  into service in the Union, where the output is used in the Union exclusively for military,  defence or national security purposes, regardless of the type of entity carrying out those  activities.  4. This Regulation shall not apply to public authorities in a third country nor to international  organisations falling within the scope of this Regulation pursuant to paragraph 1, where  those authorities or organisations use AI systems in the framework of international  cooperation or agreements for law enforcement and judicial cooperation with the Union or  with one or more Member States, under the condition that  this third country or  international organisations provide adequate safeguards with respect to the protection of  fundamental rights and freedoms of individuals;   5. This Regulation shall not affect the application of the provisions on the liability of  intermediary service providers set out in Chapter II, Section 4 of Directive 2000/31/EC of  the European Parliament and of the Council29 [as to be replaced by  the corresponding  provisions of the Digital Services Act ].   5a. This Regulation shall not apply to AI systems and models, including their output,  specifically developed and put into service for the sole purpose of scientific research and  development.   5a. Union law on the protection of personal data, privacy and the confidentiality of  communications applies to personal data processed in connection with the rights and  obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU)  2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation;   5b. This Regulation shall not apply to any research, testing and development activity regarding  AI systems or models prior to  being placed on the market or put into service; those  activities shall be conducted respecting applicable Union law. The testing in real world  conditions shall not be covered by this exemption .  5b. This Regulation is without prejudice to the rules laid down by other Union legal acts  related to consumer protection and product safety.   5c. This Regulation shall not apply to obligations of deployers who are natural persons using  AI systems in the course of a purely personal non -professional activity.     29 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on  certain legal aspects of information society services, in particular electronic commerce, in  the Internal Market ('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).  5e. This Regulation shall not preclude Member States or the Union from maintaining or  introducing laws, regulations or administrative provisions which are more favourable to  workers in terms of protecting their rights in respect of the use of  AI systems by  employers, or to encourage or allow the application of collective agreements which are  more favourable to workers.   5g. The obligations laid down in this Regulation shall not apply to AI systems released under  free and open source licences unless they are placed on the market or put into service as  high-risk AI systems or an AI system that falls under Title II and IV.         (1) An AI system is a machine -based system designed to operate with varying levels of  autonomy and that may exhibit adaptiveness after deployment and that, for explicit  or implicit objectives, infers, from the input it receives, how to generate outputs such  as predictions, content, recommendations, or decisions that can influence physical or  virtual environments.",Are there any exceptions to the Regulation for AI systems released under free and open-source licenses?,"['Yes, such AI systems are entirely exempt from the Regulation.', 'Yes, such AI systems are exempt from the Regulation if they are not high-risk or do not fall under Titles II and IV.', 'No, there are no exceptions to the Regulation for AI systems released under free and open-source licenses.', 'Yes, such AI systems are exempt from the Regulation if they are placed on the market or put into service as high-risk AI systems.']",1
AI-Act-FullText.pdf,"This Regulation shall not apply to AI systems which are not placed on the market or put  into service in the Union, where the output is used in the Union exclusively for military,  defence or national security purposes, regardless of the type of entity carrying out those  activities.  4. This Regulation shall not apply to public authorities in a third country nor to international  organisations falling within the scope of this Regulation pursuant to paragraph 1, where  those authorities or organisations use AI systems in the framework of international  cooperation or agreements for law enforcement and judicial cooperation with the Union or  with one or more Member States, under the condition that  this third country or  international organisations provide adequate safeguards with respect to the protection of  fundamental rights and freedoms of individuals;   5. This Regulation shall not affect the application of the provisions on the liability of  intermediary service providers set out in Chapter II, Section 4 of Directive 2000/31/EC of  the European Parliament and of the Council29 [as to be replaced by  the corresponding  provisions of the Digital Services Act ].   5a. This Regulation shall not apply to AI systems and models, including their output,  specifically developed and put into service for the sole purpose of scientific research and  development.   5a. Union law on the protection of personal data, privacy and the confidentiality of  communications applies to personal data processed in connection with the rights and  obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU)  2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation;   5b. This Regulation shall not apply to any research, testing and development activity regarding  AI systems or models prior to  being placed on the market or put into service; those  activities shall be conducted respecting applicable Union law. The testing in real world  conditions shall not be covered by this exemption .  5b. This Regulation is without prejudice to the rules laid down by other Union legal acts  related to consumer protection and product safety.   5c. This Regulation shall not apply to obligations of deployers who are natural persons using  AI systems in the course of a purely personal non -professional activity.     29 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on  certain legal aspects of information society services, in particular electronic commerce, in  the Internal Market ('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).  5e. This Regulation shall not preclude Member States or the Union from maintaining or  introducing laws, regulations or administrative provisions which are more favourable to  workers in terms of protecting their rights in respect of the use of  AI systems by  employers, or to encourage or allow the application of collective agreements which are  more favourable to workers.   5g. The obligations laid down in this Regulation shall not apply to AI systems released under  free and open source licences unless they are placed on the market or put into service as  high-risk AI systems or an AI system that falls under Title II and IV.         (1) An AI system is a machine -based system designed to operate with varying levels of  autonomy and that may exhibit adaptiveness after deployment and that, for explicit  or implicit objectives, infers, from the input it receives, how to generate outputs such  as predictions, content, recommendations, or decisions that can influence physical or  virtual environments.",Does the Regulation apply to AI systems used for scientific research and development?,"['Yes, the Regulation applies to all AI systems, including those used for scientific research and development.', 'No, the Regulation does not apply to AI systems used for scientific research and development, as they are exempt under Article 5a.', 'Yes, the Regulation applies to AI systems used for scientific research and development, but only if they are high-risk AI systems or fall under Title II and IV.', 'No, the Regulation does not apply to AI systems used for scientific research and development, as they are not placed on the market or put into service.']",1
AI-Act-FullText.pdf,"This Regulation shall not apply to AI systems which are not placed on the market or put  into service in the Union, where the output is used in the Union exclusively for military,  defence or national security purposes, regardless of the type of entity carrying out those  activities.  4. This Regulation shall not apply to public authorities in a third country nor to international  organisations falling within the scope of this Regulation pursuant to paragraph 1, where  those authorities or organisations use AI systems in the framework of international  cooperation or agreements for law enforcement and judicial cooperation with the Union or  with one or more Member States, under the condition that  this third country or  international organisations provide adequate safeguards with respect to the protection of  fundamental rights and freedoms of individuals;   5. This Regulation shall not affect the application of the provisions on the liability of  intermediary service providers set out in Chapter II, Section 4 of Directive 2000/31/EC of  the European Parliament and of the Council29 [as to be replaced by  the corresponding  provisions of the Digital Services Act ].   5a. This Regulation shall not apply to AI systems and models, including their output,  specifically developed and put into service for the sole purpose of scientific research and  development.   5a. Union law on the protection of personal data, privacy and the confidentiality of  communications applies to personal data processed in connection with the rights and  obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU)  2016/679 and (EU) 2018/1725 and Directives 2002/58/EC and (EU) 2016/680, without  prejudice to arrangements provided for in Article 10(5) and Article 54 of this Regulation;   5b. This Regulation shall not apply to any research, testing and development activity regarding  AI systems or models prior to  being placed on the market or put into service; those  activities shall be conducted respecting applicable Union law. The testing in real world  conditions shall not be covered by this exemption .  5b. This Regulation is without prejudice to the rules laid down by other Union legal acts  related to consumer protection and product safety.   5c. This Regulation shall not apply to obligations of deployers who are natural persons using  AI systems in the course of a purely personal non -professional activity.     29 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on  certain legal aspects of information society services, in particular electronic commerce, in  the Internal Market ('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).  5e. This Regulation shall not preclude Member States or the Union from maintaining or  introducing laws, regulations or administrative provisions which are more favourable to  workers in terms of protecting their rights in respect of the use of  AI systems by  employers, or to encourage or allow the application of collective agreements which are  more favourable to workers.   5g. The obligations laid down in this Regulation shall not apply to AI systems released under  free and open source licences unless they are placed on the market or put into service as  high-risk AI systems or an AI system that falls under Title II and IV.         (1) An AI system is a machine -based system designed to operate with varying levels of  autonomy and that may exhibit adaptiveness after deployment and that, for explicit  or implicit objectives, infers, from the input it receives, how to generate outputs such  as predictions, content, recommendations, or decisions that can influence physical or  virtual environments.",Does the Regulation provide any exemptions for small and medium-sized enterprises (SMEs)?,"['Yes, SMEs are exempt from all provisions of the Regulation.', 'Yes, SMEs are exempt from certain provisions of the Regulation, such as the requirement for a risk assessment and the obligation to establish a complaint handling mechanism.', 'No, the Regulation does not provide any exemptions for SMEs.', 'Yes, SMEs are exempt from the Regulation if they use AI systems for research and development purposes only.']",2
AI-Act-FullText.pdf,"The adaptiveness that an AI system could exhibit  after deployment, refers to self -learning capabilities, allowing the system to change while  in use. AI systems can be used on a stand -alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or  serve the functionality of the product without being integrated therein (non -embedded).   (6a) The notion of ‘deployer’ referred to in this Regulation should be interpreted as any natural  or legal person, including a public authority, agency or other body, using an AI system  under its authority, except where the AI system is used in the course of a personal non  professional activity. Depending on the type of AI system, the use of the system may affect  persons other than the deployer.   (7) The notion of biometric data used in this Regulation should be interpreted in light of the  notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council 6, Article 3(18) of Regulation (EU) 2018/1725 of  the European Parliament and of the Council 7  and Article 3(13) of Directive (EU)  2016/680 of the European Parliament and of the Council 8.Biometric data can allow for the  authentication, identification or categorisation of natural persons and for the recognition of  emotions of natural persons.   (7a) The notion of biometric identification as used in this Regulation should be defined as the  automated recognition of physical, physiological and behavioural human features such as  the face, eye movement, body shape, voice, prosody, gait, posture, heart rate, blood  pressure, odour, keystrokes characteristics, for the purpose of establishing an individual’s  identity by comparing biometric data of that individual to stored biometric data of  individuals in a reference database, irrespective of whether the individual has given its  consent or not.  This excludes AI systems intended to be used for biometric verification,  which includes authentication, whose sole purpose is to confirm that a specific natural    6 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016  on the protection of natural persons with regard to the processing of personal data and on the  free movement of such data, and repealing Directive 95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).   7 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October  2018 on the protection of natural persons with regard to the processing of personal data by  the Union institutions, bodies, offices and agencies and on the free movement of such data,  and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295,  21.11.2018, p. 39)   8 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on  the protection of natural persons with regard to the processing of personal data by competent  authorities for the purposes of the prevention, investigation, detection or prosecution of  criminal offences or the execution of criminal penalties, and on the free movement of such  data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement  Directive) (OJ L 119, 4.5.2016, p. 89).  person is the person he or she claims to be and to confirm the identity of a natural person  for the sole purpose of having access to a service, unlocking a device or having security  access to premises.   (7b) The notion of biometric categorisation as used in this Regulation should be defined as  assigning natural persons to specific categories on the basis of their biometric  data. Such  specific categories can relate to aspects such as sex, age, hair colour, eye colour, tattoos,  behavioural or personality traits, language, religion, membership of a national minority,  sexual or political orientation. This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation","What does the term ""adaptiveness"" refer to in the context of AI systems?","['The ability of an AI system to learn from its environment and adapt to new situations.', 'The ability of an AI system to perform a specific task without any errors.', 'The ability of an AI system to process large amounts of data quickly and efficiently.', 'The ability of an AI system to be programmed to perform a specific task.']",0
AI-Act-FullText.pdf,"The adaptiveness that an AI system could exhibit  after deployment, refers to self -learning capabilities, allowing the system to change while  in use. AI systems can be used on a stand -alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or  serve the functionality of the product without being integrated therein (non -embedded).   (6a) The notion of ‘deployer’ referred to in this Regulation should be interpreted as any natural  or legal person, including a public authority, agency or other body, using an AI system  under its authority, except where the AI system is used in the course of a personal non  professional activity. Depending on the type of AI system, the use of the system may affect  persons other than the deployer.   (7) The notion of biometric data used in this Regulation should be interpreted in light of the  notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council 6, Article 3(18) of Regulation (EU) 2018/1725 of  the European Parliament and of the Council 7  and Article 3(13) of Directive (EU)  2016/680 of the European Parliament and of the Council 8.Biometric data can allow for the  authentication, identification or categorisation of natural persons and for the recognition of  emotions of natural persons.   (7a) The notion of biometric identification as used in this Regulation should be defined as the  automated recognition of physical, physiological and behavioural human features such as  the face, eye movement, body shape, voice, prosody, gait, posture, heart rate, blood  pressure, odour, keystrokes characteristics, for the purpose of establishing an individual’s  identity by comparing biometric data of that individual to stored biometric data of  individuals in a reference database, irrespective of whether the individual has given its  consent or not.  This excludes AI systems intended to be used for biometric verification,  which includes authentication, whose sole purpose is to confirm that a specific natural    6 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016  on the protection of natural persons with regard to the processing of personal data and on the  free movement of such data, and repealing Directive 95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).   7 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October  2018 on the protection of natural persons with regard to the processing of personal data by  the Union institutions, bodies, offices and agencies and on the free movement of such data,  and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295,  21.11.2018, p. 39)   8 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on  the protection of natural persons with regard to the processing of personal data by competent  authorities for the purposes of the prevention, investigation, detection or prosecution of  criminal offences or the execution of criminal penalties, and on the free movement of such  data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement  Directive) (OJ L 119, 4.5.2016, p. 89).  person is the person he or she claims to be and to confirm the identity of a natural person  for the sole purpose of having access to a service, unlocking a device or having security  access to premises.   (7b) The notion of biometric categorisation as used in this Regulation should be defined as  assigning natural persons to specific categories on the basis of their biometric  data. Such  specific categories can relate to aspects such as sex, age, hair colour, eye colour, tattoos,  behavioural or personality traits, language, religion, membership of a national minority,  sexual or political orientation. This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation","Who is considered a ""deployer"" in the context of AI systems?","['Any natural person using an AI system for personal, non-professional purposes.', 'Any legal or natural person, including public authorities, agencies, or other bodies, using an AI system under their authority.', 'The developer or manufacturer of the AI system.', 'The AI system itself, as it is capable of making decisions and taking actions autonomously.']",1
AI-Act-FullText.pdf,"The adaptiveness that an AI system could exhibit  after deployment, refers to self -learning capabilities, allowing the system to change while  in use. AI systems can be used on a stand -alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or  serve the functionality of the product without being integrated therein (non -embedded).   (6a) The notion of ‘deployer’ referred to in this Regulation should be interpreted as any natural  or legal person, including a public authority, agency or other body, using an AI system  under its authority, except where the AI system is used in the course of a personal non  professional activity. Depending on the type of AI system, the use of the system may affect  persons other than the deployer.   (7) The notion of biometric data used in this Regulation should be interpreted in light of the  notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council 6, Article 3(18) of Regulation (EU) 2018/1725 of  the European Parliament and of the Council 7  and Article 3(13) of Directive (EU)  2016/680 of the European Parliament and of the Council 8.Biometric data can allow for the  authentication, identification or categorisation of natural persons and for the recognition of  emotions of natural persons.   (7a) The notion of biometric identification as used in this Regulation should be defined as the  automated recognition of physical, physiological and behavioural human features such as  the face, eye movement, body shape, voice, prosody, gait, posture, heart rate, blood  pressure, odour, keystrokes characteristics, for the purpose of establishing an individual’s  identity by comparing biometric data of that individual to stored biometric data of  individuals in a reference database, irrespective of whether the individual has given its  consent or not.  This excludes AI systems intended to be used for biometric verification,  which includes authentication, whose sole purpose is to confirm that a specific natural    6 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016  on the protection of natural persons with regard to the processing of personal data and on the  free movement of such data, and repealing Directive 95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).   7 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October  2018 on the protection of natural persons with regard to the processing of personal data by  the Union institutions, bodies, offices and agencies and on the free movement of such data,  and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295,  21.11.2018, p. 39)   8 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on  the protection of natural persons with regard to the processing of personal data by competent  authorities for the purposes of the prevention, investigation, detection or prosecution of  criminal offences or the execution of criminal penalties, and on the free movement of such  data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement  Directive) (OJ L 119, 4.5.2016, p. 89).  person is the person he or she claims to be and to confirm the identity of a natural person  for the sole purpose of having access to a service, unlocking a device or having security  access to premises.   (7b) The notion of biometric categorisation as used in this Regulation should be defined as  assigning natural persons to specific categories on the basis of their biometric  data. Such  specific categories can relate to aspects such as sex, age, hair colour, eye colour, tattoos,  behavioural or personality traits, language, religion, membership of a national minority,  sexual or political orientation. This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation","What is the definition of ""biometric data"" in the context of AI systems?","['Any data that can be used to identify, authenticate, or categorize a natural person.', 'Data that is collected and processed for the purpose of biometric verification or identification.', ""Data that is used to analyze and predict a person's behavior, preferences, or emotions."", ""Data that is used to create a digital representation of a person's physical or behavioral characteristics.""]",1
AI-Act-FullText.pdf,"The adaptiveness that an AI system could exhibit  after deployment, refers to self -learning capabilities, allowing the system to change while  in use. AI systems can be used on a stand -alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or  serve the functionality of the product without being integrated therein (non -embedded).   (6a) The notion of ‘deployer’ referred to in this Regulation should be interpreted as any natural  or legal person, including a public authority, agency or other body, using an AI system  under its authority, except where the AI system is used in the course of a personal non  professional activity. Depending on the type of AI system, the use of the system may affect  persons other than the deployer.   (7) The notion of biometric data used in this Regulation should be interpreted in light of the  notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the  European Parliament and of the Council 6, Article 3(18) of Regulation (EU) 2018/1725 of  the European Parliament and of the Council 7  and Article 3(13) of Directive (EU)  2016/680 of the European Parliament and of the Council 8.Biometric data can allow for the  authentication, identification or categorisation of natural persons and for the recognition of  emotions of natural persons.   (7a) The notion of biometric identification as used in this Regulation should be defined as the  automated recognition of physical, physiological and behavioural human features such as  the face, eye movement, body shape, voice, prosody, gait, posture, heart rate, blood  pressure, odour, keystrokes characteristics, for the purpose of establishing an individual’s  identity by comparing biometric data of that individual to stored biometric data of  individuals in a reference database, irrespective of whether the individual has given its  consent or not.  This excludes AI systems intended to be used for biometric verification,  which includes authentication, whose sole purpose is to confirm that a specific natural    6 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016  on the protection of natural persons with regard to the processing of personal data and on the  free movement of such data, and repealing Directive 95/46/EC (General Data Protection  Regulation) (OJ L 119, 4.5.2016, p. 1).   7 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October  2018 on the protection of natural persons with regard to the processing of personal data by  the Union institutions, bodies, offices and agencies and on the free movement of such data,  and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295,  21.11.2018, p. 39)   8 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on  the protection of natural persons with regard to the processing of personal data by competent  authorities for the purposes of the prevention, investigation, detection or prosecution of  criminal offences or the execution of criminal penalties, and on the free movement of such  data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement  Directive) (OJ L 119, 4.5.2016, p. 89).  person is the person he or she claims to be and to confirm the identity of a natural person  for the sole purpose of having access to a service, unlocking a device or having security  access to premises.   (7b) The notion of biometric categorisation as used in this Regulation should be defined as  assigning natural persons to specific categories on the basis of their biometric  data. Such  specific categories can relate to aspects such as sex, age, hair colour, eye colour, tattoos,  behavioural or personality traits, language, religion, membership of a national minority,  sexual or political orientation. This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation",Is biometric categorization considered a form of biometric identification?,"['Yes, biometric categorization is a form of biometric identification.', 'No, biometric categorization is not a form of biometric identification.', 'Only if the biometric data used for categorization is obtained without consent.', 'Only if the biometric data used for categorization is used for law enforcement purposes.']",1
AI-Act-FullText.pdf,"This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation. For example, filters categorizing facial or body  features used on online marketplaces could constitute such an ancillary feature as they can  only be used in relation to the principal service which consists in selling a product by  allowing the consumer to preview the display of the product on him or herself and help the  consumer to make a purchase decision. Filters used on online social network services  which categorise facial or body features to allow users to add or modify pictures or videos  could also be considered as ancillary feature as such filter cannot be used without the  principal service of the social network services consisting in the sharing of content online.   (8) The notion of remote biometric identification system as used in this Regulation should be  defined functionally, as an AI system intended for the identification of natural persons  without their active involvement, typically at a distance, through the comparison of a  person’s biometric data with the biometric data contained in a reference database,  irrespectively of the particular technology, processes or types of biometric data used. Such  remote biometric identification systems are typically used to perc eive multiple persons or  their behaviour simultaneously in order to facilitate significantly the identification of  natural persons without their active involvement. This excludes AI systems intended to be  used for biometric verification, which includes authentication, whose sole purpose is to  confirm that a specific natural person is the person he or she claims to be and to confirm  the identity of a natural person for the sole purpose of having access to a service, unlocking  a device or having security acce ss to premises. This exclusion is justified by the fact that  such systems are likely to have a minor impact on fundamental rights of natural persons  compared to the remote biometric identification systems which may be used for the  processing of the biometric data of a large number of persons without their active involvement. In the case of ‘real -time’ systems, the capturing of the biometric data, the  comparison and the identification occur all instantaneously, near -instantaneously or in any  event without a significant delay. In this regard, there should be no scope for  circumventing the rules of this Regulation on the ‘real -time’ use of the AI systems in  question by providing for minor delays. ‘Real -time’ systems involve the use of ‘live’ or  ‘near -‘live’ material, such as video footage, generated by a camera or other device with  similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have  already been captured and the comparison and identification occur only after a significant  delay. This involves material, such as pictures or video footage generated by closed circuit  television cameras or private devices, which has been generated before the use of the  system in respect of the natural persons concerned.   (8a) The notion of emotion recognition system  for the purpose of in this regulation should be  defined as an AI system for the purpose of identifying or inferring emotions or intentions  of natural persons on the basis of their biometric data. This refers to emotions or intentions  such as  happiness, sadness, anger, surprise, disgust, embarrassment, excitement, shame,  contempt, satisfaction and amusement. It does not include physical states, such as pain or  fatigue. It refers for example to systems used in detecting  the state of fatigue of  professional pilots or drivers for the purpose of preventing accidents. It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering",What is the purpose of the Regulation mentioned in the text?,"['To regulate the use of AI systems for remote biometric identification.', 'To regulate the use of AI systems for biometric verification.', 'To regulate the use of AI systems for emotion recognition.', 'To regulate the use of AI systems for detecting physical states such as pain or fatigue.']",0
AI-Act-FullText.pdf,"This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation. For example, filters categorizing facial or body  features used on online marketplaces could constitute such an ancillary feature as they can  only be used in relation to the principal service which consists in selling a product by  allowing the consumer to preview the display of the product on him or herself and help the  consumer to make a purchase decision. Filters used on online social network services  which categorise facial or body features to allow users to add or modify pictures or videos  could also be considered as ancillary feature as such filter cannot be used without the  principal service of the social network services consisting in the sharing of content online.   (8) The notion of remote biometric identification system as used in this Regulation should be  defined functionally, as an AI system intended for the identification of natural persons  without their active involvement, typically at a distance, through the comparison of a  person’s biometric data with the biometric data contained in a reference database,  irrespectively of the particular technology, processes or types of biometric data used. Such  remote biometric identification systems are typically used to perc eive multiple persons or  their behaviour simultaneously in order to facilitate significantly the identification of  natural persons without their active involvement. This excludes AI systems intended to be  used for biometric verification, which includes authentication, whose sole purpose is to  confirm that a specific natural person is the person he or she claims to be and to confirm  the identity of a natural person for the sole purpose of having access to a service, unlocking  a device or having security acce ss to premises. This exclusion is justified by the fact that  such systems are likely to have a minor impact on fundamental rights of natural persons  compared to the remote biometric identification systems which may be used for the  processing of the biometric data of a large number of persons without their active involvement. In the case of ‘real -time’ systems, the capturing of the biometric data, the  comparison and the identification occur all instantaneously, near -instantaneously or in any  event without a significant delay. In this regard, there should be no scope for  circumventing the rules of this Regulation on the ‘real -time’ use of the AI systems in  question by providing for minor delays. ‘Real -time’ systems involve the use of ‘live’ or  ‘near -‘live’ material, such as video footage, generated by a camera or other device with  similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have  already been captured and the comparison and identification occur only after a significant  delay. This involves material, such as pictures or video footage generated by closed circuit  television cameras or private devices, which has been generated before the use of the  system in respect of the natural persons concerned.   (8a) The notion of emotion recognition system  for the purpose of in this regulation should be  defined as an AI system for the purpose of identifying or inferring emotions or intentions  of natural persons on the basis of their biometric data. This refers to emotions or intentions  such as  happiness, sadness, anger, surprise, disgust, embarrassment, excitement, shame,  contempt, satisfaction and amusement. It does not include physical states, such as pain or  fatigue. It refers for example to systems used in detecting  the state of fatigue of  professional pilots or drivers for the purpose of preventing accidents. It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering",What kind of systems are excluded from the definition of emotion recognition systems?,"['Systems used for biometric verification, such as authentication', 'Systems used for detecting physical states, such as pain or fatigue', 'Systems that detect readily apparent expressions, gestures, or movements', 'Systems used for identifying or inferring emotions or intentions of animals']",1
AI-Act-FullText.pdf,"This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation. For example, filters categorizing facial or body  features used on online marketplaces could constitute such an ancillary feature as they can  only be used in relation to the principal service which consists in selling a product by  allowing the consumer to preview the display of the product on him or herself and help the  consumer to make a purchase decision. Filters used on online social network services  which categorise facial or body features to allow users to add or modify pictures or videos  could also be considered as ancillary feature as such filter cannot be used without the  principal service of the social network services consisting in the sharing of content online.   (8) The notion of remote biometric identification system as used in this Regulation should be  defined functionally, as an AI system intended for the identification of natural persons  without their active involvement, typically at a distance, through the comparison of a  person’s biometric data with the biometric data contained in a reference database,  irrespectively of the particular technology, processes or types of biometric data used. Such  remote biometric identification systems are typically used to perc eive multiple persons or  their behaviour simultaneously in order to facilitate significantly the identification of  natural persons without their active involvement. This excludes AI systems intended to be  used for biometric verification, which includes authentication, whose sole purpose is to  confirm that a specific natural person is the person he or she claims to be and to confirm  the identity of a natural person for the sole purpose of having access to a service, unlocking  a device or having security acce ss to premises. This exclusion is justified by the fact that  such systems are likely to have a minor impact on fundamental rights of natural persons  compared to the remote biometric identification systems which may be used for the  processing of the biometric data of a large number of persons without their active involvement. In the case of ‘real -time’ systems, the capturing of the biometric data, the  comparison and the identification occur all instantaneously, near -instantaneously or in any  event without a significant delay. In this regard, there should be no scope for  circumventing the rules of this Regulation on the ‘real -time’ use of the AI systems in  question by providing for minor delays. ‘Real -time’ systems involve the use of ‘live’ or  ‘near -‘live’ material, such as video footage, generated by a camera or other device with  similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have  already been captured and the comparison and identification occur only after a significant  delay. This involves material, such as pictures or video footage generated by closed circuit  television cameras or private devices, which has been generated before the use of the  system in respect of the natural persons concerned.   (8a) The notion of emotion recognition system  for the purpose of in this regulation should be  defined as an AI system for the purpose of identifying or inferring emotions or intentions  of natural persons on the basis of their biometric data. This refers to emotions or intentions  such as  happiness, sadness, anger, surprise, disgust, embarrassment, excitement, shame,  contempt, satisfaction and amusement. It does not include physical states, such as pain or  fatigue. It refers for example to systems used in detecting  the state of fatigue of  professional pilots or drivers for the purpose of preventing accidents. It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering",What is the difference between real-time and post systems?,"['Real-time systems capture and process biometric data instantly, while post systems capture biometric data and process it after a significant delay.', 'Real-time systems use live or near-live material, while post systems use material generated before the use of the system.', 'Real-time systems are used for biometric verification, while post systems are used for remote biometric identification.', 'Real-time systems are used for remote biometric identification, while post systems are used for biometric verification.']",1
AI-Act-FullText.pdf,"This does not include biometric categorization systems that  are a purely ancillary feature intrinsically linked to another commercial service meaning  that the feature cannot, for objective technical reasons, be used without the principal  service and the integration of that feature or functionality is not a means to circumvent the  applicability of the rules of this Regulation. For example, filters categorizing facial or body  features used on online marketplaces could constitute such an ancillary feature as they can  only be used in relation to the principal service which consists in selling a product by  allowing the consumer to preview the display of the product on him or herself and help the  consumer to make a purchase decision. Filters used on online social network services  which categorise facial or body features to allow users to add or modify pictures or videos  could also be considered as ancillary feature as such filter cannot be used without the  principal service of the social network services consisting in the sharing of content online.   (8) The notion of remote biometric identification system as used in this Regulation should be  defined functionally, as an AI system intended for the identification of natural persons  without their active involvement, typically at a distance, through the comparison of a  person’s biometric data with the biometric data contained in a reference database,  irrespectively of the particular technology, processes or types of biometric data used. Such  remote biometric identification systems are typically used to perc eive multiple persons or  their behaviour simultaneously in order to facilitate significantly the identification of  natural persons without their active involvement. This excludes AI systems intended to be  used for biometric verification, which includes authentication, whose sole purpose is to  confirm that a specific natural person is the person he or she claims to be and to confirm  the identity of a natural person for the sole purpose of having access to a service, unlocking  a device or having security acce ss to premises. This exclusion is justified by the fact that  such systems are likely to have a minor impact on fundamental rights of natural persons  compared to the remote biometric identification systems which may be used for the  processing of the biometric data of a large number of persons without their active involvement. In the case of ‘real -time’ systems, the capturing of the biometric data, the  comparison and the identification occur all instantaneously, near -instantaneously or in any  event without a significant delay. In this regard, there should be no scope for  circumventing the rules of this Regulation on the ‘real -time’ use of the AI systems in  question by providing for minor delays. ‘Real -time’ systems involve the use of ‘live’ or  ‘near -‘live’ material, such as video footage, generated by a camera or other device with  similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have  already been captured and the comparison and identification occur only after a significant  delay. This involves material, such as pictures or video footage generated by closed circuit  television cameras or private devices, which has been generated before the use of the  system in respect of the natural persons concerned.   (8a) The notion of emotion recognition system  for the purpose of in this regulation should be  defined as an AI system for the purpose of identifying or inferring emotions or intentions  of natural persons on the basis of their biometric data. This refers to emotions or intentions  such as  happiness, sadness, anger, surprise, disgust, embarrassment, excitement, shame,  contempt, satisfaction and amusement. It does not include physical states, such as pain or  fatigue. It refers for example to systems used in detecting  the state of fatigue of  professional pilots or drivers for the purpose of preventing accidents. It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering",How does the Regulation define biometric data?,"['As any personally identifiable information that can be used to identify, track, or monitor a natural person.', 'As any data that can be used to identify, track, or monitor a natural person, including facial recognition, fingerprints, and DNA.', 'As any data that can be used to identify, track, or monitor a natural person, but excluding facial recognition and fingerprints.', 'As any data that can be used to identify, track, or monitor a natural person, but including only facial recognition and DNA.']",1
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems",What is the purpose of the Regulation mentioned in the text?,"['To regulate the use of AI systems in publicly accessible spaces.', 'To promote AI literacy among providers, deployers, and affected persons.', 'To ensure the appropriate compliance and enforcement of AI regulations.', 'To restrict access to publicly accessible spaces using AI systems.']",2
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems",Are online spaces considered publicly accessible under the Regulation?,"['Yes, online spaces are considered publicly accessible under the Regulation.', 'No, online spaces are not considered publicly accessible under the Regulation.', 'It depends on the type of online space and its intended use.', 'Online spaces are not covered by the Regulation.']",1
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems","Who is responsible for promoting AI literacy tools, public awareness, and understanding of AI systems?","['The European Artificial Intelligence Board', 'The Commission', 'Affected persons', 'Providers and deployers of AI systems']",1
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems",What are some examples of publicly accessible spaces mentioned in the text?,"['Restaurants, hospitals, and parks', 'Company premises, offices, and private residential buildings', 'Airports, train stations, and public roads', 'Museums, theatres, and cinemas']",2
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems",Are there any exceptions to what is considered a publicly accessible space?,"['Yes, publicly accessible spaces do not include prisons or border control areas.', 'No, all physical spaces that are accessible to an undetermined number of natural persons are considered publicly accessible.', 'Yes, private residential buildings are considered publicly accessible.', 'Yes, online spaces are considered publicly accessible.']",0
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems","How should AI literacy be promoted, according to the Regulation?","['Through mandatory training programs for all AI users.', 'By providing AI literacy tools, public awareness, and understanding of the benefits, risks, safeguards, rights, and obligations in relation to the use of AI systems.', 'By limiting access to AI systems to only those with specialized knowledge and training.', 'By promoting AI literacy only among affected persons, and not among providers and deployers.']",1
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems","What is the goal of promoting AI literacy, according to the Regulation?","['To ensure that only experts can use AI systems.', 'To equip providers, deployers, and affected persons with the necessary knowledge to make informed decisions regarding AI systems.', 'To limit the use of AI systems to only publicly accessible spaces.', 'To promote the development of AI systems without regard to ethical considerations.']",1
AI-Act-FullText.pdf,"It does also not  include the mere  detection of readily apparent expressions, gestures or movements, unless  they are used for  identifying or inferring emotions. These expressions can be basic facial  expressions such as a frown or a smile, or gestures such as the movement of hands, arms or  head, or characteristics of a person’s voice, for example a raised voice or whispering.   (9) For the purposes of this Regulation the notion of publicly accessible space should be  understood as referring to any physical place that is accessible to an undetermined number  of natural persons, and irrespective of whether the place in question is privately or publicly  owned and irrespective of the activity for which the place may be used, such as commerce  (for instance, shops, restaurants, cafés), services (for instance, banks, professional  activities, hospitality), sport (for instance, swimming pool s, gyms, stadiums), transport (for  instance, bus, metro and railway stations, airports, means of transport ), entertainment (for  instance, cinemas, theatres, museums, concert and conference halls) leisure or otherwise  (for instance, public roads and squares, parks, forests, playgrounds). A place should be  classified as publicly accessible also if, regardless of potential capacity or security  restrictions, access is subject to certain predetermined conditions, which can be fulfilled by  an undetermined number  of persons, such as purchase of a ticket or title of transport, prior registration or having a certain age. By contrast, a place should not be considered publicly  accessible if access is limited to specific and defined natural persons through either Union  or national law directly related to public safety or security or through the clear  manifestation of will by the person having the relevant authority on the place. The factual  possibility of access alone (e.g. an unlocked door, an open gate in a fence) does not imply  that the place is publicly accessible in the presence of indications or circumstances  suggesting the contrary (e.g. signs prohibiting or restricting access). Company and factory  premises as well as offices and workplaces that are intended to be accessed only by  relevant employees and service providers are places that are not publicly accessible.  Publicly accessible spaces should not include prisons or border control. Some other areas  may be composed of both not publicly accessible and publicly accessible areas, such as the  hallway of a private residential building necessary to access a doctor's office or an airport.  Online spaces are not covered either, as they are not physical spaces. Whether a given  space is accessible to the public should however be determined on a case -by-case basis,  having regard to the specificities of the individual situation at hand.   (9b) In order to obtain the greatest benefits from AI systems while protecting fundamental  rights, health and safety and to enable democratic control, AI literacy should equip  providers, deployers and affected persons with the necessary notions to make informed  decisions regarding AI systems. These notions may vary with regard to the relevant context  and can include understanding the correct application of technical elements during the AI  system’s development phase, the measures to be applied during its use, the suitable ways in  which to interpret the AI system’s output, and, in the case of affected persons, the  knowledge necessary to understand how decisions taken with the assistance of AI will  impact them. In the context of the application this Regulation, AI literacy should provide  all relevant actors in the AI value chain with the insights required to ensure the appropriate  compliance and its correct enforcement. Furthermore, the wide implementation  of AI  literacy measures and the introduction of appropriate follow -up actions could contribute to  improving working conditions and ultimately sustain the consolidation, and innovation  path of trustworthy AI in the Union. The European Artificial Intelligence Board should  support the Commission , to promote AI literacy tools, public awareness and understanding  of the benefits, risks, safeguards, rights and obligations in relation to the use of AI systems",What is the role of the European Artificial Intelligence Board in promoting AI literacy?,"['To develop AI literacy tools and promote public awareness and understanding of AI.', 'To regulate the use of AI systems in the European Union.', 'To provide technical support for the development of AI systems.', 'To conduct research on the ethical implications of AI.']",0
AI-Act-FullText.pdf,"(12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity. As  regards military and defence purposes, such exclusion is justified both by Article 4(2) TEU  and by the specifities of the Member States’ and the comm on Union defence policy  covered by Chapter 2 of Title V of the Treaty on European Union (TEU) that are subject to  public international law, which is therefore the more appropriate legal framework for the  regulation of AI systems in the context of the use of lethal force and other AI systems in  the context of military and defence activities. As regards national security purposes, the  exclusion is justified both by the fact that national security remains the sole responsibility  of Member States in accordance with Article 4(2) TEU and by the specific nature and  operational needs of national security activities and specific national rules applicable to  those activities. Nonetheless, if an AI system developed, placed on the market, put into  service or used for military, defence or national security purposes is used outside those  temporarily or permanently for other purposes (for example, civilian or humanitarian  purposes, law enforcement or public security purposes), such a system would fall within  the scope of th is Regulation. In that case, the entity using the system for other than  military, defence or national security purposes should ensure compliance of the system  with this Regulation, unless the system is already compliant with this Regulation. AI  systems placed on the market or put into service for an excluded (i.e. military, defence or  national security) and one or more non excluded purposes (e.g. civilian purposes, law  enforcement, etc.), fall within the scope of this Regulation and providers of those syste ms  should ensure compliance with this Regulation. In those cases, the fact that an AI system  may fall within the scope of this Regulation should not affect the possibility of entities  carrying out national security, defence and military activities, regardless of the type of  entity carrying out those activities, to use AI systems for national security, military and defence purposes, the use of which is excluded from the scope of this Regulation. An AI  system placed on the market for civilian or law enforcement purposes which is used with  or without modification for military, defence or national security purposes should not fall  within the scope of this Regulation, regardless of the type of entity carrying out those  activities.   (12c)  This Regulation should support innovation, respect freedom of science, and should not  undermine research and development activity. It is therefore necessary to exclude from its  scope AI systems and models specifically developed and put into service for the sole  purpose of scientific research and development. Moreover, it is necessary to ensure that the  Regulation does not otherwise affect scientific research and development activity on AI  systems or models prior to being placed on the market or put into service. As regards  product oriented research, testing and development activity regarding AI systems or  models, the provisions of this Regulation should also not apply prior to these systems and  models being put into service or placed on the market. This is without prejudice to the  obligation to comply with this Regulation when an AI system falling into the scope of this  Regulation is placed on the market or put into service as a result of such research and  development activity and to the application of provisions on regulatory sandboxes and  testing in real world conditions. Furthermore, without prejudice to the foregoing regarding  AI systems specifically developed and put into service for the sole purpose of scientific  research and development, any other AI system that may be used for the conduct of any  research and development activity should remain subject to the provisions of this  Regulation. Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law",What types of AI systems are excluded from the scope of the Regulation?,"['AI systems specifically developed and put into service for scientific research and development.', 'AI systems used for military, defense, or national security purposes.', 'AI systems placed on the market or put into service for civilian or law enforcement purposes that are later used for military, defense, or national security purposes.', 'AI systems used for product-oriented research, testing, and development activity.']",1
AI-Act-FullText.pdf,"(12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity. As  regards military and defence purposes, such exclusion is justified both by Article 4(2) TEU  and by the specifities of the Member States’ and the comm on Union defence policy  covered by Chapter 2 of Title V of the Treaty on European Union (TEU) that are subject to  public international law, which is therefore the more appropriate legal framework for the  regulation of AI systems in the context of the use of lethal force and other AI systems in  the context of military and defence activities. As regards national security purposes, the  exclusion is justified both by the fact that national security remains the sole responsibility  of Member States in accordance with Article 4(2) TEU and by the specific nature and  operational needs of national security activities and specific national rules applicable to  those activities. Nonetheless, if an AI system developed, placed on the market, put into  service or used for military, defence or national security purposes is used outside those  temporarily or permanently for other purposes (for example, civilian or humanitarian  purposes, law enforcement or public security purposes), such a system would fall within  the scope of th is Regulation. In that case, the entity using the system for other than  military, defence or national security purposes should ensure compliance of the system  with this Regulation, unless the system is already compliant with this Regulation. AI  systems placed on the market or put into service for an excluded (i.e. military, defence or  national security) and one or more non excluded purposes (e.g. civilian purposes, law  enforcement, etc.), fall within the scope of this Regulation and providers of those syste ms  should ensure compliance with this Regulation. In those cases, the fact that an AI system  may fall within the scope of this Regulation should not affect the possibility of entities  carrying out national security, defence and military activities, regardless of the type of  entity carrying out those activities, to use AI systems for national security, military and defence purposes, the use of which is excluded from the scope of this Regulation. An AI  system placed on the market for civilian or law enforcement purposes which is used with  or without modification for military, defence or national security purposes should not fall  within the scope of this Regulation, regardless of the type of entity carrying out those  activities.   (12c)  This Regulation should support innovation, respect freedom of science, and should not  undermine research and development activity. It is therefore necessary to exclude from its  scope AI systems and models specifically developed and put into service for the sole  purpose of scientific research and development. Moreover, it is necessary to ensure that the  Regulation does not otherwise affect scientific research and development activity on AI  systems or models prior to being placed on the market or put into service. As regards  product oriented research, testing and development activity regarding AI systems or  models, the provisions of this Regulation should also not apply prior to these systems and  models being put into service or placed on the market. This is without prejudice to the  obligation to comply with this Regulation when an AI system falling into the scope of this  Regulation is placed on the market or put into service as a result of such research and  development activity and to the application of provisions on regulatory sandboxes and  testing in real world conditions. Furthermore, without prejudice to the foregoing regarding  AI systems specifically developed and put into service for the sole purpose of scientific  research and development, any other AI system that may be used for the conduct of any  research and development activity should remain subject to the provisions of this  Regulation. Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law","Can AI systems developed for military, defence, or national security purposes be used for other purposes?","['Yes, such AI systems can be used for other purposes, but only if they are first modified to ensure compliance with this Regulation.', 'Yes, such AI systems can be used for other purposes, without the need for modification or compliance with this Regulation.', 'No, such AI systems can only be used for military, defence, or national security purposes, and their use for other purposes is prohibited.', 'Yes, such AI systems can be used for other purposes, but only by public entities and not by private entities.']",1
AI-Act-FullText.pdf,"(12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity. As  regards military and defence purposes, such exclusion is justified both by Article 4(2) TEU  and by the specifities of the Member States’ and the comm on Union defence policy  covered by Chapter 2 of Title V of the Treaty on European Union (TEU) that are subject to  public international law, which is therefore the more appropriate legal framework for the  regulation of AI systems in the context of the use of lethal force and other AI systems in  the context of military and defence activities. As regards national security purposes, the  exclusion is justified both by the fact that national security remains the sole responsibility  of Member States in accordance with Article 4(2) TEU and by the specific nature and  operational needs of national security activities and specific national rules applicable to  those activities. Nonetheless, if an AI system developed, placed on the market, put into  service or used for military, defence or national security purposes is used outside those  temporarily or permanently for other purposes (for example, civilian or humanitarian  purposes, law enforcement or public security purposes), such a system would fall within  the scope of th is Regulation. In that case, the entity using the system for other than  military, defence or national security purposes should ensure compliance of the system  with this Regulation, unless the system is already compliant with this Regulation. AI  systems placed on the market or put into service for an excluded (i.e. military, defence or  national security) and one or more non excluded purposes (e.g. civilian purposes, law  enforcement, etc.), fall within the scope of this Regulation and providers of those syste ms  should ensure compliance with this Regulation. In those cases, the fact that an AI system  may fall within the scope of this Regulation should not affect the possibility of entities  carrying out national security, defence and military activities, regardless of the type of  entity carrying out those activities, to use AI systems for national security, military and defence purposes, the use of which is excluded from the scope of this Regulation. An AI  system placed on the market for civilian or law enforcement purposes which is used with  or without modification for military, defence or national security purposes should not fall  within the scope of this Regulation, regardless of the type of entity carrying out those  activities.   (12c)  This Regulation should support innovation, respect freedom of science, and should not  undermine research and development activity. It is therefore necessary to exclude from its  scope AI systems and models specifically developed and put into service for the sole  purpose of scientific research and development. Moreover, it is necessary to ensure that the  Regulation does not otherwise affect scientific research and development activity on AI  systems or models prior to being placed on the market or put into service. As regards  product oriented research, testing and development activity regarding AI systems or  models, the provisions of this Regulation should also not apply prior to these systems and  models being put into service or placed on the market. This is without prejudice to the  obligation to comply with this Regulation when an AI system falling into the scope of this  Regulation is placed on the market or put into service as a result of such research and  development activity and to the application of provisions on regulatory sandboxes and  testing in real world conditions. Furthermore, without prejudice to the foregoing regarding  AI systems specifically developed and put into service for the sole purpose of scientific  research and development, any other AI system that may be used for the conduct of any  research and development activity should remain subject to the provisions of this  Regulation. Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law",How does the Regulation support innovation and respect freedom of science?,"['By excluding AI systems specifically developed and put into service for scientific research and development from its scope.', 'By ensuring that the Regulation does not apply to product-oriented research, testing, and development activity regarding AI systems or models prior to being put into service or placed on the market.', 'By requiring that all research and development activity on AI systems or models comply with the Regulation prior to being placed on the market or put into service.', 'By prohibiting the use of AI systems for scientific research and development purposes.']",1
AI-Act-FullText.pdf,"(12a)  If and insofar AI systems are placed on the market, put into service, or used with or  without modification of such systems for military, defence or national security purposes,  those should be excluded from the scope of this Regulation regardless of which type of  entity is carrying out those activities, such as whether it is a public or private entity. As  regards military and defence purposes, such exclusion is justified both by Article 4(2) TEU  and by the specifities of the Member States’ and the comm on Union defence policy  covered by Chapter 2 of Title V of the Treaty on European Union (TEU) that are subject to  public international law, which is therefore the more appropriate legal framework for the  regulation of AI systems in the context of the use of lethal force and other AI systems in  the context of military and defence activities. As regards national security purposes, the  exclusion is justified both by the fact that national security remains the sole responsibility  of Member States in accordance with Article 4(2) TEU and by the specific nature and  operational needs of national security activities and specific national rules applicable to  those activities. Nonetheless, if an AI system developed, placed on the market, put into  service or used for military, defence or national security purposes is used outside those  temporarily or permanently for other purposes (for example, civilian or humanitarian  purposes, law enforcement or public security purposes), such a system would fall within  the scope of th is Regulation. In that case, the entity using the system for other than  military, defence or national security purposes should ensure compliance of the system  with this Regulation, unless the system is already compliant with this Regulation. AI  systems placed on the market or put into service for an excluded (i.e. military, defence or  national security) and one or more non excluded purposes (e.g. civilian purposes, law  enforcement, etc.), fall within the scope of this Regulation and providers of those syste ms  should ensure compliance with this Regulation. In those cases, the fact that an AI system  may fall within the scope of this Regulation should not affect the possibility of entities  carrying out national security, defence and military activities, regardless of the type of  entity carrying out those activities, to use AI systems for national security, military and defence purposes, the use of which is excluded from the scope of this Regulation. An AI  system placed on the market for civilian or law enforcement purposes which is used with  or without modification for military, defence or national security purposes should not fall  within the scope of this Regulation, regardless of the type of entity carrying out those  activities.   (12c)  This Regulation should support innovation, respect freedom of science, and should not  undermine research and development activity. It is therefore necessary to exclude from its  scope AI systems and models specifically developed and put into service for the sole  purpose of scientific research and development. Moreover, it is necessary to ensure that the  Regulation does not otherwise affect scientific research and development activity on AI  systems or models prior to being placed on the market or put into service. As regards  product oriented research, testing and development activity regarding AI systems or  models, the provisions of this Regulation should also not apply prior to these systems and  models being put into service or placed on the market. This is without prejudice to the  obligation to comply with this Regulation when an AI system falling into the scope of this  Regulation is placed on the market or put into service as a result of such research and  development activity and to the application of provisions on regulatory sandboxes and  testing in real world conditions. Furthermore, without prejudice to the foregoing regarding  AI systems specifically developed and put into service for the sole purpose of scientific  research and development, any other AI system that may be used for the conduct of any  research and development activity should remain subject to the provisions of this  Regulation. Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law",How does the Regulation ensure that research and development activity is conducted ethically?,"['By excluding AI systems and models specifically developed and put into service for scientific research and development from its scope.', 'By requiring that all research and development activity on AI systems or models prior to being placed on the market or put into service comply with the Regulation.', 'By allowing the use of AI systems for military, defense, or national security purposes without complying with the Regulation.', 'By ensuring that any research and development activity should be carried out in accordance with recognized ethical and professional standards for scientific research and conducted according to applicable Union law.']",3
AI-Act-FullText.pdf,"Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law.      (14) In order to introduce a proportionate and effective set of binding rules for AI systems, a  clearly defined risk -based approach should be followed. That approach should tailor the  type and content of such rules to the intensity and scope of the risks that AI systems can  generate. It is therefore necessary to prohibit certain unacceptable artificial intelligence  practices, to lay down requirements for high -risk AI systems and obligations for the  relevant operators, and to lay down transparency obligations for certain AI systems.   (14a)  While the risk -based approach is the basis for a proportionate and effective set of binding  rules, it is important to recall the  2019 Ethics Guidelines for Trustworthy AI developed by the independent High -Level Expert Group on AI (HLEG) appointed by the Commission.  In those Guidelines the HLEG developed seven non -binding ethical principles for AI  which should help ensure that AI is trustworthy and ethically sound. The seven  principles   include: human agency and oversight; technical robustness and safety; privacy and data  governance; transparency; diversity, non -discrimination and fairness; societal and  environmental well -being and accountability. Without prejudice to the legally binding  requirements of this Regulation and any other applicable Union law, these Guidelines    contribute to the design of a coherent, trustworthy and human -centric Artificial  Intelligence, in line with the Charter and with the values on which the Union is founded.  According to the Guidelines of HLEG, human agency and oversight means  that AI  systems are developed and used as a tool that serves people, respects human dignity and  personal autonomy, and that is functioning in a way that can be appropriately controlled  and overseen by humans. Technical robustness and safety means  that AI systems are  developed and used in a way that allows robustness in case of problems and resilience  against attempts to alter the use or performance of the AI system so as to allow unlawful  use by third parties, and minimise  unintended harm . Privacy and data governance means   that AI systems are developed and used in compliance with existing privacy and data  protection rules, while processing data that meets high standards in terms of quality and  integrity. Transparency means  that AI systems  are developed and used in a way that  allows appropriate traceability and explainability, while making humans aware that they  communicate or interact with an AI system, as well as duly informing deployers of the  capabilities and limitations of that AI system and affected persons about their rights.  Diversity, non -discrimination and fairness means  that AI systems  are developed and used  in a way that includes diverse actors and promotes equal access, gender equality and  cultural diversity, while avoiding discriminatory impacts and unfair biases that are  prohibited by Union or national law. Social and environmental well -being means  that AI  systems  are developed and used in a sustainable and environmentally friendly manner as  well as in a way to benefit all human beings, while monitoring and assessing the long -term  impacts on the individual, society and democracy. The application of these principles  should be translated, when possible, in the design and use of AI models. They should in  any case serve as a basis for the drafting of codes of conduct under this Regulation.  All  stakeholders, including industry, academia, civil society and standardisation organisations,  are encouraged to take into account as appropriate the ethical principles for the  development of voluntary best practices and standards.  (15) Aside from the many beneficial uses of artificial intelligence, that technology can also be  misused and provide novel and powerful tools for manipulative, exploitative and social  control practices. Such practices are particularly harmful and abusive and should be  prohibited because they contradict Union values of respect for human dignity, freedom,  equality, democracy and the rule of law and Union fundamental rights, including the right  to non -discrimination, data protection and privacy and the rights of the child",What are the seven non-binding ethical principles for AI developed by the independent High-Level Expert Group on AI (HLEG)?,"['Human agency and oversight, technical robustness and safety, privacy and data governance, transparency, diversity, non-discrimination and fairness, societal and environmental well-being, and accountability.']",0
AI-Act-FullText.pdf,"Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law.      (14) In order to introduce a proportionate and effective set of binding rules for AI systems, a  clearly defined risk -based approach should be followed. That approach should tailor the  type and content of such rules to the intensity and scope of the risks that AI systems can  generate. It is therefore necessary to prohibit certain unacceptable artificial intelligence  practices, to lay down requirements for high -risk AI systems and obligations for the  relevant operators, and to lay down transparency obligations for certain AI systems.   (14a)  While the risk -based approach is the basis for a proportionate and effective set of binding  rules, it is important to recall the  2019 Ethics Guidelines for Trustworthy AI developed by the independent High -Level Expert Group on AI (HLEG) appointed by the Commission.  In those Guidelines the HLEG developed seven non -binding ethical principles for AI  which should help ensure that AI is trustworthy and ethically sound. The seven  principles   include: human agency and oversight; technical robustness and safety; privacy and data  governance; transparency; diversity, non -discrimination and fairness; societal and  environmental well -being and accountability. Without prejudice to the legally binding  requirements of this Regulation and any other applicable Union law, these Guidelines    contribute to the design of a coherent, trustworthy and human -centric Artificial  Intelligence, in line with the Charter and with the values on which the Union is founded.  According to the Guidelines of HLEG, human agency and oversight means  that AI  systems are developed and used as a tool that serves people, respects human dignity and  personal autonomy, and that is functioning in a way that can be appropriately controlled  and overseen by humans. Technical robustness and safety means  that AI systems are  developed and used in a way that allows robustness in case of problems and resilience  against attempts to alter the use or performance of the AI system so as to allow unlawful  use by third parties, and minimise  unintended harm . Privacy and data governance means   that AI systems are developed and used in compliance with existing privacy and data  protection rules, while processing data that meets high standards in terms of quality and  integrity. Transparency means  that AI systems  are developed and used in a way that  allows appropriate traceability and explainability, while making humans aware that they  communicate or interact with an AI system, as well as duly informing deployers of the  capabilities and limitations of that AI system and affected persons about their rights.  Diversity, non -discrimination and fairness means  that AI systems  are developed and used  in a way that includes diverse actors and promotes equal access, gender equality and  cultural diversity, while avoiding discriminatory impacts and unfair biases that are  prohibited by Union or national law. Social and environmental well -being means  that AI  systems  are developed and used in a sustainable and environmentally friendly manner as  well as in a way to benefit all human beings, while monitoring and assessing the long -term  impacts on the individual, society and democracy. The application of these principles  should be translated, when possible, in the design and use of AI models. They should in  any case serve as a basis for the drafting of codes of conduct under this Regulation.  All  stakeholders, including industry, academia, civil society and standardisation organisations,  are encouraged to take into account as appropriate the ethical principles for the  development of voluntary best practices and standards.  (15) Aside from the many beneficial uses of artificial intelligence, that technology can also be  misused and provide novel and powerful tools for manipulative, exploitative and social  control practices. Such practices are particularly harmful and abusive and should be  prohibited because they contradict Union values of respect for human dignity, freedom,  equality, democracy and the rule of law and Union fundamental rights, including the right  to non -discrimination, data protection and privacy and the rights of the child",What does human agency and oversight mean in the context of AI?,"['AI systems are developed and used in a way that allows humans to control and oversee them.', 'AI systems are developed and used in a way that minimizes unintended harm.', 'AI systems are developed and used in a way that promotes equal access and cultural diversity.', 'AI systems are developed and used in a way that includes diverse actors and promotes gender equality.']",0
AI-Act-FullText.pdf,"Under all circumstances, any research and development activity should be  carried out in accordance with recognised ethical and professional standards for scientific  research and should be conducted according to applicable Union law.      (14) In order to introduce a proportionate and effective set of binding rules for AI systems, a  clearly defined risk -based approach should be followed. That approach should tailor the  type and content of such rules to the intensity and scope of the risks that AI systems can  generate. It is therefore necessary to prohibit certain unacceptable artificial intelligence  practices, to lay down requirements for high -risk AI systems and obligations for the  relevant operators, and to lay down transparency obligations for certain AI systems.   (14a)  While the risk -based approach is the basis for a proportionate and effective set of binding  rules, it is important to recall the  2019 Ethics Guidelines for Trustworthy AI developed by the independent High -Level Expert Group on AI (HLEG) appointed by the Commission.  In those Guidelines the HLEG developed seven non -binding ethical principles for AI  which should help ensure that AI is trustworthy and ethically sound. The seven  principles   include: human agency and oversight; technical robustness and safety; privacy and data  governance; transparency; diversity, non -discrimination and fairness; societal and  environmental well -being and accountability. Without prejudice to the legally binding  requirements of this Regulation and any other applicable Union law, these Guidelines    contribute to the design of a coherent, trustworthy and human -centric Artificial  Intelligence, in line with the Charter and with the values on which the Union is founded.  According to the Guidelines of HLEG, human agency and oversight means  that AI  systems are developed and used as a tool that serves people, respects human dignity and  personal autonomy, and that is functioning in a way that can be appropriately controlled  and overseen by humans. Technical robustness and safety means  that AI systems are  developed and used in a way that allows robustness in case of problems and resilience  against attempts to alter the use or performance of the AI system so as to allow unlawful  use by third parties, and minimise  unintended harm . Privacy and data governance means   that AI systems are developed and used in compliance with existing privacy and data  protection rules, while processing data that meets high standards in terms of quality and  integrity. Transparency means  that AI systems  are developed and used in a way that  allows appropriate traceability and explainability, while making humans aware that they  communicate or interact with an AI system, as well as duly informing deployers of the  capabilities and limitations of that AI system and affected persons about their rights.  Diversity, non -discrimination and fairness means  that AI systems  are developed and used  in a way that includes diverse actors and promotes equal access, gender equality and  cultural diversity, while avoiding discriminatory impacts and unfair biases that are  prohibited by Union or national law. Social and environmental well -being means  that AI  systems  are developed and used in a sustainable and environmentally friendly manner as  well as in a way to benefit all human beings, while monitoring and assessing the long -term  impacts on the individual, society and democracy. The application of these principles  should be translated, when possible, in the design and use of AI models. They should in  any case serve as a basis for the drafting of codes of conduct under this Regulation.  All  stakeholders, including industry, academia, civil society and standardisation organisations,  are encouraged to take into account as appropriate the ethical principles for the  development of voluntary best practices and standards.  (15) Aside from the many beneficial uses of artificial intelligence, that technology can also be  misused and provide novel and powerful tools for manipulative, exploitative and social  control practices. Such practices are particularly harmful and abusive and should be  prohibited because they contradict Union values of respect for human dignity, freedom,  equality, democracy and the rule of law and Union fundamental rights, including the right  to non -discrimination, data protection and privacy and the rights of the child",Why is it important to prohibit certain artificial intelligence practices?,"['To ensure that AI systems are developed and used in a way that serves people, respects human dignity and personal autonomy.', 'To prevent AI systems from being used for manipulative, exploitative, and social control practices that contradict Union values and fundamental rights.', 'To promote diverse actors and equal access, gender equality, and cultural diversity in AI development and use.', 'To ensure that AI systems are developed and used in a sustainable and environmentally friendly manner.']",1
AI-Act-FullText.pdf,"Such practices are particularly harmful and abusive and should be  prohibited because they contradict Union values of respect for human dignity, freedom,  equality, democracy and the rule of law and Union fundamental rights, including the right  to non -discrimination, data protection and privacy and the rights of the child.   (16) AI-enabled manipulative techniques can be used to persuade persons to engage in  unwanted behaviours, or to deceive them by nudging them into decisions in a way that  subverts and impairs their autonomy, decision -making and free choices. The placing on the  market, putting into service or use of certain AI systems with the objective to or the effect  of materially distorting human behaviour, whereby  significant harms, in particular having  sufficiently important adverse impacts on physical, psychological h ealth or financial  interests are likely to occur, are particularly dangerous and should therefore be forbidden.  Such AI systems deploy subliminal components such as audio, image, video stimuli that  persons cannot perceive as those stimuli are beyond human perception or other  manipulative or deceptive  techniques that subvert or impair person’s autonomy, decision - making or free choices in ways that people are not consciously aware of, or even if aware   they are still deceived or not able to control or resist . This could be for example, facilitated  by machine -brain interfaces or virtual reality as they allow for a higher degree of control of  what stimuli are presented to persons, insofar as they may be materially distorting their  behaviour in a significantly harmful manner.  In addition, AI systems may also otherwise  exploit vulnerabilities of a person or a specific group of persons due to their age, disability  within the meaning of Directive (EU) 2019/882, or a specific social or economic situation  that is lik ely to make those persons more vulnerable to exploitation such as persons living  in extreme poverty, ethnic or religious minorities. Such AI systems can be placed on the  market, put into service or used with the objective to or the effect of materially distorting  the behaviour of a person and in a manner that causes or is reasonably likely to cause     significant harm to that or another person or groups of persons, including harms that may  be accumulated over time and should therefore be prohibited. The int ention to distort the  behaviour may not be presumed if the distortion results from factors external to the AI  system which are outside of the control of the provider or the deployer, meaning factors  that may not be reasonably foreseen and mitigated by the provider or the deployer of the  AI system. In any case, it is not necessary for the provider or the deployer to have the  intention to cause significant harm, as long as such harm results from the manipulative or exploitative AI -enabled practices. The prohibitions for such AI practices are  complementary to the provisions contained in Directive 2005/29/EC, notably unfair  commercial practices leading to economic or financial harms to consumers are prohibited  under all circumstances, irrespective of whether they are put in place through AI systems  or otherwise.  The prohibitions of manipulative and exploitative practices in this  Regulation should not affect lawful practices in the context of medical treatment such as  psychological treatment of a mental disease or physical rehabilitation, when those practices  are carried out in accordance with the applicable legislation and medical standards, for  example explicit consent of the individuals or their legal representatives   . In addition,  common and legitimate commercial practices, for example in the field of advertising, that  are in compliance with the applicable law should not in themselves be regarded as  constituting harmful manipulative AI practices.   (16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited",Are there any exceptions to the prohibition on manipulative and exploitative AI practices?,"['Yes, there are exceptions for medical treatment and legitimate commercial practices.', 'No, there are no exceptions to the prohibition on manipulative and exploitative AI practices.', 'Yes, there are exceptions for practices that are in compliance with the applicable law.', 'Yes, there are exceptions for practices that are carried out with the explicit consent of the individuals or their legal representatives.']",0
AI-Act-FullText.pdf,"Such practices are particularly harmful and abusive and should be  prohibited because they contradict Union values of respect for human dignity, freedom,  equality, democracy and the rule of law and Union fundamental rights, including the right  to non -discrimination, data protection and privacy and the rights of the child.   (16) AI-enabled manipulative techniques can be used to persuade persons to engage in  unwanted behaviours, or to deceive them by nudging them into decisions in a way that  subverts and impairs their autonomy, decision -making and free choices. The placing on the  market, putting into service or use of certain AI systems with the objective to or the effect  of materially distorting human behaviour, whereby  significant harms, in particular having  sufficiently important adverse impacts on physical, psychological h ealth or financial  interests are likely to occur, are particularly dangerous and should therefore be forbidden.  Such AI systems deploy subliminal components such as audio, image, video stimuli that  persons cannot perceive as those stimuli are beyond human perception or other  manipulative or deceptive  techniques that subvert or impair person’s autonomy, decision - making or free choices in ways that people are not consciously aware of, or even if aware   they are still deceived or not able to control or resist . This could be for example, facilitated  by machine -brain interfaces or virtual reality as they allow for a higher degree of control of  what stimuli are presented to persons, insofar as they may be materially distorting their  behaviour in a significantly harmful manner.  In addition, AI systems may also otherwise  exploit vulnerabilities of a person or a specific group of persons due to their age, disability  within the meaning of Directive (EU) 2019/882, or a specific social or economic situation  that is lik ely to make those persons more vulnerable to exploitation such as persons living  in extreme poverty, ethnic or religious minorities. Such AI systems can be placed on the  market, put into service or used with the objective to or the effect of materially distorting  the behaviour of a person and in a manner that causes or is reasonably likely to cause     significant harm to that or another person or groups of persons, including harms that may  be accumulated over time and should therefore be prohibited. The int ention to distort the  behaviour may not be presumed if the distortion results from factors external to the AI  system which are outside of the control of the provider or the deployer, meaning factors  that may not be reasonably foreseen and mitigated by the provider or the deployer of the  AI system. In any case, it is not necessary for the provider or the deployer to have the  intention to cause significant harm, as long as such harm results from the manipulative or exploitative AI -enabled practices. The prohibitions for such AI practices are  complementary to the provisions contained in Directive 2005/29/EC, notably unfair  commercial practices leading to economic or financial harms to consumers are prohibited  under all circumstances, irrespective of whether they are put in place through AI systems  or otherwise.  The prohibitions of manipulative and exploitative practices in this  Regulation should not affect lawful practices in the context of medical treatment such as  psychological treatment of a mental disease or physical rehabilitation, when those practices  are carried out in accordance with the applicable legislation and medical standards, for  example explicit consent of the individuals or their legal representatives   . In addition,  common and legitimate commercial practices, for example in the field of advertising, that  are in compliance with the applicable law should not in themselves be regarded as  constituting harmful manipulative AI practices.   (16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited",Can the use of AI systems for manipulative or exploitative purposes be justified in certain circumstances?,"['Yes, in situations where the benefits of AI outweigh the potential harms.', 'No, AI systems should never be used for manipulative or exploitative purposes.', 'Yes, if the individuals being targeted have given their explicit consent.', 'Yes, in cases where the AI system is being used for a legitimate commercial purpose.']",1
AI-Act-FullText.pdf,"(16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited. This prohibition does not cover the lawful labelling,  filtering or categorisation of biometric datasets acquired in line with Union or national law  according to biometric data, such as the sorting of images according to hair colour or eye  colour, which can for example be used in the area of law enforcement.   (17) AI systems providing social scoring of natural persons by public or  private actors may  lead to discriminatory outcomes and the exclusion of certain groups. They may violate the  right to dignity and non -discrimination and the values of equality and justice. Such AI  systems evaluate or classify natural persons or groups thereof based on multiple data points  related to their social behaviour in multiple contexts or known, inferred or predicted  personal or personality characteristics over certain periods of time. The social score  obtained from such AI systems may lead to the detrimental or unfavourable treatment of  natural persons or whole groups thereof in social contexts, which are unrelated to the  context in which the data was originally generated or collected or to a detrimental  treatment that is disproportionate or unjustified to the gravity of their social behaviour. AI  systems entailing such unacceptable scoring practices leading to such detrimental or  unfavorable outcomes  should be therefore prohibited. This prohibition should not affect  lawful evaluation practices of natural persons done for a specific purpose in compliance  with national and Union law.  (18) The use of AI systems for ‘real -time’ remote biometric identification of natural persons in  publicly accessible spaces for the purpose of law enforcement is  particularly intrusive to   the rights and freedoms of the concerned persons, to the extent that it may affect the  private life of a large part of the population, evoke a feeling of constant surveillance and  indirectly dissuade the exercise of the freedom of assembly and other fundamental rights .   Technical inaccuracies of AI systems intended for the remote biometric identification of  natural persons can lead to biased results and entail discriminatory effects. This is  particularly relevant when it comes to age, ethnicity, race, sex or disabilities.  In addition,  the immediacy of the impact and the limited opportunities for further checks or corrections  in relation to the use of such systems operating in ‘real -time’ carry heightened risks for the  rights and freedoms of the persons that are concerned by law enforcement activities.   (19) The use of those systems for the purpose of law enforcement should therefore be  prohibited, except in  exhaustively listed and narrowly defined situations, where the use is  strictly necessary to achieve a substantial public interest, the importance of which  outweighs the risks. Those situations involve the search for certain  victims of crime  including missing people; certain threats to the life or physical safety of natural persons or  of a terrorist attack; and the  localisation or identification  of perpetrators or suspects of the  criminal offences referred to in Annex IIa  if those criminal offences are punishable in the  Member State concerned by a custodial sentence or a detention order for a maximum  period of at least  four years and as they are defined in the law of that Member State. Such  threshold for the custodial sentence or detention order in accordance with national law  contributes to ensure that the offence should be serious enough to potentially justify the use  of ‘real -time’ remote biometr ic identification systems",What is the purpose of prohibiting AI systems that provide social scoring of natural persons?,"[""To prevent AI systems from accurately predicting a person's social behavior"", 'To prevent discriminatory outcomes and the exclusion of certain groups', ""To protect individuals' privacy and personal data"", 'To promote the use of AI systems for law enforcement']",1
AI-Act-FullText.pdf,"(16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited. This prohibition does not cover the lawful labelling,  filtering or categorisation of biometric datasets acquired in line with Union or national law  according to biometric data, such as the sorting of images according to hair colour or eye  colour, which can for example be used in the area of law enforcement.   (17) AI systems providing social scoring of natural persons by public or  private actors may  lead to discriminatory outcomes and the exclusion of certain groups. They may violate the  right to dignity and non -discrimination and the values of equality and justice. Such AI  systems evaluate or classify natural persons or groups thereof based on multiple data points  related to their social behaviour in multiple contexts or known, inferred or predicted  personal or personality characteristics over certain periods of time. The social score  obtained from such AI systems may lead to the detrimental or unfavourable treatment of  natural persons or whole groups thereof in social contexts, which are unrelated to the  context in which the data was originally generated or collected or to a detrimental  treatment that is disproportionate or unjustified to the gravity of their social behaviour. AI  systems entailing such unacceptable scoring practices leading to such detrimental or  unfavorable outcomes  should be therefore prohibited. This prohibition should not affect  lawful evaluation practices of natural persons done for a specific purpose in compliance  with national and Union law.  (18) The use of AI systems for ‘real -time’ remote biometric identification of natural persons in  publicly accessible spaces for the purpose of law enforcement is  particularly intrusive to   the rights and freedoms of the concerned persons, to the extent that it may affect the  private life of a large part of the population, evoke a feeling of constant surveillance and  indirectly dissuade the exercise of the freedom of assembly and other fundamental rights .   Technical inaccuracies of AI systems intended for the remote biometric identification of  natural persons can lead to biased results and entail discriminatory effects. This is  particularly relevant when it comes to age, ethnicity, race, sex or disabilities.  In addition,  the immediacy of the impact and the limited opportunities for further checks or corrections  in relation to the use of such systems operating in ‘real -time’ carry heightened risks for the  rights and freedoms of the persons that are concerned by law enforcement activities.   (19) The use of those systems for the purpose of law enforcement should therefore be  prohibited, except in  exhaustively listed and narrowly defined situations, where the use is  strictly necessary to achieve a substantial public interest, the importance of which  outweighs the risks. Those situations involve the search for certain  victims of crime  including missing people; certain threats to the life or physical safety of natural persons or  of a terrorist attack; and the  localisation or identification  of perpetrators or suspects of the  criminal offences referred to in Annex IIa  if those criminal offences are punishable in the  Member State concerned by a custodial sentence or a detention order for a maximum  period of at least  four years and as they are defined in the law of that Member State. Such  threshold for the custodial sentence or detention order in accordance with national law  contributes to ensure that the offence should be serious enough to potentially justify the use  of ‘real -time’ remote biometr ic identification systems",What is the issue with using AI systems for 'real-time' remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement?,"['It may lead to biased results and discriminatory effects, particularly when it comes to age, ethnicity, race, sex, or disabilities.', 'It may affect the private life of a large part of the population, evoke a feeling of constant surveillance, and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights.', 'It is a violation of the right to dignity and non-discrimination and the values of equality and justice.', 'It is not necessary to achieve a substantial public interest and the importance of which outweighs the risks.']",1
AI-Act-FullText.pdf,"(16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited. This prohibition does not cover the lawful labelling,  filtering or categorisation of biometric datasets acquired in line with Union or national law  according to biometric data, such as the sorting of images according to hair colour or eye  colour, which can for example be used in the area of law enforcement.   (17) AI systems providing social scoring of natural persons by public or  private actors may  lead to discriminatory outcomes and the exclusion of certain groups. They may violate the  right to dignity and non -discrimination and the values of equality and justice. Such AI  systems evaluate or classify natural persons or groups thereof based on multiple data points  related to their social behaviour in multiple contexts or known, inferred or predicted  personal or personality characteristics over certain periods of time. The social score  obtained from such AI systems may lead to the detrimental or unfavourable treatment of  natural persons or whole groups thereof in social contexts, which are unrelated to the  context in which the data was originally generated or collected or to a detrimental  treatment that is disproportionate or unjustified to the gravity of their social behaviour. AI  systems entailing such unacceptable scoring practices leading to such detrimental or  unfavorable outcomes  should be therefore prohibited. This prohibition should not affect  lawful evaluation practices of natural persons done for a specific purpose in compliance  with national and Union law.  (18) The use of AI systems for ‘real -time’ remote biometric identification of natural persons in  publicly accessible spaces for the purpose of law enforcement is  particularly intrusive to   the rights and freedoms of the concerned persons, to the extent that it may affect the  private life of a large part of the population, evoke a feeling of constant surveillance and  indirectly dissuade the exercise of the freedom of assembly and other fundamental rights .   Technical inaccuracies of AI systems intended for the remote biometric identification of  natural persons can lead to biased results and entail discriminatory effects. This is  particularly relevant when it comes to age, ethnicity, race, sex or disabilities.  In addition,  the immediacy of the impact and the limited opportunities for further checks or corrections  in relation to the use of such systems operating in ‘real -time’ carry heightened risks for the  rights and freedoms of the persons that are concerned by law enforcement activities.   (19) The use of those systems for the purpose of law enforcement should therefore be  prohibited, except in  exhaustively listed and narrowly defined situations, where the use is  strictly necessary to achieve a substantial public interest, the importance of which  outweighs the risks. Those situations involve the search for certain  victims of crime  including missing people; certain threats to the life or physical safety of natural persons or  of a terrorist attack; and the  localisation or identification  of perpetrators or suspects of the  criminal offences referred to in Annex IIa  if those criminal offences are punishable in the  Member State concerned by a custodial sentence or a detention order for a maximum  period of at least  four years and as they are defined in the law of that Member State. Such  threshold for the custodial sentence or detention order in accordance with national law  contributes to ensure that the offence should be serious enough to potentially justify the use  of ‘real -time’ remote biometr ic identification systems",What is the threshold for the custodial sentence or detention order for the use of 'real-time' remote biometric identification systems to be justified?,"['Two years', 'Four years', 'Six years', 'Ten years']",1
AI-Act-FullText.pdf,"(16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited. This prohibition does not cover the lawful labelling,  filtering or categorisation of biometric datasets acquired in line with Union or national law  according to biometric data, such as the sorting of images according to hair colour or eye  colour, which can for example be used in the area of law enforcement.   (17) AI systems providing social scoring of natural persons by public or  private actors may  lead to discriminatory outcomes and the exclusion of certain groups. They may violate the  right to dignity and non -discrimination and the values of equality and justice. Such AI  systems evaluate or classify natural persons or groups thereof based on multiple data points  related to their social behaviour in multiple contexts or known, inferred or predicted  personal or personality characteristics over certain periods of time. The social score  obtained from such AI systems may lead to the detrimental or unfavourable treatment of  natural persons or whole groups thereof in social contexts, which are unrelated to the  context in which the data was originally generated or collected or to a detrimental  treatment that is disproportionate or unjustified to the gravity of their social behaviour. AI  systems entailing such unacceptable scoring practices leading to such detrimental or  unfavorable outcomes  should be therefore prohibited. This prohibition should not affect  lawful evaluation practices of natural persons done for a specific purpose in compliance  with national and Union law.  (18) The use of AI systems for ‘real -time’ remote biometric identification of natural persons in  publicly accessible spaces for the purpose of law enforcement is  particularly intrusive to   the rights and freedoms of the concerned persons, to the extent that it may affect the  private life of a large part of the population, evoke a feeling of constant surveillance and  indirectly dissuade the exercise of the freedom of assembly and other fundamental rights .   Technical inaccuracies of AI systems intended for the remote biometric identification of  natural persons can lead to biased results and entail discriminatory effects. This is  particularly relevant when it comes to age, ethnicity, race, sex or disabilities.  In addition,  the immediacy of the impact and the limited opportunities for further checks or corrections  in relation to the use of such systems operating in ‘real -time’ carry heightened risks for the  rights and freedoms of the persons that are concerned by law enforcement activities.   (19) The use of those systems for the purpose of law enforcement should therefore be  prohibited, except in  exhaustively listed and narrowly defined situations, where the use is  strictly necessary to achieve a substantial public interest, the importance of which  outweighs the risks. Those situations involve the search for certain  victims of crime  including missing people; certain threats to the life or physical safety of natural persons or  of a terrorist attack; and the  localisation or identification  of perpetrators or suspects of the  criminal offences referred to in Annex IIa  if those criminal offences are punishable in the  Member State concerned by a custodial sentence or a detention order for a maximum  period of at least  four years and as they are defined in the law of that Member State. Such  threshold for the custodial sentence or detention order in accordance with national law  contributes to ensure that the offence should be serious enough to potentially justify the use  of ‘real -time’ remote biometr ic identification systems",What is the significance of the requirement that the use of AI systems for law enforcement purposes must be strictly necessary to achieve a substantial public interest?,"['It ensures that the use of AI systems is proportionate to the gravity of the crime being investigated.', ""It guarantees that the use of AI systems will not infringe on individuals' fundamental rights and freedoms."", 'It allows law enforcement agencies to use AI systems for any purpose they deem necessary.', 'It ensures that the use of AI systems is limited to situations where it is necessary to prevent imminent harm to individuals or the community.']",3
AI-Act-FullText.pdf,"(16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited. This prohibition does not cover the lawful labelling,  filtering or categorisation of biometric datasets acquired in line with Union or national law  according to biometric data, such as the sorting of images according to hair colour or eye  colour, which can for example be used in the area of law enforcement.   (17) AI systems providing social scoring of natural persons by public or  private actors may  lead to discriminatory outcomes and the exclusion of certain groups. They may violate the  right to dignity and non -discrimination and the values of equality and justice. Such AI  systems evaluate or classify natural persons or groups thereof based on multiple data points  related to their social behaviour in multiple contexts or known, inferred or predicted  personal or personality characteristics over certain periods of time. The social score  obtained from such AI systems may lead to the detrimental or unfavourable treatment of  natural persons or whole groups thereof in social contexts, which are unrelated to the  context in which the data was originally generated or collected or to a detrimental  treatment that is disproportionate or unjustified to the gravity of their social behaviour. AI  systems entailing such unacceptable scoring practices leading to such detrimental or  unfavorable outcomes  should be therefore prohibited. This prohibition should not affect  lawful evaluation practices of natural persons done for a specific purpose in compliance  with national and Union law.  (18) The use of AI systems for ‘real -time’ remote biometric identification of natural persons in  publicly accessible spaces for the purpose of law enforcement is  particularly intrusive to   the rights and freedoms of the concerned persons, to the extent that it may affect the  private life of a large part of the population, evoke a feeling of constant surveillance and  indirectly dissuade the exercise of the freedom of assembly and other fundamental rights .   Technical inaccuracies of AI systems intended for the remote biometric identification of  natural persons can lead to biased results and entail discriminatory effects. This is  particularly relevant when it comes to age, ethnicity, race, sex or disabilities.  In addition,  the immediacy of the impact and the limited opportunities for further checks or corrections  in relation to the use of such systems operating in ‘real -time’ carry heightened risks for the  rights and freedoms of the persons that are concerned by law enforcement activities.   (19) The use of those systems for the purpose of law enforcement should therefore be  prohibited, except in  exhaustively listed and narrowly defined situations, where the use is  strictly necessary to achieve a substantial public interest, the importance of which  outweighs the risks. Those situations involve the search for certain  victims of crime  including missing people; certain threats to the life or physical safety of natural persons or  of a terrorist attack; and the  localisation or identification  of perpetrators or suspects of the  criminal offences referred to in Annex IIa  if those criminal offences are punishable in the  Member State concerned by a custodial sentence or a detention order for a maximum  period of at least  four years and as they are defined in the law of that Member State. Such  threshold for the custodial sentence or detention order in accordance with national law  contributes to ensure that the offence should be serious enough to potentially justify the use  of ‘real -time’ remote biometr ic identification systems",How does the use of AI systems for 'real-time' remote biometric identification impact the exercise of fundamental rights?,"['It does not impact the exercise of fundamental rights.', 'It may indirectly dissuade the exercise of the freedom of assembly and other fundamental rights.', 'It has no impact on the private life of individuals.', 'It does not affect the rights and freedoms of the concerned persons.']",1
AI-Act-FullText.pdf,"(16a)  Biometric categorisation systems that are based on individuals’ biometric data, such as an  individual person’s face or fingerprint, to deduce or infer an individuals’ political opinions,  trade union membership, religious or philosophical beliefs, race, sex life or sexual  orientation should be prohibited. This prohibition does not cover the lawful labelling,  filtering or categorisation of biometric datasets acquired in line with Union or national law  according to biometric data, such as the sorting of images according to hair colour or eye  colour, which can for example be used in the area of law enforcement.   (17) AI systems providing social scoring of natural persons by public or  private actors may  lead to discriminatory outcomes and the exclusion of certain groups. They may violate the  right to dignity and non -discrimination and the values of equality and justice. Such AI  systems evaluate or classify natural persons or groups thereof based on multiple data points  related to their social behaviour in multiple contexts or known, inferred or predicted  personal or personality characteristics over certain periods of time. The social score  obtained from such AI systems may lead to the detrimental or unfavourable treatment of  natural persons or whole groups thereof in social contexts, which are unrelated to the  context in which the data was originally generated or collected or to a detrimental  treatment that is disproportionate or unjustified to the gravity of their social behaviour. AI  systems entailing such unacceptable scoring practices leading to such detrimental or  unfavorable outcomes  should be therefore prohibited. This prohibition should not affect  lawful evaluation practices of natural persons done for a specific purpose in compliance  with national and Union law.  (18) The use of AI systems for ‘real -time’ remote biometric identification of natural persons in  publicly accessible spaces for the purpose of law enforcement is  particularly intrusive to   the rights and freedoms of the concerned persons, to the extent that it may affect the  private life of a large part of the population, evoke a feeling of constant surveillance and  indirectly dissuade the exercise of the freedom of assembly and other fundamental rights .   Technical inaccuracies of AI systems intended for the remote biometric identification of  natural persons can lead to biased results and entail discriminatory effects. This is  particularly relevant when it comes to age, ethnicity, race, sex or disabilities.  In addition,  the immediacy of the impact and the limited opportunities for further checks or corrections  in relation to the use of such systems operating in ‘real -time’ carry heightened risks for the  rights and freedoms of the persons that are concerned by law enforcement activities.   (19) The use of those systems for the purpose of law enforcement should therefore be  prohibited, except in  exhaustively listed and narrowly defined situations, where the use is  strictly necessary to achieve a substantial public interest, the importance of which  outweighs the risks. Those situations involve the search for certain  victims of crime  including missing people; certain threats to the life or physical safety of natural persons or  of a terrorist attack; and the  localisation or identification  of perpetrators or suspects of the  criminal offences referred to in Annex IIa  if those criminal offences are punishable in the  Member State concerned by a custodial sentence or a detention order for a maximum  period of at least  four years and as they are defined in the law of that Member State. Such  threshold for the custodial sentence or detention order in accordance with national law  contributes to ensure that the offence should be serious enough to potentially justify the use  of ‘real -time’ remote biometr ic identification systems","What is the purpose of Annex IIa, which lists the criminal offenses for which the use of 'real-time' remote biometric identification systems is permitted?","[""To specify the minimum requirements for the use of 'real-time' remote biometric identification systems in law enforcement."", 'To list the criminal offenses that are punishable by a custodial sentence or detention order for a maximum period of at least four years in the Member State concerned.', ""To provide a list of exceptions where the use of 'real-time' remote biometric identification systems is prohibited."", ""To establish a framework for the evaluation and approval of 'real-time' remote biometric identification systems for law enforcement purposes.""]",1